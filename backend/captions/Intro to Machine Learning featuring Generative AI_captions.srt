1
00:00:00,080 --> 00:00:04,480
welcome to this intro to machine

2
00:00:01,560 --> 00:00:07,280
learning course from Rola Dolly Rola is

3
00:00:04,480 --> 00:00:09,719
an AI engineer and has a PHD in

4
00:00:07,280 --> 00:00:11,840
Neuroscience the course starts with the

5
00:00:09,719 --> 00:00:13,639
fundamentals covering what machine

6
00:00:11,840 --> 00:00:15,240
learning is how it differs from

7
00:00:13,639 --> 00:00:17,400
traditional approaches and when it's

8
00:00:15,240 --> 00:00:20,600
used it then Dives deeper into the

9
00:00:17,400 --> 00:00:23,279
mechanics exploring different models

10
00:00:20,600 --> 00:00:26,160
algorithms and training processes next

11
00:00:23,279 --> 00:00:29,000
it covers generative AI before wrapping

12
00:00:26,160 --> 00:00:30,840
up with the architecture of AI systems

13
00:00:29,000 --> 00:00:34,000
and how to design deploy them

14
00:00:30,840 --> 00:00:37,239
effectively hello everyone my name is uh

15
00:00:34,000 --> 00:00:40,879
Rola D I am a machine learning architect

16
00:00:37,239 --> 00:00:44,680
and uh what I want to do here today is

17
00:00:40,879 --> 00:00:47,160
to give you some background information

18
00:00:44,680 --> 00:00:51,239
on machine learning so this is really a

19
00:00:47,160 --> 00:00:52,879
primer for people without um ml

20
00:00:51,239 --> 00:00:55,039
knowledge it's not supposed to go into

21
00:00:52,879 --> 00:00:57,120
technical great technical detail I just

22
00:00:55,039 --> 00:01:01,840
want to give you practically the lay of

23
00:00:57,120 --> 00:01:04,360
the land um and so I'll take you through

24
00:01:01,840 --> 00:01:06,360
this so um just a little bit about

25
00:01:04,360 --> 00:01:10,119
myself again I'm a machine learning

26
00:01:06,360 --> 00:01:13,280
architect at rapid scale um we serve the

27
00:01:10,119 --> 00:01:16,280
US market and I help customers build

28
00:01:13,280 --> 00:01:17,759
machine Learning Systems every day um I

29
00:01:16,280 --> 00:01:19,920
come from an academic background so I

30
00:01:17,759 --> 00:01:22,240
have a PhD in N science and biomatics I

31
00:01:19,920 --> 00:01:25,200
graduated from Mill University in

32
00:01:22,240 --> 00:01:27,840
2017 um I like to say that I was

33
00:01:25,200 --> 00:01:29,560
interested in human intelligence and now

34
00:01:27,840 --> 00:01:32,159
I work more in artificial intelligence I

35
00:01:29,560 --> 00:01:34,399
really like like to compare and contrast

36
00:01:32,159 --> 00:01:36,560
um the two

37
00:01:34,399 --> 00:01:39,439
occasionally um I'm also an AWS

38
00:01:36,560 --> 00:01:43,799
Enthusiast so I'm an AWS Community

39
00:01:39,439 --> 00:01:47,040
Builder I'm the AWS Montreal uh co-lead

40
00:01:43,799 --> 00:01:49,560
and I'm also a an an AWS Ambassador for

41
00:01:47,040 --> 00:01:52,680
Rapid scale I'm a gold jacket Ambassador

42
00:01:49,560 --> 00:01:55,880
which means that I have completed all 12

43
00:01:52,680 --> 00:01:58,000
certifications um on a personal side I

44
00:01:55,880 --> 00:02:02,240
am a mother of two little angels that

45
00:01:58,000 --> 00:02:04,439
keep me busy and I love to cake um

46
00:02:02,240 --> 00:02:07,039
although I don't get to do that as much

47
00:02:04,439 --> 00:02:10,560
anymore um so in terms of what I've got

48
00:02:07,039 --> 00:02:13,480
here today it's a series uh a four part

49
00:02:10,560 --> 00:02:15,319
series um I'm going to go through what

50
00:02:13,480 --> 00:02:18,480
I'm calling ml11 which is an

51
00:02:15,319 --> 00:02:20,120
introduction to machine learning ml12

52
00:02:18,480 --> 00:02:21,920
which is really ml under the hood so

53
00:02:20,120 --> 00:02:24,080
we'll talk a little bit about algorithms

54
00:02:21,920 --> 00:02:25,599
just to peel a layer off and and give

55
00:02:24,080 --> 00:02:29,040
you a better understanding of what is

56
00:02:25,599 --> 00:02:30,400
going on ml13 is an introduction to

57
00:02:29,040 --> 00:02:33,720
generative AI

58
00:02:30,400 --> 00:02:37,599
and 104 is about architecting a gen

59
00:02:33,720 --> 00:02:40,400
system okay so they shouldn't be um long

60
00:02:37,599 --> 00:02:44,519
I'm expecting about 30 minutes a lecture

61
00:02:40,400 --> 00:02:47,480
hopefully I do tend to go off rails

62
00:02:44,519 --> 00:02:50,560
sometimes so let's say 45 minutes and um

63
00:02:47,480 --> 00:02:54,159
hopefully it's useful so I'll see you in

64
00:02:50,560 --> 00:02:56,159
the next one hello again um so let's

65
00:02:54,159 --> 00:02:57,760
start with ml11 so this is an

66
00:02:56,159 --> 00:03:00,440
introduction to machine learning again

67
00:02:57,760 --> 00:03:04,239
it assumes no knowledge um and this is

68
00:03:00,440 --> 00:03:07,200
supposed to be for a beginner

69
00:03:04,239 --> 00:03:08,640
audience so um I'll go through what

70
00:03:07,200 --> 00:03:10,040
machine learning is in terms of

71
00:03:08,640 --> 00:03:11,799
definition how it's different from

72
00:03:10,040 --> 00:03:14,040
computer science how it's different from

73
00:03:11,799 --> 00:03:15,519
statistics where to use it and where not

74
00:03:14,040 --> 00:03:17,519
to use it and a little bit about the

75
00:03:15,519 --> 00:03:20,959
machine learning life cycle talk a

76
00:03:17,519 --> 00:03:22,640
little bit about ML on AWS um it looks

77
00:03:20,959 --> 00:03:26,280
um it's fairly similar to how it look it

78
00:03:22,640 --> 00:03:29,400
works on cloud in general but I am um an

79
00:03:26,280 --> 00:03:33,239
AWS prati heavy practitioner so I'll

80
00:03:29,400 --> 00:03:35,000
choose AWS and then I'll look at um

81
00:03:33,239 --> 00:03:37,840
artificial intelligence versus human

82
00:03:35,000 --> 00:03:41,080
intelligence again in Ode to my

83
00:03:37,840 --> 00:03:42,400
doctorate studies okay so what is

84
00:03:41,080 --> 00:03:44,519
machine learning so in terms of

85
00:03:42,400 --> 00:03:49,120
definition and if you looked if you

86
00:03:44,519 --> 00:03:51,000
asked Google um then you'll get a uh a

87
00:03:49,120 --> 00:03:53,519
definition from Oxford languages which

88
00:03:51,000 --> 00:03:55,959
says machine learning is the use and

89
00:03:53,519 --> 00:03:58,239
development of computer systems that are

90
00:03:55,959 --> 00:04:01,280
able to learn and adapt without

91
00:03:58,239 --> 00:04:04,439
following explicit instruction

92
00:04:01,280 --> 00:04:06,280
and by using algorithms and statistical

93
00:04:04,439 --> 00:04:08,640
models to analyze and draw inferences

94
00:04:06,280 --> 00:04:10,200
from patterns in the data I don't know

95
00:04:08,640 --> 00:04:13,599
if you understood anything from that but

96
00:04:10,200 --> 00:04:15,760
it's pretty uh long so let's deconstruct

97
00:04:13,599 --> 00:04:19,600
this a little bit so machine learning

98
00:04:15,760 --> 00:04:22,880
systems are computer systems um they are

99
00:04:19,600 --> 00:04:25,560
based on algorithm and statistical

100
00:04:22,880 --> 00:04:28,120
models and they learn patterns in the

101
00:04:25,560 --> 00:04:30,120
data without following explicit

102
00:04:28,120 --> 00:04:32,919
instructions so these are the four core

103
00:04:30,120 --> 00:04:34,800
things I think in here and so if I were

104
00:04:32,919 --> 00:04:38,639
to rewrite this I would say that machine

105
00:04:34,800 --> 00:04:41,080
learning is really powerful mathematics

106
00:04:38,639 --> 00:04:43,880
powered by computer systems that learn

107
00:04:41,080 --> 00:04:47,039
patterns in the data without explicitly

108
00:04:43,880 --> 00:04:49,280
being taught that's my

109
00:04:47,039 --> 00:04:52,520
definition and that that's exactly what

110
00:04:49,280 --> 00:04:53,840
it is so it's it's math it's computers

111
00:04:52,520 --> 00:04:56,360
it's

112
00:04:53,840 --> 00:04:59,720
data and so how is it different from

113
00:04:56,360 --> 00:05:00,600
computer software so ml has been called

114
00:04:59,720 --> 00:05:03,199
software

115
00:05:00,600 --> 00:05:06,840
2.0 uh so how is it really different

116
00:05:03,199 --> 00:05:09,720
from so uh traditional software well

117
00:05:06,840 --> 00:05:11,360
there's two steps to any software system

118
00:05:09,720 --> 00:05:12,800
there's there's the development step and

119
00:05:11,360 --> 00:05:15,680
then there's the deployment step right

120
00:05:12,800 --> 00:05:17,000
so in traditional software during

121
00:05:15,680 --> 00:05:19,600
development you've got yourself a

122
00:05:17,000 --> 00:05:20,880
computer and what you do is you sit down

123
00:05:19,600 --> 00:05:22,880
and you write your code this is the

124
00:05:20,880 --> 00:05:25,039
formula you sit down and whatever

125
00:05:22,880 --> 00:05:27,199
language you choose you you write a set

126
00:05:25,039 --> 00:05:29,400
of statements right if this happens do

127
00:05:27,199 --> 00:05:32,240
that when this happens do this other

128
00:05:29,400 --> 00:05:34,479
thing and so on so that's your code and

129
00:05:32,240 --> 00:05:37,039
then what happens is you give the code

130
00:05:34,479 --> 00:05:40,080
an input the computer crunches all of

131
00:05:37,039 --> 00:05:41,400
this and gives you an output right now

132
00:05:40,080 --> 00:05:42,880
how is that different in machine

133
00:05:41,400 --> 00:05:45,280
learning well in machine learning

134
00:05:42,880 --> 00:05:47,479
development this is what we call

135
00:05:45,280 --> 00:05:49,919
training and you've got a

136
00:05:47,479 --> 00:05:51,759
computer but then instead of actually

137
00:05:49,919 --> 00:05:53,240
writing the formula what you do is you

138
00:05:51,759 --> 00:05:55,880
give it the

139
00:05:53,240 --> 00:05:57,720
input and you give it the output this is

140
00:05:55,880 --> 00:06:00,039
a specific type called supervised

141
00:05:57,720 --> 00:06:01,800
learning but it it's it's one of the

142
00:06:00,039 --> 00:06:03,319
more popular types so that's what I'm

143
00:06:01,800 --> 00:06:05,160
going to use and so you've got yourself

144
00:06:03,319 --> 00:06:07,360
a computer you give it the input and you

145
00:06:05,160 --> 00:06:09,560
give it the output it crunches the

146
00:06:07,360 --> 00:06:11,520
information and it tells you the formula

147
00:06:09,560 --> 00:06:12,919
so this is really interesting in places

148
00:06:11,520 --> 00:06:15,479
where we don't know the formula

149
00:06:12,919 --> 00:06:18,800
ourselves we don't think there's

150
00:06:15,479 --> 00:06:20,280
complexity um or or there's things that

151
00:06:18,800 --> 00:06:21,800
we just don't understand right so this

152
00:06:20,280 --> 00:06:24,479
is how it works that's the main

153
00:06:21,800 --> 00:06:27,840
difference is that in a traditional

154
00:06:24,479 --> 00:06:29,880
computer system you write the formula

155
00:06:27,840 --> 00:06:32,840
and in a machine Learning System the

156
00:06:29,880 --> 00:06:35,639
formula is the actual output during

157
00:06:32,840 --> 00:06:37,840
training um the formula there's a lot of

158
00:06:35,639 --> 00:06:40,319
other terminology the formula is a

159
00:06:37,840 --> 00:06:42,240
pattern it's an algorithm it's a recipe

160
00:06:40,319 --> 00:06:45,000
um instructions in machine learning it's

161
00:06:42,240 --> 00:06:48,240
the actual model the term is the

162
00:06:45,000 --> 00:06:50,000
model now when it comes to deployment

163
00:06:48,240 --> 00:06:52,080
what ends up happening is you deploy

164
00:06:50,000 --> 00:06:55,520
this this software system on a computer

165
00:06:52,080 --> 00:06:57,800
your user inputs the puts the input in

166
00:06:55,520 --> 00:06:59,360
and gets an output now in machine

167
00:06:57,800 --> 00:07:01,400
learning deployment this is what we call

168
00:06:59,360 --> 00:07:03,599
in difference or prediction again you

169
00:07:01,400 --> 00:07:06,240
deploy this formula now that that that

170
00:07:03,599 --> 00:07:08,400
you got out of training you deploy that

171
00:07:06,240 --> 00:07:11,080
and you get an output so at deployment

172
00:07:08,400 --> 00:07:13,280
time um software and and machine

173
00:07:11,080 --> 00:07:16,039
Learning Systems look fairly

174
00:07:13,280 --> 00:07:17,759
similar uh but the difference mainly is

175
00:07:16,039 --> 00:07:20,319
at training

176
00:07:17,759 --> 00:07:22,479
time so how is it different from

177
00:07:20,319 --> 00:07:24,680
statistics there's a lot of people tend

178
00:07:22,479 --> 00:07:26,800
to confuse statistics and ml sometimes

179
00:07:24,680 --> 00:07:28,960
so let me tell you a little bit about uh

180
00:07:26,800 --> 00:07:30,840
the different types of analytics um we

181
00:07:28,960 --> 00:07:32,840
distinguish four types of analytics so

182
00:07:30,840 --> 00:07:35,319
there's descriptive analytics which

183
00:07:32,840 --> 00:07:38,720
explains what

184
00:07:35,319 --> 00:07:40,960
happened um there's diagnostic analytics

185
00:07:38,720 --> 00:07:42,639
which explains why it actually happened

186
00:07:40,960 --> 00:07:44,759
there's Predictive Analytics which

187
00:07:42,639 --> 00:07:46,599
describe which forecast what might

188
00:07:44,759 --> 00:07:48,639
happen in the future and prescriptive

189
00:07:46,599 --> 00:07:52,000
analytics which recommends action based

190
00:07:48,639 --> 00:07:55,199
on that predicted forecast and as you

191
00:07:52,000 --> 00:07:58,280
move through this to the right um

192
00:07:55,199 --> 00:08:00,199
there's there's more insight and

193
00:07:58,280 --> 00:08:02,080
foresight and

194
00:08:00,199 --> 00:08:05,000
so

195
00:08:02,080 --> 00:08:06,680
statistics really is at the different

196
00:08:05,000 --> 00:08:11,080
scale than machine learning is machine

197
00:08:06,680 --> 00:08:13,000
learning really um excels at prediction

198
00:08:11,080 --> 00:08:16,199
um and and

199
00:08:13,000 --> 00:08:16,199
foresight and

200
00:08:16,639 --> 00:08:22,720
so both statistics and machine learning

201
00:08:19,159 --> 00:08:25,080
are both part of the data set uh toolkit

202
00:08:22,720 --> 00:08:27,840
they both aim at defining mathematical

203
00:08:25,080 --> 00:08:30,840
representations of the real world uh

204
00:08:27,840 --> 00:08:32,640
which we call a model and um but

205
00:08:30,840 --> 00:08:34,000
statistics is more concerned with

206
00:08:32,640 --> 00:08:35,880
understanding population descriptions

207
00:08:34,000 --> 00:08:38,479
what is your mean what is your your

208
00:08:35,880 --> 00:08:40,560
variance uh what is your sample size how

209
00:08:38,479 --> 00:08:42,959
does the sample represent the bigger

210
00:08:40,560 --> 00:08:44,720
population things like that uh whereas

211
00:08:42,959 --> 00:08:47,600
ml is more concerned with predicting

212
00:08:44,720 --> 00:08:49,320
unseen data so more projecting based on

213
00:08:47,600 --> 00:08:52,760
the information I have today can I

214
00:08:49,320 --> 00:08:54,640
project later and so the machine

215
00:08:52,760 --> 00:08:57,160
learning superpow is really prediction

216
00:08:54,640 --> 00:08:59,000
it's using information you have you have

217
00:08:57,160 --> 00:09:01,040
to to predict information you do not

218
00:08:59,000 --> 00:09:03,920
have and the importance of that is

219
00:09:01,040 --> 00:09:06,360
really reducing uncertainty and being

220
00:09:03,920 --> 00:09:08,839
more prepared and so as humans I think

221
00:09:06,360 --> 00:09:11,600
we we have always had a fascination with

222
00:09:08,839 --> 00:09:13,720
prediction so I took Greek mythology and

223
00:09:11,600 --> 00:09:16,680
my in my undergrad and this is the

224
00:09:13,720 --> 00:09:19,360
Oracle of Deli which was one of the most

225
00:09:16,680 --> 00:09:21,519
famous Greek uh oracles and people would

226
00:09:19,360 --> 00:09:23,880
go in for predictions and there's a lot

227
00:09:21,519 --> 00:09:25,800
of stories of war in the ancient world

228
00:09:23,880 --> 00:09:29,920
that that were based on different

229
00:09:25,800 --> 00:09:31,959
predictions and I mean uh for tellers

230
00:09:29,920 --> 00:09:35,240
are forms of predictors although they

231
00:09:31,959 --> 00:09:36,880
they're a different backend um than ml

232
00:09:35,240 --> 00:09:40,560
but there is a Fascination there's a

233
00:09:36,880 --> 00:09:43,000
human fascination with

234
00:09:40,560 --> 00:09:46,160
prediction and so um I'll take you

235
00:09:43,000 --> 00:09:48,839
through some ml terminology um

236
00:09:46,160 --> 00:09:51,320
artificial intelligence or AI in the

237
00:09:48,839 --> 00:09:53,839
field um is defined as techniques that

238
00:09:51,320 --> 00:09:56,000
enable computers to mimic human behavior

239
00:09:53,839 --> 00:10:01,279
so these are things like robots these

240
00:09:56,000 --> 00:10:04,000
are things um that just allow systems to

241
00:10:01,279 --> 00:10:05,760
behave humanlike right so what is

242
00:10:04,000 --> 00:10:07,399
machine learning or ml these are AI

243
00:10:05,760 --> 00:10:09,000
techniques that allow computers to learn

244
00:10:07,399 --> 00:10:11,480
without explicit programming so these

245
00:10:09,000 --> 00:10:14,640
are specifically mimicking the learning

246
00:10:11,480 --> 00:10:16,360
capability of of humans and so you've

247
00:10:14,640 --> 00:10:19,200
got artificial intelligence which is the

248
00:10:16,360 --> 00:10:21,040
bigger uh bucket and machine learning is

249
00:10:19,200 --> 00:10:22,399
a subset of that so what is artificial

250
00:10:21,040 --> 00:10:23,480
intelligence that is not machine

251
00:10:22,399 --> 00:10:27,760
learning well there's things like

252
00:10:23,480 --> 00:10:31,920
robotics because robots mimic human uh

253
00:10:27,760 --> 00:10:33,480
motion uh and other aspects but they are

254
00:10:31,920 --> 00:10:37,279
uh code based or they're programmed

255
00:10:33,480 --> 00:10:39,800
specifically to do that um there's NLP

256
00:10:37,279 --> 00:10:41,959
syntax and semantics so NLP can be if

257
00:10:39,800 --> 00:10:46,320
it's based on

258
00:10:41,959 --> 00:10:47,720
um uh learning uh then it could be part

259
00:10:46,320 --> 00:10:50,680
of machine learning but there's a whole

260
00:10:47,720 --> 00:10:54,079
part of NLP that is really rule-based

261
00:10:50,680 --> 00:10:56,600
that is outside of uh machine

262
00:10:54,079 --> 00:10:58,839
learning deep learning is a subset of

263
00:10:56,600 --> 00:11:01,120
machine learning which uses multi-layer

264
00:10:58,839 --> 00:11:04,959
neuron metric is inspired by the human

265
00:11:01,120 --> 00:11:10,000
brain um and so again that's a subset of

266
00:11:04,959 --> 00:11:12,519
ml other algorithms that are not in this

267
00:11:10,000 --> 00:11:14,399
are for example svms logistic regression

268
00:11:12,519 --> 00:11:16,920
linear regression XG boost there's a

269
00:11:14,399 --> 00:11:19,320
whole lot of um different types of

270
00:11:16,920 --> 00:11:21,160
algorithms and we'll go through that in

271
00:11:19,320 --> 00:11:23,680
the second

272
00:11:21,160 --> 00:11:25,720
lecture generative AI is a type of AI

273
00:11:23,680 --> 00:11:27,839
that allows computers to generate new

274
00:11:25,720 --> 00:11:30,720
content and we'll see again across the

275
00:11:27,839 --> 00:11:33,880
series what that really means

276
00:11:30,720 --> 00:11:35,800
means um so the rise of ml I find this

277
00:11:33,880 --> 00:11:38,920
really interesting and and I I wanted to

278
00:11:35,800 --> 00:11:40,839
mention it so um the AI has been is a

279
00:11:38,920 --> 00:11:45,279
field that has been around for a really

280
00:11:40,839 --> 00:11:46,920
long time um these are the AI Godfathers

281
00:11:45,279 --> 00:11:49,600
what are known as the AI Godfathers

282
00:11:46,920 --> 00:11:52,920
there's uh Jeffrey Hinton yan yan Lon

283
00:11:49,600 --> 00:11:56,600
and yosua Benjo and they did their phds

284
00:11:52,920 --> 00:12:00,880
in the 70s and and 80s and 90s on uh

285
00:11:56,600 --> 00:12:04,920
machine learning they they um

286
00:12:00,880 --> 00:12:07,720
they have done a lot of work on uh the

287
00:12:04,920 --> 00:12:09,560
the Deep learning and and a lot of

288
00:12:07,720 --> 00:12:10,920
really uh cool techniques they've really

289
00:12:09,560 --> 00:12:14,160
revived the field that that's why

290
00:12:10,920 --> 00:12:17,040
they're called the AI uh Godfathers but

291
00:12:14,160 --> 00:12:21,320
the first papers the first academic

292
00:12:17,040 --> 00:12:25,320
papers on machine learning are as old as

293
00:12:21,320 --> 00:12:29,680
1940s right and so we've why did it take

294
00:12:25,320 --> 00:12:31,880
so long why has it been 80 years um that

295
00:12:29,680 --> 00:12:33,360
right now is super popular and there's a

296
00:12:31,880 --> 00:12:38,199
number of reasons so there's an increase

297
00:12:33,360 --> 00:12:40,360
in number of devices in data in in um

298
00:12:38,199 --> 00:12:42,480
just information uh there's an increase

299
00:12:40,360 --> 00:12:45,440
in computer speed in memory so now we

300
00:12:42,480 --> 00:12:48,920
have data we can process that data and

301
00:12:45,440 --> 00:12:50,959
there is an explosion of algorithms and

302
00:12:48,920 --> 00:12:54,079
mathematical

303
00:12:50,959 --> 00:12:55,959
models and there's increased demand for

304
00:12:54,079 --> 00:12:57,839
customized Solutions and Data drien

305
00:12:55,959 --> 00:13:01,959
Systems I think there's a realization of

306
00:12:57,839 --> 00:13:04,560
the potential power in data M ML and so

307
00:13:01,959 --> 00:13:06,440
if we look at this um the ml

308
00:13:04,560 --> 00:13:07,760
foundational pillars based on the

309
00:13:06,440 --> 00:13:11,160
definition I Told You So machine

310
00:13:07,760 --> 00:13:14,120
learning systems are really based on um

311
00:13:11,160 --> 00:13:18,480
data mathematical algorithms and uh

312
00:13:14,120 --> 00:13:22,720
computer systems and there has been a

313
00:13:18,480 --> 00:13:25,040
huge con a huge conversion and and an

314
00:13:22,720 --> 00:13:28,160
explosion of information across all

315
00:13:25,040 --> 00:13:30,320
these fields and and one of my my um one

316
00:13:28,160 --> 00:13:32,680
of the resources I really like is this

317
00:13:30,320 --> 00:13:35,320
McKenzie

318
00:13:32,680 --> 00:13:39,560
um uh diagram let me show it to you it's

319
00:13:35,320 --> 00:13:42,199
really cool um so if you look at yai and

320
00:13:39,560 --> 00:13:44,279
then they show you um some of the things

321
00:13:42,199 --> 00:13:46,720
that happen in the exposion of data so

322
00:13:44,279 --> 00:13:51,279
the N the opening of the internet in

323
00:13:46,720 --> 00:13:53,360
1991 has really um just exploded the

324
00:13:51,279 --> 00:13:57,399
amount of data that we have we bring

325
00:13:53,360 --> 00:13:59,519
tracked um across everything we do and

326
00:13:57,399 --> 00:14:00,759
so you can see here across all of the

327
00:13:59,519 --> 00:14:02,440
things that have happened and it's

328
00:14:00,759 --> 00:14:04,720
really interesting to to see that and

329
00:14:02,440 --> 00:14:06,560
I've I've played with this several times

330
00:14:04,720 --> 00:14:08,639
there's algorithmic advancements again

331
00:14:06,560 --> 00:14:11,959
you can see all of the things that some

332
00:14:08,639 --> 00:14:14,519
of the really major uh things that have

333
00:14:11,959 --> 00:14:15,920
um changed the field and then you've got

334
00:14:14,519 --> 00:14:21,279
increases in

335
00:14:15,920 --> 00:14:26,000
power and they all converge to here to

336
00:14:21,279 --> 00:14:27,680
2009 um with Andrew using gpus to train

337
00:14:26,000 --> 00:14:29,800
deep learning models and so on and you

338
00:14:27,680 --> 00:14:31,279
can look at this this is one of I really

339
00:14:29,800 --> 00:14:36,000
like this

340
00:14:31,279 --> 00:14:38,240
resource and so um yeah we're at an era

341
00:14:36,000 --> 00:14:39,759
where computers cheap there's a lot of

342
00:14:38,240 --> 00:14:41,279
smart people creating a lot of really

343
00:14:39,759 --> 00:14:45,560
cool algorithms and there's a lot of

344
00:14:41,279 --> 00:14:47,040
data so it's it's really um great uh for

345
00:14:45,560 --> 00:14:50,560
machine

346
00:14:47,040 --> 00:14:52,560
learning okay so when is MLA fit for

347
00:14:50,560 --> 00:14:55,399
your use case and what are some anti

348
00:14:52,560 --> 00:14:57,480
patterns um anytime there is data

349
00:14:55,399 --> 00:14:59,240
machine learning is a possible option

350
00:14:57,480 --> 00:15:02,560
right because it can learn patterns in

351
00:14:59,240 --> 00:15:04,560
the data it is a great fit though I tell

352
00:15:02,560 --> 00:15:07,040
my clients it's a it's an actually great

353
00:15:04,560 --> 00:15:09,920
fit a no-brainer when there's scales

354
00:15:07,040 --> 00:15:11,600
scale so if you because machines scale

355
00:15:09,920 --> 00:15:13,480
much much better than humans so if you

356
00:15:11,600 --> 00:15:16,480
have an operation you have you're

357
00:15:13,480 --> 00:15:22,120
running a company and you want to double

358
00:15:16,480 --> 00:15:24,320
your operations if you have um a system

359
00:15:22,120 --> 00:15:26,440
that is not based on machine learning

360
00:15:24,320 --> 00:15:29,240
for example you would have to hire

361
00:15:26,440 --> 00:15:31,839
double the people uh by double the death

362
00:15:29,240 --> 00:15:34,920
by by double the resources the space

363
00:15:31,839 --> 00:15:37,079
train um and so on whereas if this was a

364
00:15:34,920 --> 00:15:39,240
machine Learning System uh let's say on

365
00:15:37,079 --> 00:15:41,680
in the cloud then with a few clicks you

366
00:15:39,240 --> 00:15:43,800
could potentially double or triple or so

367
00:15:41,680 --> 00:15:46,040
on you could scale really well really

368
00:15:43,800 --> 00:15:49,959
fast so when there's scale machine

369
00:15:46,040 --> 00:15:52,079
learning is is uh is a great option when

370
00:15:49,959 --> 00:15:55,040
there's change

371
00:15:52,079 --> 00:15:57,160
because um we're now living in a global

372
00:15:55,040 --> 00:16:01,040
world it's an interconnected world and

373
00:15:57,160 --> 00:16:04,800
things change very fast and for us to um

374
00:16:01,040 --> 00:16:08,079
detect change and then uh try to

375
00:16:04,800 --> 00:16:11,959
understand it try to model it try to

376
00:16:08,079 --> 00:16:14,240
make um predictions out of it manually

377
00:16:11,959 --> 00:16:17,519
or or it's going to

378
00:16:14,240 --> 00:16:21,000
be things move so fast that we can't do

379
00:16:17,519 --> 00:16:24,079
that cycle efficiently but if we have an

380
00:16:21,000 --> 00:16:27,759
an mlof system uh then it can detect a

381
00:16:24,079 --> 00:16:30,240
change and and Trigger um uh training

382
00:16:27,759 --> 00:16:33,959
and and and deployment and so on so

383
00:16:30,240 --> 00:16:38,959
again with change um ML and mlops are a

384
00:16:33,959 --> 00:16:41,079
better uh solution than other options

385
00:16:38,959 --> 00:16:43,639
and in terms of complexity because when

386
00:16:41,079 --> 00:16:45,959
patterns are too complex to tease out uh

387
00:16:43,639 --> 00:16:48,319
machine learning shines in complexity

388
00:16:45,959 --> 00:16:50,279
and so when is it a great fit scale

389
00:16:48,319 --> 00:16:52,600
change and

390
00:16:50,279 --> 00:16:55,240
complexity when is it an anti pattern

391
00:16:52,600 --> 00:16:57,800
well um I used to say when you don't

392
00:16:55,240 --> 00:17:00,000
have enough data or bad quality data

393
00:16:57,800 --> 00:17:01,680
that is of course making the assumption

394
00:17:00,000 --> 00:17:03,839
that you want to train your own models

395
00:17:01,680 --> 00:17:05,760
today there's a lot of pre-trained

396
00:17:03,839 --> 00:17:07,360
models so you don't have to do that so

397
00:17:05,760 --> 00:17:09,760
if you do want to train your own model

398
00:17:07,360 --> 00:17:13,199
then data is definitely a prerequisite

399
00:17:09,760 --> 00:17:15,520
uh but you can use pre-trained models if

400
00:17:13,199 --> 00:17:17,199
if simpler Solutions exist and do the

401
00:17:15,520 --> 00:17:22,199
trick really well then you don't really

402
00:17:17,199 --> 00:17:24,160
need machine learning um there is a an

403
00:17:22,199 --> 00:17:27,079
onboarding cost right there there is a

404
00:17:24,160 --> 00:17:30,679
skill set required there is a setup

405
00:17:27,079 --> 00:17:33,039
required and so on so um if your systems

406
00:17:30,679 --> 00:17:34,720
work and they're fine maybe you don't

407
00:17:33,039 --> 00:17:37,640
need it and if it's not a cost-

408
00:17:34,720 --> 00:17:40,520
effective right um if you if you're

409
00:17:37,640 --> 00:17:42,679
using a system it should be cost-

410
00:17:40,520 --> 00:17:45,760
effective and there's a word of caution

411
00:17:42,679 --> 00:17:46,960
I wanted to say um in previous in the

412
00:17:45,760 --> 00:17:49,559
previous decade there was a lot of

413
00:17:46,960 --> 00:17:51,240
disappointment in machine learning uh

414
00:17:49,559 --> 00:17:53,400
because there I think there was a huge

415
00:17:51,240 --> 00:17:56,480
disconnect between the engineers on the

416
00:17:53,400 --> 00:17:58,559
ground that were uh optimizing for

417
00:17:56,480 --> 00:18:00,480
technical objectives and the business

418
00:17:58,559 --> 00:18:02,000
itself self which was looking at

419
00:18:00,480 --> 00:18:05,159
business goals and there was a there's a

420
00:18:02,000 --> 00:18:07,159
disconnect between um the actual

421
00:18:05,159 --> 00:18:10,679
technical objectives and the business

422
00:18:07,159 --> 00:18:12,039
needs uh because the engineers would

423
00:18:10,679 --> 00:18:13,679
optimize the objective function the

424
00:18:12,039 --> 00:18:16,000
model would work but it wouldn't be tied

425
00:18:13,679 --> 00:18:18,559
to the business and not created a bit of

426
00:18:16,000 --> 00:18:22,120
frustration and so if you are an ml

427
00:18:18,559 --> 00:18:24,960
engineer um ml serves the business so

428
00:18:22,120 --> 00:18:26,520
you need to connect you need to model

429
00:18:24,960 --> 00:18:28,480
your problem to serve the business and

430
00:18:26,520 --> 00:18:31,440
we'll talk a little bit more about that

431
00:18:28,480 --> 00:18:35,559
in in the life

432
00:18:31,440 --> 00:18:38,000
cycle um so this one this is about the

433
00:18:35,559 --> 00:18:41,039
automation life cycle so machine uh

434
00:18:38,000 --> 00:18:44,400
learning machine human interaction

435
00:18:41,039 --> 00:18:47,080
skills people assume that people are are

436
00:18:44,400 --> 00:18:49,240
sometimes scared uh about ml it doesn't

437
00:18:47,080 --> 00:18:51,880
have to be an all or none

438
00:18:49,240 --> 00:18:53,400
situation um there's different

439
00:18:51,880 --> 00:18:56,919
configurations that you can set up in

440
00:18:53,400 --> 00:18:58,799
your company so on one scale you've got

441
00:18:56,919 --> 00:19:00,960
the human only system so these are

442
00:18:58,799 --> 00:19:03,600
humans these are systems run fully by

443
00:19:00,960 --> 00:19:05,400
humans um on the very other end of the

444
00:19:03,600 --> 00:19:08,000
scale you've got systems that are fully

445
00:19:05,400 --> 00:19:10,640
run by machines right so there's full

446
00:19:08,000 --> 00:19:12,080
automation um and there's very very few

447
00:19:10,640 --> 00:19:14,720
systems I think in the world that do

448
00:19:12,080 --> 00:19:16,919
this very few companies uh that do this

449
00:19:14,720 --> 00:19:20,880
it's certainly not everybody uh although

450
00:19:16,919 --> 00:19:23,640
they you know we we um we try to set

451
00:19:20,880 --> 00:19:24,840
these system up but um again you don't

452
00:19:23,640 --> 00:19:27,360
have

453
00:19:24,840 --> 00:19:29,440
to um in the middle there's a whole

454
00:19:27,360 --> 00:19:31,480
spectrum of things so there's Shadow

455
00:19:29,440 --> 00:19:34,080
mode where the machine learning Shadows

456
00:19:31,480 --> 00:19:35,559
the human uh but its output is not used

457
00:19:34,080 --> 00:19:37,200
this could be done for compliance this

458
00:19:35,559 --> 00:19:39,000
could be done for training this can be

459
00:19:37,200 --> 00:19:42,200
done for different reasons for

460
00:19:39,000 --> 00:19:44,679
understanding systems um then you've got

461
00:19:42,200 --> 00:19:48,320
AI assistance where the human is the

462
00:19:44,679 --> 00:19:50,320
primary driver and then there's a uh

463
00:19:48,320 --> 00:19:52,919
machine Learning System that the human

464
00:19:50,320 --> 00:19:54,679
can tap into as required so these are

465
00:19:52,919 --> 00:19:57,039
people in call centers for example have

466
00:19:54,679 --> 00:19:59,159
an auxiliary system that helps them do

467
00:19:57,039 --> 00:20:01,919
their job fast and um different

468
00:19:59,159 --> 00:20:04,000
positions where we put an auxiliary

469
00:20:01,919 --> 00:20:06,320
system that helps the person but you're

470
00:20:04,000 --> 00:20:08,440
still interacting with a human

471
00:20:06,320 --> 00:20:10,960
first and then we've got partial

472
00:20:08,440 --> 00:20:13,159
automation where um the machine learning

473
00:20:10,960 --> 00:20:15,440
does the actual work um it is in the

474
00:20:13,159 --> 00:20:17,679
Forefront but then there's human gating

475
00:20:15,440 --> 00:20:20,960
and validation and approval so uh

476
00:20:17,679 --> 00:20:23,240
there's some sort of control by humans

477
00:20:20,960 --> 00:20:24,919
and ml is an inter iterative and

478
00:20:23,240 --> 00:20:26,640
experimental process towards maturity so

479
00:20:24,919 --> 00:20:28,320
you start early and you keep iterating

480
00:20:26,640 --> 00:20:30,400
towards the system that you are

481
00:20:28,320 --> 00:20:31,840
comfortable with and I always tell

482
00:20:30,400 --> 00:20:33,720
clients that you know if you wait for

483
00:20:31,840 --> 00:20:35,520
technology to prove its worth for the

484
00:20:33,720 --> 00:20:37,240
rest of the industry before you jump in

485
00:20:35,520 --> 00:20:40,880
then you might be playing catchup for a

486
00:20:37,240 --> 00:20:42,640
really long time right so um stay up to

487
00:20:40,880 --> 00:20:46,400
date with new technology try to to

488
00:20:42,640 --> 00:20:49,240
dabble into it and and just to at least

489
00:20:46,400 --> 00:20:51,880
be aware of what's going on in the

490
00:20:49,240 --> 00:20:56,200
field okay so the machine learning life

491
00:20:51,880 --> 00:20:58,960
cycle um this is my five petal flower

492
00:20:56,200 --> 00:21:00,600
that I've Illustrated uh so always we

493
00:20:58,960 --> 00:21:02,679
start with the business again Tech

494
00:21:00,600 --> 00:21:05,120
serves the business we start from

495
00:21:02,679 --> 00:21:08,080
business needs we identify the goals we

496
00:21:05,120 --> 00:21:10,039
frame the problem we choose the metrics

497
00:21:08,080 --> 00:21:12,159
and plan the process we come into the

498
00:21:10,039 --> 00:21:15,080
data so we collect we explore we

499
00:21:12,159 --> 00:21:17,640
transform then we go into the model

500
00:21:15,080 --> 00:21:20,080
domain we choose our model we train it

501
00:21:17,640 --> 00:21:24,400
we evaluate it we optimize it and then

502
00:21:20,080 --> 00:21:28,080
we deploy it and then uh we mon we uh

503
00:21:24,400 --> 00:21:31,159
maintain it and monitor it and so so um

504
00:21:28,080 --> 00:21:33,760
some interesting um steps there so the

505
00:21:31,159 --> 00:21:37,520
most important one I think uh is really

506
00:21:33,760 --> 00:21:39,720
defining and framing the problem and so

507
00:21:37,520 --> 00:21:43,159
what this means is that again the

508
00:21:39,720 --> 00:21:45,240
business has a goal a business goal and

509
00:21:43,159 --> 00:21:47,200
there's a million ways that that

510
00:21:45,240 --> 00:21:49,600
business goal can be transposed into

511
00:21:47,200 --> 00:21:52,880
mathematical space right what is the

512
00:21:49,600 --> 00:21:54,880
proxy um what me metrics proxy that

513
00:21:52,880 --> 00:21:56,679
business goal what does it mean in

514
00:21:54,880 --> 00:21:58,679
mathematical representation so that's

515
00:21:56,679 --> 00:22:00,679
called framing the problem and and

516
00:21:58,679 --> 00:22:03,000
that's probably one of the most

517
00:22:00,679 --> 00:22:05,960
important steps I would say uh when

518
00:22:03,000 --> 00:22:07,840
you're an ml engineer is to really

519
00:22:05,960 --> 00:22:10,120
understand the business goal and

520
00:22:07,840 --> 00:22:12,559
formulate it in mathematical

521
00:22:10,120 --> 00:22:16,400
terms then there's the data preparation

522
00:22:12,559 --> 00:22:18,679
phase the model phase the deployment and

523
00:22:16,400 --> 00:22:18,679
the

524
00:22:18,720 --> 00:22:24,840
operations so

525
00:22:21,480 --> 00:22:27,880
um I I'm a great fan of AWS but again

526
00:22:24,840 --> 00:22:30,480
this works um pretty similarly in most

527
00:22:27,880 --> 00:22:33,440
clubs what I want to show you is that

528
00:22:30,480 --> 00:22:36,039
these clouds um they provide services to

529
00:22:33,440 --> 00:22:38,279
different personas this is a fairly old

530
00:22:36,039 --> 00:22:39,480
uh representation so all of the a lot of

531
00:22:38,279 --> 00:22:41,640
the services they have a lot more

532
00:22:39,480 --> 00:22:42,720
services now uh but I just want to show

533
00:22:41,640 --> 00:22:46,440
you the

534
00:22:42,720 --> 00:22:50,480
layering and so at the bottom oops

535
00:22:46,440 --> 00:22:54,200
oops at the bottom here um we've got

536
00:22:50,480 --> 00:22:58,080
Frameworks uh these are chips these are

537
00:22:54,200 --> 00:23:00,320
uh base libraries that people can use um

538
00:22:58,080 --> 00:23:02,520
so this these are systems that an ml

539
00:23:00,320 --> 00:23:05,159
engineer would use to build from scratch

540
00:23:02,520 --> 00:23:07,320
but not everybody would need that um

541
00:23:05,159 --> 00:23:10,400
above that they have a layer which is a

542
00:23:07,320 --> 00:23:13,600
little bit more abstracted so um this is

543
00:23:10,400 --> 00:23:16,279
these say J maker for example has um a

544
00:23:13,600 --> 00:23:18,159
lot of abstracted capabilities for you

545
00:23:16,279 --> 00:23:22,200
this is for example where a data

546
00:23:18,159 --> 00:23:26,080
scientist uh might Thrive above that

547
00:23:22,200 --> 00:23:29,640
they have a a layer of uh pre-trained

548
00:23:26,080 --> 00:23:32,400
models so ml as a

549
00:23:29,640 --> 00:23:34,320
as a service and um this is for

550
00:23:32,400 --> 00:23:37,039
everybody it's an API call that you can

551
00:23:34,320 --> 00:23:39,559
make and these are models that uh the

552
00:23:37,039 --> 00:23:41,240
provide the AWS for

553
00:23:39,559 --> 00:23:43,960
example

554
00:23:41,240 --> 00:23:46,159
maintains and so as you go up the scale

555
00:23:43,960 --> 00:23:48,640
there's an abstraction uh so there's

556
00:23:46,159 --> 00:23:51,440
ease of use but then as you go down

557
00:23:48,640 --> 00:23:53,000
there's a lot more control and so if uh

558
00:23:51,440 --> 00:23:55,200
you're interested in machine learning

559
00:23:53,000 --> 00:23:57,840
wherever you are in that Spectrum there

560
00:23:55,200 --> 00:24:00,799
is a tool for you um and so you just

561
00:23:57,840 --> 00:24:04,000
need to just identify where you are here

562
00:24:00,799 --> 00:24:07,799
and and look um

563
00:24:04,000 --> 00:24:09,360
there this is true for generative AI as

564
00:24:07,799 --> 00:24:11,320
well it's the same stack so at the

565
00:24:09,360 --> 00:24:13,240
bottom you've got your infrastructure on

566
00:24:11,320 --> 00:24:16,240
the top you've got your platforms and

567
00:24:13,240 --> 00:24:19,400
then uh on the very top you've got your

568
00:24:16,240 --> 00:24:19,400
uh SAS

569
00:24:19,559 --> 00:24:25,159
models and uh this is my last slide so

570
00:24:22,760 --> 00:24:26,880
this is the brains versus Bots uh this

571
00:24:25,159 --> 00:24:30,880
is an article that I had wrote

572
00:24:26,880 --> 00:24:32,440
previously about comparing hum and uh

573
00:24:30,880 --> 00:24:35,960
artificial

574
00:24:32,440 --> 00:24:38,799
intelligence um

575
00:24:35,960 --> 00:24:40,039
so they're both predictive machines

576
00:24:38,799 --> 00:24:43,360
right so I told you through this

577
00:24:40,039 --> 00:24:45,600
presentation that uh machine learning is

578
00:24:43,360 --> 00:24:49,399
uh the the main power is predictive

579
00:24:45,600 --> 00:24:51,919
power um it's interesting that brains

580
00:24:49,399 --> 00:24:54,640
are also predictive I think that caught

581
00:24:51,919 --> 00:24:57,039
neuroscientist by surprise

582
00:24:54,640 --> 00:24:58,960
um there's a lot of evidence today that

583
00:24:57,039 --> 00:25:01,200
the brain predicts

584
00:24:58,960 --> 00:25:04,640
uh actions before they happen so when

585
00:25:01,200 --> 00:25:07,399
you drink water for example uh you get

586
00:25:04,640 --> 00:25:10,159
uh satiated before the water hits your

587
00:25:07,399 --> 00:25:11,679
stomach right or or travels through your

588
00:25:10,159 --> 00:25:12,919
system and and that's a prediction from

589
00:25:11,679 --> 00:25:14,520
your brain that your system is going to

590
00:25:12,919 --> 00:25:17,720
go through homeostasis right so there's

591
00:25:14,520 --> 00:25:19,039
a predictive capability um and and that

592
00:25:17,720 --> 00:25:20,520
makes sense right and and there's a lot

593
00:25:19,039 --> 00:25:23,039
of examples about this and it makes

594
00:25:20,520 --> 00:25:26,760
sense because an ancestor who would have

595
00:25:23,039 --> 00:25:28,880
waited to react would have been eaten um

596
00:25:26,760 --> 00:25:31,760
and not survived and so

597
00:25:28,880 --> 00:25:34,799
um it's interesting I I I when I learned

598
00:25:31,760 --> 00:25:36,720
this it was um I was a little surprised

599
00:25:34,799 --> 00:25:38,679
I must say but there's a lot of um

600
00:25:36,720 --> 00:25:43,000
evidence today to support

601
00:25:38,679 --> 00:25:46,279
this in terms of counts or or size um of

602
00:25:43,000 --> 00:25:49,880
course uh brains uh the main processing

603
00:25:46,279 --> 00:25:52,320
unit of the brain is the neuron um we

604
00:25:49,880 --> 00:25:55,399
can look at synapses which is which are

605
00:25:52,320 --> 00:25:58,640
the neuron neuron to neuron connection

606
00:25:55,399 --> 00:26:01,600
um and there's about 100 trillion sign

607
00:25:58,640 --> 00:26:04,679
in the brain the equivalent to that in

608
00:26:01,600 --> 00:26:07,000
the Bots are parameters or weights um

609
00:26:04,679 --> 00:26:08,919
and today there's about two trillion in

610
00:26:07,000 --> 00:26:11,520
the state of the-art models roughly

611
00:26:08,919 --> 00:26:12,559
about 1.8 but I'm I'm averaging to to

612
00:26:11,520 --> 00:26:15,000
roughly two

613
00:26:12,559 --> 00:26:16,520
trillions and so brains are still about

614
00:26:15,000 --> 00:26:18,080
50 times more

615
00:26:16,520 --> 00:26:22,919
interconnected

616
00:26:18,080 --> 00:26:26,039
um than any of our models and the brain

617
00:26:22,919 --> 00:26:26,960
is still a lot better at integrating

618
00:26:26,039 --> 00:26:29,960
data

619
00:26:26,960 --> 00:26:34,360
holistically um we have been evolving

620
00:26:29,960 --> 00:26:36,960
for about 300,000 years and so we um

621
00:26:34,360 --> 00:26:40,200
handle information still a lot better

622
00:26:36,960 --> 00:26:41,600
than models do so in terms of winner the

623
00:26:40,200 --> 00:26:45,279
brain is the winner

624
00:26:41,600 --> 00:26:47,640
here in terms of training time again uh

625
00:26:45,279 --> 00:26:53,320
the brain has been evolving for 300,000

626
00:26:47,640 --> 00:26:56,559
years um and your own um well there's

627
00:26:53,320 --> 00:26:59,440
typo here but your own instance has been

628
00:26:56,559 --> 00:27:03,919
fine-tuning for the L length of your own

629
00:26:59,440 --> 00:27:06,679
age right um Bots however are a lot

630
00:27:03,919 --> 00:27:08,520
younger so I just told you the field is

631
00:27:06,679 --> 00:27:12,440
about 80 years old and in started in

632
00:27:08,520 --> 00:27:15,320
1940s so let's say about 100 but it is a

633
00:27:12,440 --> 00:27:17,000
product of human Ingenuity right um

634
00:27:15,320 --> 00:27:22,240
there's a lot of

635
00:27:17,000 --> 00:27:25,039
effort that um is being dumped

636
00:27:22,240 --> 00:27:26,520
into uh artificial intelligence there's

637
00:27:25,039 --> 00:27:29,600
a lot of money going there there's a lot

638
00:27:26,520 --> 00:27:31,640
of interest and so um um so the Bots

639
00:27:29,600 --> 00:27:34,600
have had a lot less time in terms of

640
00:27:31,640 --> 00:27:38,039
training time machines have a way to go

641
00:27:34,600 --> 00:27:40,279
still to um catch up with the brain so

642
00:27:38,039 --> 00:27:42,960
the brain wins but not I assume in

643
00:27:40,279 --> 00:27:44,039
another few decades this would not be

644
00:27:42,960 --> 00:27:48,519
the

645
00:27:44,039 --> 00:27:50,559
case um speed again brains uh depend on

646
00:27:48,519 --> 00:27:53,240
neurotransmitters diffusing through

647
00:27:50,559 --> 00:27:56,440
liquids so these are

648
00:27:53,240 --> 00:27:59,159
the neurotransmitters that are used to

649
00:27:56,440 --> 00:28:02,519
communicate and that's estimated at

650
00:27:59,159 --> 00:28:05,440
about let's say 200 Herz um Bots depend

651
00:28:02,519 --> 00:28:08,200
on electrons running through transistors

652
00:28:05,440 --> 00:28:11,240
and today CPU clock rate is about is

653
00:28:08,200 --> 00:28:13,640
over 10 gahz right so Bots are about 50

654
00:28:11,240 --> 00:28:15,279
times faster than brains are or could

655
00:28:13,640 --> 00:28:18,880
ever

656
00:28:15,279 --> 00:28:21,919
be in terms of input modalities um we

657
00:28:18,880 --> 00:28:26,480
are Tethered to biology our brain gets

658
00:28:21,919 --> 00:28:28,240
um input input through our five senses

659
00:28:26,480 --> 00:28:30,720
uh whereas

660
00:28:28,240 --> 00:28:35,080
Bots have unlimited input streams so if

661
00:28:30,720 --> 00:28:37,519
you've ever built an Arduino um or or

662
00:28:35,080 --> 00:28:40,519
you know any particular system you can

663
00:28:37,519 --> 00:28:42,120
buy tons and tons of different um iot

664
00:28:40,519 --> 00:28:43,440
devices and input devices that you can

665
00:28:42,120 --> 00:28:45,919
add through the systems and you can

666
00:28:43,440 --> 00:28:48,279
figure out how to process that data so

667
00:28:45,919 --> 00:28:50,760
Bots have unlimited in input streams

668
00:28:48,279 --> 00:28:54,240
which we cannot

669
00:28:50,760 --> 00:28:57,679
match and so machine Learning Systems

670
00:28:54,240 --> 00:28:58,559
have huge potential uh because of their

671
00:28:57,679 --> 00:29:00,919
speed

672
00:28:58,559 --> 00:29:04,120
and augmentation capability so the fact

673
00:29:00,919 --> 00:29:06,679
that we are Tethered to biology kind of

674
00:29:04,120 --> 00:29:11,760
um gives us the short end of the stick

675
00:29:06,679 --> 00:29:13,679
here uh so there I it is no surprise

676
00:29:11,760 --> 00:29:18,279
that AI will be the Workhorse of the

677
00:29:13,679 --> 00:29:21,240
future so I suggest everybody learns

678
00:29:18,279 --> 00:29:24,159
ML and these are some of the resources

679
00:29:21,240 --> 00:29:25,399
um that I've used along my way getting

680
00:29:24,159 --> 00:29:27,760
into the field I've been in the field

681
00:29:25,399 --> 00:29:30,159
since 2012 uh so I put them here I'm

682
00:29:27,760 --> 00:29:33,200
really ing uh these notes as well so you

683
00:29:30,159 --> 00:29:36,880
could be able to click through these and

684
00:29:33,200 --> 00:29:38,600
that's it so this is ml12 so this is

685
00:29:36,880 --> 00:29:39,760
machine learning under the hood so what

686
00:29:38,600 --> 00:29:43,159
we're going to do is we're going to

687
00:29:39,760 --> 00:29:46,679
delve a little bit further into models

688
00:29:43,159 --> 00:29:48,240
and so on um again not too deep or not

689
00:29:46,679 --> 00:29:51,880
too technical but a lot of people say

690
00:29:48,240 --> 00:29:53,720
well what's happening um a little deeper

691
00:29:51,880 --> 00:29:58,360
and so I'm going to take you one

692
00:29:53,720 --> 00:29:59,799
level uh down and so um I'm going to

693
00:29:58,360 --> 00:30:02,679
start with the types of machine learning

694
00:29:59,799 --> 00:30:06,120
so there's different types or categories

695
00:30:02,679 --> 00:30:08,159
of machine learning and um right now the

696
00:30:06,120 --> 00:30:10,200
the the major classification is four

697
00:30:08,159 --> 00:30:12,679
different types so there's supervised

698
00:30:10,200 --> 00:30:16,679
learning this is when the model

699
00:30:12,679 --> 00:30:19,080
learns um from data with labels so we

700
00:30:16,679 --> 00:30:21,880
already know what the right solution is

701
00:30:19,080 --> 00:30:24,480
and the model tends to mimic that

702
00:30:21,880 --> 00:30:26,600
unsupervised learning is when the model

703
00:30:24,480 --> 00:30:28,519
learns from data without labels so we do

704
00:30:26,600 --> 00:30:30,720
not know what the right answer is and

705
00:30:28,519 --> 00:30:32,559
then the model tries to make some sense

706
00:30:30,720 --> 00:30:36,360
or some pattern in the

707
00:30:32,559 --> 00:30:38,679
data reinforcement learning is um a type

708
00:30:36,360 --> 00:30:43,039
of machine learning which um solves

709
00:30:38,679 --> 00:30:47,679
multi-step problems uh by maximizing a

710
00:30:43,039 --> 00:30:51,279
reward function and generative AI um are

711
00:30:47,679 --> 00:30:53,960
models that generate new content and if

712
00:30:51,279 --> 00:30:56,200
you read a machine learning book before

713
00:30:53,960 --> 00:30:58,720
November

714
00:30:56,200 --> 00:31:03,080
2022 um you wouldn't have seen the

715
00:30:58,720 --> 00:31:04,279
fourth type so before November 2022 most

716
00:31:03,080 --> 00:31:06,279
books would have told you there's three

717
00:31:04,279 --> 00:31:09,120
types of machine learning supervised on

718
00:31:06,279 --> 00:31:12,840
supervis and reinforcement learning in

719
00:31:09,120 --> 00:31:17,320
November 2022 open AI released chbt to

720
00:31:12,840 --> 00:31:19,919
the public and of course it caught fire

721
00:31:17,320 --> 00:31:23,320
and since then um I think everything we

722
00:31:19,919 --> 00:31:25,519
can hear of of is J ji so again if

723
00:31:23,320 --> 00:31:29,440
you're reading older res sources you

724
00:31:25,519 --> 00:31:33,880
would not see that now um

725
00:31:29,440 --> 00:31:38,320
what the the the terminology that I'm

726
00:31:33,880 --> 00:31:41,559
going to use um for the three um classes

727
00:31:38,320 --> 00:31:44,080
of ml uh that are not gen is predictive

728
00:31:41,559 --> 00:31:47,519
ml or classical ml some people call it

729
00:31:44,080 --> 00:31:51,080
traditional ml or um and then gen so I'm

730
00:31:47,519 --> 00:31:54,399
going to call them predictive ML and

731
00:31:51,080 --> 00:31:56,519
gen and you have to remember that um AI

732
00:31:54,399 --> 00:31:58,279
or ml are is really a set of tools it's

733
00:31:56,519 --> 00:32:01,360
a toolkit

734
00:31:58,279 --> 00:32:05,080
that um solves problems it it's a

735
00:32:01,360 --> 00:32:07,799
general purpose technology Andrew Ang um

736
00:32:05,080 --> 00:32:09,240
always says it it's it's electricity

737
00:32:07,799 --> 00:32:10,799
right it's the new age

738
00:32:09,240 --> 00:32:15,720
electricity

739
00:32:10,799 --> 00:32:18,880
um and it is what it is really is um

740
00:32:15,720 --> 00:32:18,880
mapping input to

741
00:32:19,360 --> 00:32:25,120
Output um and the last decade was a lot

742
00:32:23,000 --> 00:32:27,240
about optimizing supervised learning so

743
00:32:25,120 --> 00:32:29,240
if you were you if you've been in the

744
00:32:27,240 --> 00:32:31,080
field for really long time like I have

745
00:32:29,240 --> 00:32:34,279
it was really a lot about supervised

746
00:32:31,080 --> 00:32:38,039
learning we had a deep learning boom a

747
00:32:34,279 --> 00:32:40,120
decade ago um and now it's all about gen

748
00:32:38,039 --> 00:32:45,480
so the prediction is that this decade is

749
00:32:40,120 --> 00:32:47,880
more about gen and um one interesting

750
00:32:45,480 --> 00:32:50,519
thing that I wanted to mention is that

751
00:32:47,880 --> 00:32:52,080
um if a model is small and we we'll see

752
00:32:50,519 --> 00:32:54,519
what that means what does it mean for a

753
00:32:52,080 --> 00:32:55,559
model that is small but let's say if a

754
00:32:54,519 --> 00:32:58,360
model is

755
00:32:55,559 --> 00:33:00,159
small what increasing amount of the data

756
00:32:58,360 --> 00:33:02,200
will eventually Plateau performance

757
00:33:00,159 --> 00:33:05,039
because we say the model overfits which

758
00:33:02,200 --> 00:33:07,159
means it memorizes the data what we're

759
00:33:05,039 --> 00:33:09,159
saying and this was true for supervised

760
00:33:07,159 --> 00:33:11,600
learning we were that was something we

761
00:33:09,159 --> 00:33:13,159
really watched out for that is not true

762
00:33:11,600 --> 00:33:16,399
for generative AI we're not seeing

763
00:33:13,159 --> 00:33:17,799
overfitting for generative AI yet and so

764
00:33:16,399 --> 00:33:19,679
the more data we give it the better

765
00:33:17,799 --> 00:33:23,240
performance so there's a huge difference

766
00:33:19,679 --> 00:33:27,200
in performance between um supervised

767
00:33:23,240 --> 00:33:29,679
learning uh and generative AI in that uh

768
00:33:27,200 --> 00:33:31,840
we are not seeing overfitting yet and

769
00:33:29,679 --> 00:33:34,880
and that's partly because these models

770
00:33:31,840 --> 00:33:36,559
are are huge and so the amount of data

771
00:33:34,880 --> 00:33:39,200
that it would take them to overfit is

772
00:33:36,559 --> 00:33:42,159
probably quite usual we're not there

773
00:33:39,200 --> 00:33:47,200
yet okay so let's let's take a step back

774
00:33:42,159 --> 00:33:49,799
what is a model and um and so again like

775
00:33:47,200 --> 00:33:51,320
I told you uh before a model is a

776
00:33:49,799 --> 00:33:54,880
mathematical representation of a real

777
00:33:51,320 --> 00:33:56,600
world system right uh it's a model it's

778
00:33:54,880 --> 00:33:58,919
an algorithm it's a formula it's a

779
00:33:56,600 --> 00:34:03,000
pattern um mathematically it's an

780
00:33:58,919 --> 00:34:04,399
equation um and the way I think of them

781
00:34:03,000 --> 00:34:06,360
is machine learning models are really

782
00:34:04,399 --> 00:34:08,839
big statistical calculators right is

783
00:34:06,360 --> 00:34:10,960
just playing with numbers uh and tuning

784
00:34:08,839 --> 00:34:15,879
them the right

785
00:34:10,960 --> 00:34:17,919
way model components um there are these

786
00:34:15,879 --> 00:34:19,159
are what we mathematically represent

787
00:34:17,919 --> 00:34:21,919
things again we're not going to go into

788
00:34:19,159 --> 00:34:23,839
too too much technical detail but um

789
00:34:21,919 --> 00:34:27,359
it's just good to to know some of these

790
00:34:23,839 --> 00:34:28,839
things so the Y is um the class to be

791
00:34:27,359 --> 00:34:31,879
predicted this is what we're trying to

792
00:34:28,839 --> 00:34:34,159
predict it will be the model output what

793
00:34:31,879 --> 00:34:35,839
we call X is the input data so these are

794
00:34:34,159 --> 00:34:38,560
also called the features so this is the

795
00:34:35,839 --> 00:34:43,240
information that uh the model will take

796
00:34:38,560 --> 00:34:46,760
in to predict the model output the

797
00:34:43,240 --> 00:34:49,079
parameters or the weights um are tunable

798
00:34:46,760 --> 00:34:52,760
numbers in the model that encode the

799
00:34:49,079 --> 00:34:55,480
learning so uh we'll see some

800
00:34:52,760 --> 00:34:56,599
formulas and of course uh what really

801
00:34:55,480 --> 00:34:58,440
matters as well is the model

802
00:34:56,599 --> 00:35:00,400
architecture class so this is the actual

803
00:34:58,440 --> 00:35:04,000
formula or equation and we'll we'll see

804
00:35:00,400 --> 00:35:06,000
a couple and so the model class uh

805
00:35:04,000 --> 00:35:09,800
defines the mathematical formula use so

806
00:35:06,000 --> 00:35:12,760
for example a linear regression uh class

807
00:35:09,800 --> 00:35:15,119
uses a formula in the shape of yal ax

808
00:35:12,760 --> 00:35:16,440
plus b where Y is of course the the

809
00:35:15,119 --> 00:35:19,000
output class this is what we're trying

810
00:35:16,440 --> 00:35:21,960
to predict X is the input features this

811
00:35:19,000 --> 00:35:25,640
is what we are what the the information

812
00:35:21,960 --> 00:35:27,119
we have and a and b are the parameters

813
00:35:25,640 --> 00:35:29,040
so these are the weights and what will

814
00:35:27,119 --> 00:35:32,040
happen we'll see an example of this what

815
00:35:29,040 --> 00:35:35,359
will happen is that the model will try

816
00:35:32,040 --> 00:35:39,160
to find the right values of A and B

817
00:35:35,359 --> 00:35:41,160
where if given X it can predict y right

818
00:35:39,160 --> 00:35:42,640
and this in in this way the way I've

819
00:35:41,160 --> 00:35:45,480
written it here it looks like this is a

820
00:35:42,640 --> 00:35:48,440
single column and it it could be uh but

821
00:35:45,480 --> 00:35:50,800
in reality this is a this is a series of

822
00:35:48,440 --> 00:35:53,599
columns so this this would be a

823
00:35:50,800 --> 00:35:55,760
vector and so it would be y equals if I

824
00:35:53,599 --> 00:36:01,480
would expand it out it would be yal A1

825
00:35:55,760 --> 00:36:05,280
X1 plus A2 X2 plus so on a A anxn plus b

826
00:36:01,480 --> 00:36:07,599
okay um another example so if logistic

827
00:36:05,280 --> 00:36:12,880
regression for example this this um ends

828
00:36:07,599 --> 00:36:15,760
up this is used when y um is continuous

829
00:36:12,880 --> 00:36:18,079
a logistic regression is used when Y is

830
00:36:15,760 --> 00:36:19,480
discrete um and again if you don't know

831
00:36:18,079 --> 00:36:21,119
what these are don't don't worry about

832
00:36:19,480 --> 00:36:22,520
it um I'm just trying to show you a

833
00:36:21,119 --> 00:36:25,280
little bit under the hood it's not

834
00:36:22,520 --> 00:36:28,240
necessary for the rest of the exercises

835
00:36:25,280 --> 00:36:30,119
but um just in case you are interested

836
00:36:28,240 --> 00:36:32,040
so a logistic regression is you take the

837
00:36:30,119 --> 00:36:33,480
linear regression model and you you pass

838
00:36:32,040 --> 00:36:35,079
it through a sigo function which is an

839
00:36:33,480 --> 00:36:37,160
activation function again if you don't

840
00:36:35,079 --> 00:36:38,920
know what that is you don't really need

841
00:36:37,160 --> 00:36:41,480
to but the idea is to show you that

842
00:36:38,920 --> 00:36:43,960
underneath these systems is an actual

843
00:36:41,480 --> 00:36:45,880
mathematical equation right and this is

844
00:36:43,960 --> 00:36:48,119
the simplest one so I put these here

845
00:36:45,880 --> 00:36:50,560
because they are the simplest ones but

846
00:36:48,119 --> 00:36:52,240
as models become too big the exact

847
00:36:50,560 --> 00:36:54,480
mathematical equation becomes too

848
00:36:52,240 --> 00:36:57,160
complex and so we visualize their

849
00:36:54,480 --> 00:36:59,520
architecture with abstract diagrams okay

850
00:36:57,160 --> 00:37:01,480
and we'll see a couple of these but at

851
00:36:59,520 --> 00:37:03,440
again at the heart of it is a

852
00:37:01,480 --> 00:37:05,280
mathematical

853
00:37:03,440 --> 00:37:06,720
equation and so these are some of the

854
00:37:05,280 --> 00:37:08,520
types of algorithms we've got linear

855
00:37:06,720 --> 00:37:12,560
regression logistic regression decision

856
00:37:08,520 --> 00:37:16,640
trees random Forest naive Bays um

857
00:37:12,560 --> 00:37:19,000
support Vector machines svms neural Nets

858
00:37:16,640 --> 00:37:21,119
um these blue ones are for unsupervised

859
00:37:19,000 --> 00:37:23,640
learning so nearest neighbor uh

860
00:37:21,119 --> 00:37:27,599
clustering and and some dimensionality

861
00:37:23,640 --> 00:37:31,880
reduction again um this is a lot of what

862
00:37:27,599 --> 00:37:34,000
what predictive ml was um concerned with

863
00:37:31,880 --> 00:37:35,720
is choosing the right class of model

864
00:37:34,000 --> 00:37:38,040
understanding what these models do what

865
00:37:35,720 --> 00:37:40,480
is the equation underlying them where

866
00:37:38,040 --> 00:37:43,680
does it Excel when do I use it how do I

867
00:37:40,480 --> 00:37:47,960
optimize it this is not so much this is

868
00:37:43,680 --> 00:37:50,119
not true of course for Gen but um I'm

869
00:37:47,960 --> 00:37:52,240
just want wanted to show you if we peel

870
00:37:50,119 --> 00:37:54,760
one layer up so we're not going to go

871
00:37:52,240 --> 00:37:56,640
into these um I just I'm using them as

872
00:37:54,760 --> 00:37:59,040
an example to explain to you what

873
00:37:56,640 --> 00:38:01,599
parameters are hyper parameters and so

874
00:37:59,040 --> 00:38:04,119
on I do want to go a little bit into

875
00:38:01,599 --> 00:38:07,079
deep learning or neuron lets because

876
00:38:04,119 --> 00:38:10,079
they are the underlying foundation for a

877
00:38:07,079 --> 00:38:14,240
lot of things including CH so deep

878
00:38:10,079 --> 00:38:15,240
learning um the human brain is made of

879
00:38:14,240 --> 00:38:18,839
different

880
00:38:15,240 --> 00:38:21,880
layers six layers to be exact of neurons

881
00:38:18,839 --> 00:38:23,680
that are stacked um and the way the

882
00:38:21,880 --> 00:38:27,640
human brain works is that neurons

883
00:38:23,680 --> 00:38:29,800
interconnect with each other um and

884
00:38:27,640 --> 00:38:31,720
there's a lot of there's thousands and

885
00:38:29,800 --> 00:38:37,079
thousands of connections per

886
00:38:31,720 --> 00:38:40,440
neuron and this is a um an image from

887
00:38:37,079 --> 00:38:42,280
Ramon kahal the neuro the the father of

888
00:38:40,440 --> 00:38:44,160
Neuroscience um and you can see the

889
00:38:42,280 --> 00:38:46,400
layer of neurons so this is a layer and

890
00:38:44,160 --> 00:38:50,839
this is a layer and how they

891
00:38:46,400 --> 00:38:53,040
interconnect and so um neural Nets

892
00:38:50,839 --> 00:38:56,520
artificial neural networks what they try

893
00:38:53,040 --> 00:38:59,839
to do is mimic that behavior and so what

894
00:38:56,520 --> 00:39:01,760
you've got here is um a neuron this is a

895
00:38:59,839 --> 00:39:04,680
processing unit this is a at its heart

896
00:39:01,760 --> 00:39:06,359
is a logistic regression function and we

897
00:39:04,680 --> 00:39:08,440
stack them so there's a layer here this

898
00:39:06,359 --> 00:39:10,119
is the input layer and then we've got

899
00:39:08,440 --> 00:39:11,839
another layer so you think of them as

900
00:39:10,119 --> 00:39:13,280
you've got layers and layers and layers

901
00:39:11,839 --> 00:39:15,319
and this is it you've got layers and

902
00:39:13,280 --> 00:39:17,079
layers and layers and this is the first

903
00:39:15,319 --> 00:39:18,839
one is called the input layer the last

904
00:39:17,079 --> 00:39:20,560
one is called the output layer and

905
00:39:18,839 --> 00:39:23,640
everything in between is called a hidden

906
00:39:20,560 --> 00:39:25,960
layer and um what these are the

907
00:39:23,640 --> 00:39:28,640
connections here but from neuron to

908
00:39:25,960 --> 00:39:29,960
neuron um are the parameters are so this

909
00:39:28,640 --> 00:39:32,440
is the strength of connection the

910
00:39:29,960 --> 00:39:34,520
parameters what they do is um they

911
00:39:32,440 --> 00:39:37,160
encode the strength of connections again

912
00:39:34,520 --> 00:39:38,200
you don't need to know that but um we're

913
00:39:37,160 --> 00:39:42,240
going to

914
00:39:38,200 --> 00:39:43,920
see so again I didn't uh put the formula

915
00:39:42,240 --> 00:39:45,480
here because this would be quite complex

916
00:39:43,920 --> 00:39:47,520
these would be logistic regression so

917
00:39:45,480 --> 00:39:50,359
these would be

918
00:39:47,520 --> 00:39:51,800
um and then they would connect to each

919
00:39:50,359 --> 00:39:53,720
of these each of them would connect to

920
00:39:51,800 --> 00:39:55,319
each of them and um when I was in

921
00:39:53,720 --> 00:39:57,400
graduate school we did actually write

922
00:39:55,319 --> 00:40:00,400
those and we coded them up in Python and

923
00:39:57,400 --> 00:40:04,040
so on but uh we do not need to do that

924
00:40:00,400 --> 00:40:07,000
here but um you're going to see another

925
00:40:04,040 --> 00:40:10,480
so these are the underlying systems

926
00:40:07,000 --> 00:40:12,960
again um that in Co Transformers and ji

927
00:40:10,480 --> 00:40:14,880
but um we don't really need to get any

928
00:40:12,960 --> 00:40:17,960
deeper than

929
00:40:14,880 --> 00:40:20,480
that so what is a parameter uh and what

930
00:40:17,960 --> 00:40:22,680
is a hyperparameter so a parameter a

931
00:40:20,480 --> 00:40:25,839
model parameter is a tunable variable so

932
00:40:22,680 --> 00:40:28,079
this is something that um the model can

933
00:40:25,839 --> 00:40:30,640
change and it is in internal to the

934
00:40:28,079 --> 00:40:33,119
model and whose value can be learned

935
00:40:30,640 --> 00:40:34,839
from the data through training okay and

936
00:40:33,119 --> 00:40:36,960
this is what encodes the learning of the

937
00:40:34,839 --> 00:40:39,200
model so two different models that have

938
00:40:36,960 --> 00:40:40,800
seen different data would have different

939
00:40:39,200 --> 00:40:43,839
parameter values or different weights

940
00:40:40,800 --> 00:40:46,319
parameters and weights are the same um

941
00:40:43,839 --> 00:40:47,599
refer to the same thing what are model

942
00:40:46,319 --> 00:40:50,359
hyper parameters well these are

943
00:40:47,599 --> 00:40:51,880
variables that are external to the model

944
00:40:50,359 --> 00:40:55,359
um their value cannot be learned from

945
00:40:51,880 --> 00:40:56,640
the data but what hyper parameters do um

946
00:40:55,359 --> 00:40:58,640
is that they control the learning

947
00:40:56,640 --> 00:41:00,400
process and so examples of

948
00:40:58,640 --> 00:41:03,200
hyperparameters of their learning rate

949
00:41:00,400 --> 00:41:05,440
of certain uh algorithms the number of

950
00:41:03,200 --> 00:41:08,000
epoch this is how many training Cycles

951
00:41:05,440 --> 00:41:11,160
the system went through regularization

952
00:41:08,000 --> 00:41:16,839
this is um a system that con constrains

953
00:41:11,160 --> 00:41:18,880
the the model from getting to Big um so

954
00:41:16,839 --> 00:41:20,200
when you download a Model A pre-trained

955
00:41:18,880 --> 00:41:21,599
model what you're actually downloading

956
00:41:20,200 --> 00:41:24,720
are the parameters of the weights of

957
00:41:21,599 --> 00:41:26,240
that model you are not um I don't know

958
00:41:24,720 --> 00:41:28,079
that hyper parameters are always

959
00:41:26,240 --> 00:41:33,760
included they don't affect

960
00:41:28,079 --> 00:41:35,520
the um model performance uh but so

961
00:41:33,760 --> 00:41:37,800
models are sized by the number of

962
00:41:35,520 --> 00:41:39,960
parameters and hyperparameters are good

963
00:41:37,800 --> 00:41:41,599
to keep track of because they might

964
00:41:39,960 --> 00:41:43,000
explain they might allow you to

965
00:41:41,599 --> 00:41:46,520
troubleshoot through things but they're

966
00:41:43,000 --> 00:41:49,800
not um they don't they are not important

967
00:41:46,520 --> 00:41:51,880
for the actual um learned information

968
00:41:49,800 --> 00:41:54,680
they're important for the learning

969
00:41:51,880 --> 00:41:58,040
process

970
00:41:54,680 --> 00:42:01,079
okay okay so solving a

971
00:41:58,040 --> 00:42:05,560
um supervised learning problem uh we

972
00:42:01,079 --> 00:42:09,839
went through this in um

973
00:42:05,560 --> 00:42:12,119
the the previous um session so I'm just

974
00:42:09,839 --> 00:42:14,319
going to go through it very quickly uh

975
00:42:12,119 --> 00:42:15,800
and so again we start with the business

976
00:42:14,319 --> 00:42:17,000
um Tech serves the business and so we

977
00:42:15,800 --> 00:42:19,400
always start with the business we

978
00:42:17,000 --> 00:42:21,119
understand the business goal um we try

979
00:42:19,400 --> 00:42:25,559
to frame the problem which means we

980
00:42:21,119 --> 00:42:27,480
transform that um business problem into

981
00:42:25,559 --> 00:42:29,960
uh mathematical

982
00:42:27,480 --> 00:42:32,760
um notations uh we understand what

983
00:42:29,960 --> 00:42:36,319
metrics are great proxies we we plan the

984
00:42:32,760 --> 00:42:39,040
process then once we do that uh we go

985
00:42:36,319 --> 00:42:40,640
into the data realm we collect data we

986
00:42:39,040 --> 00:42:42,040
clean it up we decide on what our

987
00:42:40,640 --> 00:42:46,119
features are what

988
00:42:42,040 --> 00:42:48,839
matters um and then we get into the

989
00:42:46,119 --> 00:42:51,000
model domain so we select a model class

990
00:42:48,839 --> 00:42:55,400
we decide is this a classification is it

991
00:42:51,000 --> 00:42:56,920
a regression uh what model fits best uh

992
00:42:55,400 --> 00:42:58,640
you know am I running a neural net am I

993
00:42:56,920 --> 00:43:01,680
running running in svm I don't think

994
00:42:58,640 --> 00:43:03,520
anybody runs svms anymore but um they

995
00:43:01,680 --> 00:43:06,319
were very popular before the Deep

996
00:43:03,520 --> 00:43:07,280
learning boom am I running an XG boost a

997
00:43:06,319 --> 00:43:10,119
random

998
00:43:07,280 --> 00:43:12,119
Forest uh and so you set that model you

999
00:43:10,119 --> 00:43:13,599
train it you evaluate it you optimize it

1000
00:43:12,119 --> 00:43:15,839
and then once you're happy with its

1001
00:43:13,599 --> 00:43:19,240
performance uh and it generalizes it's

1002
00:43:15,839 --> 00:43:23,599
very important that you're that it

1003
00:43:19,240 --> 00:43:25,880
generalizes well um then you deploy it

1004
00:43:23,599 --> 00:43:29,000
and you'll maintain it

1005
00:43:25,880 --> 00:43:31,520
okay and so what does training a

1006
00:43:29,000 --> 00:43:34,200
supervis model look like well what

1007
00:43:31,520 --> 00:43:36,440
happens is that again it has the the the

1008
00:43:34,200 --> 00:43:38,880
learning itself is encoded in these

1009
00:43:36,440 --> 00:43:40,680
weights or parameters what ends up

1010
00:43:38,880 --> 00:43:42,520
happening is that the model when you

1011
00:43:40,680 --> 00:43:46,160
start training it initializes them at

1012
00:43:42,520 --> 00:43:49,319
random so um it starts them at random it

1013
00:43:46,160 --> 00:43:51,200
makes a prediction so it says okay well

1014
00:43:49,319 --> 00:43:54,119
this is in supervised learning so I know

1015
00:43:51,200 --> 00:43:58,200
the answer uh we we know the answer to

1016
00:43:54,119 --> 00:44:01,640
to to these um uh instances we're

1017
00:43:58,200 --> 00:44:04,200
looking at and so it makes a prediction

1018
00:44:01,640 --> 00:44:07,240
and then it looks how far is it from the

1019
00:44:04,200 --> 00:44:09,000
actual data it calculates some sort of

1020
00:44:07,240 --> 00:44:12,160
metric it could be we call it an error

1021
00:44:09,000 --> 00:44:14,160
but it could be um in reality it's

1022
00:44:12,160 --> 00:44:16,079
optimizing an objective function so that

1023
00:44:14,160 --> 00:44:17,960
could be it could be maximizing accuracy

1024
00:44:16,079 --> 00:44:20,480
for example or minimizing error so that

1025
00:44:17,960 --> 00:44:21,680
the general term is optimizing objective

1026
00:44:20,480 --> 00:44:23,960
function but I'm making the Assumption

1027
00:44:21,680 --> 00:44:25,920
here that I'm I'm minimizing an error

1028
00:44:23,960 --> 00:44:28,200
and so I can calculate the error between

1029
00:44:25,920 --> 00:44:31,160
the model predictions and the answers

1030
00:44:28,200 --> 00:44:34,240
and then it goes in and edits the weight

1031
00:44:31,160 --> 00:44:35,960
the weights to reduce that error um and

1032
00:44:34,240 --> 00:44:39,480
then it tries again and so what it does

1033
00:44:35,960 --> 00:44:41,079
is it repeats the Cycles two to four

1034
00:44:39,480 --> 00:44:42,839
until the error doesn't go down and I'll

1035
00:44:41,079 --> 00:44:44,880
give you and I'll show you an example of

1036
00:44:42,839 --> 00:44:47,280
how this is done in one of the demos so

1037
00:44:44,880 --> 00:44:49,160
you adjust you start the models you

1038
00:44:47,280 --> 00:44:50,480
predict you calculate an error then you

1039
00:44:49,160 --> 00:44:53,599
adjust the models and you keep doing

1040
00:44:50,480 --> 00:44:57,559
this until you can no longer reduce the

1041
00:44:53,599 --> 00:44:58,760
error okay and so I have two I have

1042
00:44:57,559 --> 00:45:01,599
three demos here I'm going to put them

1043
00:44:58,760 --> 00:45:04,240
in separate uh videos uh and so I'm

1044
00:45:01,599 --> 00:45:06,800
going to demo how

1045
00:45:04,240 --> 00:45:09,359
software is different from machine

1046
00:45:06,800 --> 00:45:11,720
Learning Systems um I have a little bit

1047
00:45:09,359 --> 00:45:15,359
a little notebook which I'll release uh

1048
00:45:11,720 --> 00:45:19,520
to you for you to play with um I'll also

1049
00:45:15,359 --> 00:45:22,079
demo um this training uh how how that

1050
00:45:19,520 --> 00:45:24,280
works with the uh linear regression

1051
00:45:22,079 --> 00:45:27,400
which is a very simple model and I also

1052
00:45:24,280 --> 00:45:28,800
want to demo the tensor F uh playground

1053
00:45:27,400 --> 00:45:31,960
which I like very much so I'm going to

1054
00:45:28,800 --> 00:45:35,200
releasee those as separate videos and

1055
00:45:31,960 --> 00:45:39,000
that's it for this one hello again so

1056
00:45:35,200 --> 00:45:41,440
this is the demo um that is with the

1057
00:45:39,000 --> 00:45:44,559
ml11 lecture so what I'm going to demo

1058
00:45:41,440 --> 00:45:46,559
here is the software versus ml approach

1059
00:45:44,559 --> 00:45:49,280
to solving problems um and then I'm

1060
00:45:46,559 --> 00:45:53,559
going to demo uh the model training

1061
00:45:49,280 --> 00:45:56,079
visualization okay so um let me go here

1062
00:45:53,559 --> 00:45:58,760
and so what this is this is a notebook a

1063
00:45:56,079 --> 00:46:02,400
Jupiter notebook that I will again uh

1064
00:45:58,760 --> 00:46:06,480
release uh for you to play with and

1065
00:46:02,400 --> 00:46:09,680
um and what I'm showing here is how we

1066
00:46:06,480 --> 00:46:14,200
would solve this

1067
00:46:09,680 --> 00:46:18,079
um uh Celsius conversion from Fahrenheit

1068
00:46:14,200 --> 00:46:22,800
or Fahrenheit conversion uh from Celsius

1069
00:46:18,079 --> 00:46:25,440
uh using uh software versus ml okay so

1070
00:46:22,800 --> 00:46:28,520
uh in for traditional software we do

1071
00:46:25,440 --> 00:46:33,079
know the formula that

1072
00:46:28,520 --> 00:46:34,920
um encodes Fahrenheit to Celsius uh

1073
00:46:33,079 --> 00:46:36,200
conversion and that's the the

1074
00:46:34,920 --> 00:46:39,440
temperature in Fahrenheit is equal to

1075
00:46:36,200 --> 00:46:42,440
1.8 time the temperature in celsius plus

1076
00:46:39,440 --> 00:46:47,280
32 so now given that I know this I can

1077
00:46:42,440 --> 00:46:50,200
write a function that goes in and uh

1078
00:46:47,280 --> 00:46:51,240
given an input in Celsius goes in and

1079
00:46:50,200 --> 00:46:55,319
returns a

1080
00:46:51,240 --> 00:46:59,040
Farenheit uh temperature and so this is

1081
00:46:55,319 --> 00:47:00,839
my formula or my code um again this is a

1082
00:46:59,040 --> 00:47:02,160
single function it's simple for for for

1083
00:47:00,839 --> 00:47:04,760
demonstration purposes but you can

1084
00:47:02,160 --> 00:47:07,559
imagine that this is a larger piece of

1085
00:47:04,760 --> 00:47:10,079
code and then I am going to deploy it

1086
00:47:07,559 --> 00:47:11,680
which is here just asking for user input

1087
00:47:10,079 --> 00:47:15,599
but you can again imagine that this is a

1088
00:47:11,680 --> 00:47:17,240
more complex system and so if I am to

1089
00:47:15,599 --> 00:47:19,079
run that it's going to tell me Well

1090
00:47:17,240 --> 00:47:20,800
enter your temperature in celsius I'm

1091
00:47:19,079 --> 00:47:24,599
going to enter minus

1092
00:47:20,800 --> 00:47:25,480
27 which is the temperature here today

1093
00:47:24,599 --> 00:47:27,319
in

1094
00:47:25,480 --> 00:47:32,040
Montreal and that's going to tell me

1095
00:47:27,319 --> 00:47:34,880
that it's- 16.6 fah okay so again I

1096
00:47:32,040 --> 00:47:37,160
wrote my formula which I already know my

1097
00:47:34,880 --> 00:47:41,800
I wrote my rules I know the rule I wrote

1098
00:47:37,160 --> 00:47:43,599
it up uh you deploy it and then you you

1099
00:47:41,800 --> 00:47:46,440
uh allow your users to interact with it

1100
00:47:43,599 --> 00:47:47,760
and then you maintain it now what

1101
00:47:46,440 --> 00:47:50,240
happens in a machine Learning System

1102
00:47:47,760 --> 00:47:52,280
well in a machine Learning System um

1103
00:47:50,240 --> 00:47:54,920
what usually happens is you do not know

1104
00:47:52,280 --> 00:47:57,079
this formula okay what you have is data

1105
00:47:54,920 --> 00:48:00,240
and so let's say I work for a company

1106
00:47:57,079 --> 00:48:02,760
and that company has both uh Celsius

1107
00:48:00,240 --> 00:48:04,520
thermometers and Fahrenheit thermometers

1108
00:48:02,760 --> 00:48:08,079
in the field that are collecting data

1109
00:48:04,520 --> 00:48:09,520
all the time and what ends up happening

1110
00:48:08,079 --> 00:48:12,920
uh is that the fahrenheit thermometers

1111
00:48:09,520 --> 00:48:14,839
they break they broke and uh it's too

1112
00:48:12,920 --> 00:48:16,440
costly to fix and there's a shortage so

1113
00:48:14,839 --> 00:48:19,880
we need that data we need that

1114
00:48:16,440 --> 00:48:24,200
information but I don't have a way to

1115
00:48:19,880 --> 00:48:28,160
collect it directly but my Celsius uh

1116
00:48:24,200 --> 00:48:30,040
sensors are still um picking up signal

1117
00:48:28,160 --> 00:48:32,440
and so what I want to do is to try to

1118
00:48:30,040 --> 00:48:35,240
predict uh the temperature in Fahrenheit

1119
00:48:32,440 --> 00:48:39,280
for my Downstream systems from the

1120
00:48:35,240 --> 00:48:43,400
sensors um in Celsius okay and so I'm

1121
00:48:39,280 --> 00:48:45,400
going to download my

1122
00:48:43,400 --> 00:48:49,119
data

1123
00:48:45,400 --> 00:48:52,400
and I want to show you what this looks

1124
00:48:49,119 --> 00:48:55,040
like so this is a set of data this is a

1125
00:48:52,400 --> 00:48:56,880
single file temperature. CSV which again

1126
00:48:55,040 --> 00:48:59,760
you're going to have access to um

1127
00:48:56,880 --> 00:49:03,359
there's two columns here this is degre

1128
00:48:59,760 --> 00:49:05,400
the the data in Celsius and this is the

1129
00:49:03,359 --> 00:49:08,280
data in Fahrenheit and if you go down

1130
00:49:05,400 --> 00:49:10,160
there's about 300 different uh rows in

1131
00:49:08,280 --> 00:49:12,240
this okay so this is the data that we

1132
00:49:10,160 --> 00:49:15,440
are

1133
00:49:12,240 --> 00:49:16,720
using and so here I'm going to download

1134
00:49:15,440 --> 00:49:18,599
this data and again it shows what I

1135
00:49:16,720 --> 00:49:20,119
showed you right there's a the First

1136
00:49:18,599 --> 00:49:22,480
Column is temperature in celsius the

1137
00:49:20,119 --> 00:49:25,680
second one is in Fahrenheit I've got 300

1138
00:49:22,480 --> 00:49:31,160
different rows and um there's some

1139
00:49:25,680 --> 00:49:34,000
statistical um metrics here uh and my

1140
00:49:31,160 --> 00:49:38,119
Min it goes all the way from -43 celsi

1141
00:49:34,000 --> 00:49:40,319
to 120 okay and this is data of course

1142
00:49:38,119 --> 00:49:44,319
that I generated myself with the formula

1143
00:49:40,319 --> 00:49:46,000
plus or minus uh 30 uh degrees of noise

1144
00:49:44,319 --> 00:49:49,520
so you're going to see that there's we

1145
00:49:46,000 --> 00:49:51,839
I've added some noise into there okay so

1146
00:49:49,520 --> 00:49:52,960
if we plot this uh this is what it looks

1147
00:49:51,839 --> 00:49:55,280
like so there's a temperature in

1148
00:49:52,960 --> 00:49:57,440
fahrenheit um and a temperature in

1149
00:49:55,280 --> 00:49:59,720
celsius and you can see that

1150
00:49:57,440 --> 00:50:02,200
uh that's the little noise I've added

1151
00:49:59,720 --> 00:50:05,760
now um it's easy to look at this because

1152
00:50:02,200 --> 00:50:07,520
um it's it's two columns So and I've

1153
00:50:05,760 --> 00:50:10,280
designed it that way for the reason

1154
00:50:07,520 --> 00:50:12,040
because it's easier to see things uh in

1155
00:50:10,280 --> 00:50:14,480
the real world you'll

1156
00:50:12,040 --> 00:50:16,559
never there's very few applications for

1157
00:50:14,480 --> 00:50:18,280
this for a single column and so uh

1158
00:50:16,559 --> 00:50:21,000
there's a lot of comp there's a lot more

1159
00:50:18,280 --> 00:50:22,680
columns and features in the real world

1160
00:50:21,000 --> 00:50:24,640
and visualization becomes a lot harder

1161
00:50:22,680 --> 00:50:26,400
but again I'm putting I'm making it

1162
00:50:24,640 --> 00:50:28,640
two-dimensional for you to to see the

1163
00:50:26,400 --> 00:50:28,640
difference

1164
00:50:28,760 --> 00:50:33,920
okay so now I've got this information

1165
00:50:31,680 --> 00:50:36,079
this is my my information prior to the

1166
00:50:33,920 --> 00:50:39,280
sensors breaking down so I do have some

1167
00:50:36,079 --> 00:50:41,880
information and now what I do have is my

1168
00:50:39,280 --> 00:50:45,319
um Celsius sensors are still picking up

1169
00:50:41,880 --> 00:50:47,359
data um and I don't have any Fahrenheit

1170
00:50:45,319 --> 00:50:49,400
anymore and what I'm trying to do is

1171
00:50:47,359 --> 00:50:52,280
take this information and predict my

1172
00:50:49,400 --> 00:50:54,720
Fahrenheit for Downstream systems okay

1173
00:50:52,280 --> 00:50:57,920
so how am I going to go about this well

1174
00:50:54,720 --> 00:51:01,480
um I'm going to import numpy um and a

1175
00:50:57,920 --> 00:51:04,440
ske learn uh psychic learn is um a

1176
00:51:01,480 --> 00:51:06,440
really good uh it's a found it's a

1177
00:51:04,440 --> 00:51:08,000
fundamental library in machine learning

1178
00:51:06,440 --> 00:51:11,000
what I'm importing here is linear

1179
00:51:08,000 --> 00:51:12,559
regression which is the model

1180
00:51:11,000 --> 00:51:15,280
class

1181
00:51:12,559 --> 00:51:16,720
um uh and this is this is for evaluation

1182
00:51:15,280 --> 00:51:20,440
and this is for spling the data we'll

1183
00:51:16,720 --> 00:51:23,400
see in uh the the code later what I'm

1184
00:51:20,440 --> 00:51:26,040
what I'm doing is I'm pulling my X which

1185
00:51:23,400 --> 00:51:27,280
is the Celsius column this is my input

1186
00:51:26,040 --> 00:51:29,680
or my feat

1187
00:51:27,280 --> 00:51:31,640
and I'm pulling my Y which is the actual

1188
00:51:29,680 --> 00:51:34,839
column that I want to predict this is my

1189
00:51:31,640 --> 00:51:37,319
output and then I choose a model class

1190
00:51:34,839 --> 00:51:40,319
um this is a linear regression because

1191
00:51:37,319 --> 00:51:42,680
the output um is continuous but also

1192
00:51:40,319 --> 00:51:45,400
because I mean I can see it's a line but

1193
00:51:42,680 --> 00:51:48,160
usually um there's a lot of work in

1194
00:51:45,400 --> 00:51:50,040
predictive ml in understanding what

1195
00:51:48,160 --> 00:51:52,040
these models what these model classes

1196
00:51:50,040 --> 00:51:53,559
are what is the underlying equation what

1197
00:51:52,040 --> 00:51:56,119
inputs do they take what outputs how

1198
00:51:53,559 --> 00:51:57,200
well do they do what space of

1199
00:51:56,119 --> 00:52:00,000
mathematics

1200
00:51:57,200 --> 00:52:02,160
um are they really good at and so on so

1201
00:52:00,000 --> 00:52:04,160
there's a lot of work in predictive ml

1202
00:52:02,160 --> 00:52:06,880
in terms of knowing your algorithms and

1203
00:52:04,160 --> 00:52:10,079
which one to use that's not true for

1204
00:52:06,880 --> 00:52:12,720
Gen but um okay so for this one I'm

1205
00:52:10,079 --> 00:52:14,559
going to use linear regression and so

1206
00:52:12,720 --> 00:52:17,799
this I've initiated a model that is a

1207
00:52:14,559 --> 00:52:20,280
linear regression model um I'm taking my

1208
00:52:17,799 --> 00:52:22,960
data I'm splitting at 3070 so 70 will go

1209
00:52:20,280 --> 00:52:24,599
to training and 30 would go for testing

1210
00:52:22,960 --> 00:52:27,319
the reason we do this is we want the

1211
00:52:24,599 --> 00:52:29,680
model to uh learn a pattern that can

1212
00:52:27,319 --> 00:52:33,160
generalize beyond the data that the

1213
00:52:29,680 --> 00:52:34,680
model sees if the model does really well

1214
00:52:33,160 --> 00:52:36,319
on the training data and does terribly

1215
00:52:34,680 --> 00:52:38,280
on the test data then it what we say

1216
00:52:36,319 --> 00:52:40,400
it's it it overfit which means it really

1217
00:52:38,280 --> 00:52:42,079
memorized the information which is not

1218
00:52:40,400 --> 00:52:45,079
what we want it to do we want the model

1219
00:52:42,079 --> 00:52:48,040
to generaliz on uh the test data so we

1220
00:52:45,079 --> 00:52:50,559
pull out um here 30% of the data that

1221
00:52:48,040 --> 00:52:52,480
the model will never see and once it

1222
00:52:50,559 --> 00:52:54,160
Tunes its

1223
00:52:52,480 --> 00:52:57,359
parameters

1224
00:52:54,160 --> 00:52:58,920
um on the training data then we'll use

1225
00:52:57,359 --> 00:53:01,400
that test data to evaluate whether it

1226
00:52:58,920 --> 00:53:03,760
generalized as well and here we're

1227
00:53:01,400 --> 00:53:05,680
training so SK learn is really nice and

1228
00:53:03,760 --> 00:53:09,960
that you can use model.fit

1229
00:53:05,680 --> 00:53:13,400
to um predict and then model uh to to to

1230
00:53:09,960 --> 00:53:15,760
train and then model. predict to uh

1231
00:53:13,400 --> 00:53:19,319
predict and so we're training here and

1232
00:53:15,760 --> 00:53:21,960
then we score the model by by taking the

1233
00:53:19,319 --> 00:53:24,280
r squ uh

1234
00:53:21,960 --> 00:53:27,640
coefficient and then we look at some

1235
00:53:24,280 --> 00:53:29,559
metrics so let me do this okay

1236
00:53:27,640 --> 00:53:30,799
so this model after training and again

1237
00:53:29,559 --> 00:53:33,400
we'll look at a linear regression

1238
00:53:30,799 --> 00:53:39,559
training in in the second notebook but

1239
00:53:33,400 --> 00:53:41,920
after training this model uh did uh 96 R

1240
00:53:39,559 --> 00:53:45,200
SAR these are I'm parting R squ yeah so

1241
00:53:41,920 --> 00:53:49,319
this is um 96 r squar on the training

1242
00:53:45,200 --> 00:53:51,079
and 95 on 95.9 on the test the fact that

1243
00:53:49,319 --> 00:53:52,880
these two numbers are really close tells

1244
00:53:51,079 --> 00:53:56,160
me that it's not overfitting that the

1245
00:53:52,880 --> 00:53:57,720
the the um performance on the test set

1246
00:53:56,160 --> 00:54:00,680
is s similar to that on the training set

1247
00:53:57,720 --> 00:54:01,920
and so the model is generalizing okay so

1248
00:54:00,680 --> 00:54:04,520
now I'm going to look at this model I'm

1249
00:54:01,920 --> 00:54:06,040
printing the coefficient um of

1250
00:54:04,520 --> 00:54:07,559
determination which is the r squ which

1251
00:54:06,040 --> 00:54:09,400
we've printed out here but also the

1252
00:54:07,559 --> 00:54:11,680
intercept and the slope so again a

1253
00:54:09,400 --> 00:54:15,280
linear regression is um in the formula

1254
00:54:11,680 --> 00:54:16,880
of yal ax plus b uh B is the intercept

1255
00:54:15,280 --> 00:54:18,599
and a is the slope so these are the two

1256
00:54:16,880 --> 00:54:21,680
parameters that the model has learned

1257
00:54:18,599 --> 00:54:23,680
and I'm printing them out and so when I

1258
00:54:21,680 --> 00:54:26,440
print them out this is what it looks

1259
00:54:23,680 --> 00:54:28,240
like and so when I run this so this the

1260
00:54:26,440 --> 00:54:31,440
M system after training thinks that the

1261
00:54:28,240 --> 00:54:34,720
temperature in Celsius is 1.8 times the

1262
00:54:31,440 --> 00:54:38,799
temperature in celsius plus 32 so this

1263
00:54:34,720 --> 00:54:41,359
is fairly close to the actual um formula

1264
00:54:38,799 --> 00:54:43,440
that we know is true again this depends

1265
00:54:41,359 --> 00:54:45,319
on how good your data is how much noise

1266
00:54:43,440 --> 00:54:47,599
is injected why did it know it exactly

1267
00:54:45,319 --> 00:54:50,839
because I injected noise um and it

1268
00:54:47,599 --> 00:54:54,079
didn't train that long there's only 300

1269
00:54:50,839 --> 00:54:56,440
um so the more data you have the cleaner

1270
00:54:54,079 --> 00:54:58,160
your data is then the more accurate your

1271
00:54:56,440 --> 00:55:02,000
your predict your model

1272
00:54:58,160 --> 00:55:03,799
is okay and so now that I've got this

1273
00:55:02,000 --> 00:55:07,040
formula I've trained I've got this

1274
00:55:03,799 --> 00:55:10,000
formula then I go in and deploy this

1275
00:55:07,040 --> 00:55:11,960
model so I'm using the model. predict uh

1276
00:55:10,000 --> 00:55:13,680
to to to get a prediction from this

1277
00:55:11,960 --> 00:55:15,599
model and so let me pull that out it's

1278
00:55:13,680 --> 00:55:17,559
going to tell me what did you do and I

1279
00:55:15,599 --> 00:55:21,799
think I use minus

1280
00:55:17,559 --> 00:55:23,960
27 and again this tells me based on the

1281
00:55:21,799 --> 00:55:26,680
software system that I I WR wrote above

1282
00:55:23,960 --> 00:55:29,839
it's minus 16.6 Fahrenheit and then on

1283
00:55:26,680 --> 00:55:32,799
the based on the ml uh prediction it's

1284
00:55:29,839 --> 00:55:36,160
1651 which is very very close right and

1285
00:55:32,799 --> 00:55:38,599
so this is the um that's how these two

1286
00:55:36,160 --> 00:55:40,319
things works if you know the rule if you

1287
00:55:38,599 --> 00:55:42,920
know the formula you type it up and if

1288
00:55:40,319 --> 00:55:46,839
you don't and you have data then you can

1289
00:55:42,920 --> 00:55:49,440
infer that formula from the data okay so

1290
00:55:46,839 --> 00:55:54,680
again I'm going to uh release this for

1291
00:55:49,440 --> 00:55:57,920
you to play with now the other

1292
00:55:54,680 --> 00:56:01,079
um model

1293
00:55:57,920 --> 00:56:02,599
I want to just see if all of these are

1294
00:56:01,079 --> 00:56:04,880
installed this is another computer so I

1295
00:56:02,599 --> 00:56:06,280
just want to make sure okay so uh what

1296
00:56:04,880 --> 00:56:08,680
this is again is a linear regression

1297
00:56:06,280 --> 00:56:10,079
model what we trained in the the the the

1298
00:56:08,680 --> 00:56:11,359
first notebook is a linear regression

1299
00:56:10,079 --> 00:56:15,039
model the linear regression model

1300
00:56:11,359 --> 00:56:18,119
equation of course is the y equal uh ax

1301
00:56:15,039 --> 00:56:20,039
plus b or WX plus b no matter how you

1302
00:56:18,119 --> 00:56:24,160
want to call it what the objective

1303
00:56:20,039 --> 00:56:27,920
function that um this model optimizes is

1304
00:56:24,160 --> 00:56:31,920
a is a Le square and this is equation

1305
00:56:27,920 --> 00:56:33,000
and no this is the error that it it uh

1306
00:56:31,920 --> 00:56:35,280
it

1307
00:56:33,000 --> 00:56:37,200
calculates and so it's minimizing this

1308
00:56:35,280 --> 00:56:39,400
subjective function anyway that's not

1309
00:56:37,200 --> 00:56:40,720
that not information you need but anyway

1310
00:56:39,400 --> 00:56:44,440
this is what's happening under the hood

1311
00:56:40,720 --> 00:56:45,880
so I've got some functions here that um

1312
00:56:44,440 --> 00:56:48,079
train this model and we're not going to

1313
00:56:45,880 --> 00:56:50,920
go into it in details but like I said in

1314
00:56:48,079 --> 00:56:53,599
the lecture um the model initially

1315
00:56:50,920 --> 00:56:55,760
initializes the weights at random so

1316
00:56:53,599 --> 00:56:57,480
this is the initialization code this is

1317
00:56:55,760 --> 00:56:59,520
the it calculates an error so this is

1318
00:56:57,480 --> 00:57:02,200
the cost function it's uh it's

1319
00:56:59,520 --> 00:57:04,720
calculating uh it predicts right because

1320
00:57:02,200 --> 00:57:07,079
it has to predict then use that

1321
00:57:04,720 --> 00:57:08,559
prediction to calculate an error and

1322
00:57:07,079 --> 00:57:10,000
then it updates the parameters so these

1323
00:57:08,559 --> 00:57:14,000
are the three things that we've seen in

1324
00:57:10,000 --> 00:57:17,400
that Loop and um uh it runs gradient

1325
00:57:14,000 --> 00:57:17,400
descent but that's

1326
00:57:18,319 --> 00:57:24,680
um okay and then I collect the cost

1327
00:57:21,960 --> 00:57:26,400
history and so on okay so there's some

1328
00:57:24,680 --> 00:57:28,280
functions here that are useful again I'm

1329
00:57:26,400 --> 00:57:30,599
downloading the same file the

1330
00:57:28,280 --> 00:57:33,319
temperature. CSV file which we just

1331
00:57:30,599 --> 00:57:35,839
looked at I'm going to load it

1332
00:57:33,319 --> 00:57:39,400
up and then again it's the same one so

1333
00:57:35,839 --> 00:57:42,720
we've got 300 going from -43 uh Celsius

1334
00:57:39,400 --> 00:57:45,799
to 120 okay so these are hyperparameters

1335
00:57:42,720 --> 00:57:49,670
so if I go back to this model

1336
00:57:45,799 --> 00:57:50,880
here if I go back to this model here

1337
00:57:49,670 --> 00:57:54,720
[Music]

1338
00:57:50,880 --> 00:57:56,520
um where is the temperature in the

1339
00:57:54,720 --> 00:57:58,599
temperature in Fahrenheit is what I want

1340
00:57:56,520 --> 00:58:00,480
to predict that's my y the temperature

1341
00:57:58,599 --> 00:58:03,200
in Celsius is my information that's

1342
00:58:00,480 --> 00:58:07,119
given that's my X that's my input data

1343
00:58:03,200 --> 00:58:10,400
um the two numbers that I

1344
00:58:07,119 --> 00:58:13,440
actually trained that that were tuned in

1345
00:58:10,400 --> 00:58:17,039
this model are this intercept and the

1346
00:58:13,440 --> 00:58:21,880
slope which is uh if we

1347
00:58:17,039 --> 00:58:24,799
go back um is really we found what this

1348
00:58:21,880 --> 00:58:27,640
1.8 and 32 are so if I go back here

1349
00:58:24,799 --> 00:58:30,760
actually it's this number here the W and

1350
00:58:27,640 --> 00:58:34,280
the B so these are my parameters okay my

1351
00:58:30,760 --> 00:58:37,760
weights my hyper parameters are going to

1352
00:58:34,280 --> 00:58:40,400
be um here for logistic for linear

1353
00:58:37,760 --> 00:58:43,160
regression uh is the linear the learning

1354
00:58:40,400 --> 00:58:44,559
rate which I've set at at this and and

1355
00:58:43,160 --> 00:58:46,480
the iterations these are the number of

1356
00:58:44,559 --> 00:58:50,599
epochs this is how many runs it's going

1357
00:58:46,480 --> 00:58:53,000
to do of this cycle of um

1358
00:58:50,599 --> 00:58:57,280
calculate uh

1359
00:58:53,000 --> 00:59:00,440
predict predict calculate error update

1360
00:58:57,280 --> 00:59:02,760
Waits this uh three system it's going to

1361
00:59:00,440 --> 00:59:04,720
do 10 Loops of that that's the epoch or

1362
00:59:02,760 --> 00:59:06,520
the iterations okay and so now I'm

1363
00:59:04,720 --> 00:59:09,480
running the gradient descent so I am

1364
00:59:06,520 --> 00:59:09,480
running this

1365
00:59:09,640 --> 00:59:16,079
model and then I'm going to print the

1366
00:59:13,799 --> 00:59:17,359
history so what I'm showing you here

1367
00:59:16,079 --> 00:59:20,880
this is iteration number one it's going

1368
00:59:17,359 --> 00:59:22,839
to do do through 10 so when it started

1369
00:59:20,880 --> 00:59:24,640
what we we looked at this so these are

1370
00:59:22,839 --> 00:59:26,880
my actual data this is my actual data

1371
00:59:24,640 --> 00:59:29,799
that I showed you before and this is the

1372
00:59:26,880 --> 00:59:32,119
model prediction okay so it initializes

1373
00:59:29,799 --> 00:59:33,920
the models at random and then it makes a

1374
00:59:32,119 --> 00:59:36,160
prediction and this is its prediction

1375
00:59:33,920 --> 00:59:38,000
and so it calculates a cost and the cost

1376
00:59:36,160 --> 00:59:40,119
here is 44

1377
00:59:38,000 --> 00:59:42,680
45.3 right there's no units for this

1378
00:59:40,119 --> 00:59:45,039
it's just a number but we have to

1379
00:59:42,680 --> 00:59:47,000
because uh this is an error we have to

1380
00:59:45,039 --> 00:59:48,599
bring it down and so what does it do

1381
00:59:47,000 --> 00:59:50,480
well it goes into iteration two so it

1382
00:59:48,599 --> 00:59:52,319
updates its weights so now it predicts

1383
00:59:50,480 --> 00:59:54,799
that this is a better prediction it

1384
00:59:52,319 --> 00:59:57,119
updates the weights creates a cost now

1385
00:59:54,799 --> 01:00:00,559
it's 2028

1386
00:59:57,119 --> 01:00:02,680
and then it goes again goes through

1387
01:00:00,559 --> 01:00:05,160
another cycle and so now it has this

1388
01:00:02,680 --> 01:00:07,839
guess with this cost this guess what

1389
01:00:05,160 --> 01:00:12,640
this cost this guess what this cost and

1390
01:00:07,839 --> 01:00:15,160
by the end of it what we've got here is

1391
01:00:12,640 --> 01:00:18,520
the last iteration again I I I stopped

1392
01:00:15,160 --> 01:00:20,920
it at 10 we can go um as as long as we

1393
01:00:18,520 --> 01:00:22,760
want again we don't want to overfit but

1394
01:00:20,920 --> 01:00:25,039
um now it brought down the error from

1395
01:00:22,760 --> 01:00:27,799
4,000 roughly to 400 and this is a

1396
01:00:25,039 --> 01:00:31,760
better fit this is what thinks that this

1397
01:00:27,799 --> 01:00:34,640
model is and so if I plot this cost we

1398
01:00:31,760 --> 01:00:36,440
started at 4,000 in the first iteration

1399
01:00:34,640 --> 01:00:39,720
and then it brought it down and down and

1400
01:00:36,440 --> 01:00:42,599
down and down up to um and when this

1401
01:00:39,720 --> 01:00:44,359
flattens out when this Plateau is done

1402
01:00:42,599 --> 01:00:46,000
it it doesn't move anymore that's when

1403
01:00:44,359 --> 01:00:48,200
you know that it can't learn anymore

1404
01:00:46,000 --> 01:00:52,200
from that data so that the learning is

1405
01:00:48,200 --> 01:00:53,640
complete we if if if I plotted this and

1406
01:00:52,200 --> 01:00:55,200
it ended up here then I know there's

1407
01:00:53,640 --> 01:00:58,039
more learning potentially because I

1408
01:00:55,200 --> 01:01:01,240
haven't um plateaued okay so this has

1409
01:00:58,039 --> 01:01:04,920
plateaued it learned uh the whole system

1410
01:01:01,240 --> 01:01:07,000
and this is what the observed versus

1411
01:01:04,920 --> 01:01:09,039
predicted values is if I plot my actual

1412
01:01:07,000 --> 01:01:13,079
data and the data I would get from this

1413
01:01:09,039 --> 01:01:17,480
model this is what this thing looks like

1414
01:01:13,079 --> 01:01:19,720
okay I have one thing to demo before I

1415
01:01:17,480 --> 01:01:22,880
let you go I really like this uh

1416
01:01:19,720 --> 01:01:26,079
playground from tensorflow um what this

1417
01:01:22,880 --> 01:01:27,160
is is a neural network and you can play

1418
01:01:26,079 --> 01:01:29,119
with this so this is these are the

1419
01:01:27,160 --> 01:01:31,079
inputs there's two inputs there's X1 and

1420
01:01:29,119 --> 01:01:35,400
X2 so what are we looking at here we're

1421
01:01:31,079 --> 01:01:38,240
looking at this is X1 and X2 right and

1422
01:01:35,400 --> 01:01:40,799
what you see is so the there's X1 and X2

1423
01:01:38,240 --> 01:01:43,680
and the color is the actual y so this is

1424
01:01:40,799 --> 01:01:46,119
a um

1425
01:01:43,680 --> 01:01:49,359
classification

1426
01:01:46,119 --> 01:01:51,960
uh problem and you're trying to classify

1427
01:01:49,359 --> 01:01:53,599
any particular row as blue or orange and

1428
01:01:51,960 --> 01:01:55,079
so what you see here in the color is the

1429
01:01:53,599 --> 01:01:57,599
actual label or what you're trying to

1430
01:01:55,079 --> 01:02:01,599
predict blue or orange and you got two

1431
01:01:57,599 --> 01:02:04,400
features which are X1 and X2 and what

1432
01:02:01,599 --> 01:02:07,400
you got here is a neural net so this is

1433
01:02:04,400 --> 01:02:09,720
the uh layer the input layer and then

1434
01:02:07,400 --> 01:02:12,480
you've got two hidden layers which I can

1435
01:02:09,720 --> 01:02:15,119
delete or ADD and then you can also add

1436
01:02:12,480 --> 01:02:17,119
the number of neurons or delete them

1437
01:02:15,119 --> 01:02:19,079
okay so I can add neurons or delete them

1438
01:02:17,119 --> 01:02:21,319
and you have got four different

1439
01:02:19,079 --> 01:02:22,839
information uh sets of information here

1440
01:02:21,319 --> 01:02:26,039
okay so this is the simplest case is

1441
01:02:22,839 --> 01:02:29,000
when you've got um two different classes

1442
01:02:26,039 --> 01:02:31,480
that you can separate linearly okay so

1443
01:02:29,000 --> 01:02:33,359
what is going to happen so um this is

1444
01:02:31,480 --> 01:02:35,119
the simplest case so even if this is a

1445
01:02:33,359 --> 01:02:36,400
this can be solved by a logistic

1446
01:02:35,119 --> 01:02:38,520
regression so I've removed all the

1447
01:02:36,400 --> 01:02:42,160
layers this becomes simple logistic

1448
01:02:38,520 --> 01:02:47,319
regression and what you see here is

1449
01:02:42,160 --> 01:02:50,000
um the the features and again the color

1450
01:02:47,319 --> 01:02:51,880
of the dot is the label that we want to

1451
01:02:50,000 --> 01:02:54,920
predict and the background is what the

1452
01:02:51,880 --> 01:02:59,000
model thinks and so we've succeeded when

1453
01:02:54,920 --> 01:03:01,039
the color of the dots um aligns with the

1454
01:02:59,000 --> 01:03:04,200
color uh in the background and so you

1455
01:03:01,039 --> 01:03:06,720
can see that this even a simple logistic

1456
01:03:04,200 --> 01:03:09,960
uh logistic regression can solve this

1457
01:03:06,720 --> 01:03:11,640
problem by creating a line there right

1458
01:03:09,960 --> 01:03:14,240
now I wanted to show you some things

1459
01:03:11,640 --> 01:03:16,720
here so the if I look here these are my

1460
01:03:14,240 --> 01:03:19,599
inputs the color is my label or my

1461
01:03:16,720 --> 01:03:21,400
output and if I look here what I have is

1462
01:03:19,599 --> 01:03:25,279
these are my weights the connection

1463
01:03:21,400 --> 01:03:27,160
strength of input um the connection

1464
01:03:25,279 --> 01:03:29,279
strength is my weight or parameter so

1465
01:03:27,160 --> 01:03:31,559
this is the the parameter and then what

1466
01:03:29,279 --> 01:03:33,880
I have here is a set of hyper parameters

1467
01:03:31,559 --> 01:03:35,680
this is what's controlling my learning

1468
01:03:33,880 --> 01:03:37,599
so this is the EPO this is the iteration

1469
01:03:35,680 --> 01:03:39,760
the number of Cycles it goes through

1470
01:03:37,599 --> 01:03:43,720
this is the learning rate this is how

1471
01:03:39,760 --> 01:03:45,880
fast um of a jump it moves uh between

1472
01:03:43,720 --> 01:03:49,279
Epoch and and this can be tuned this is

1473
01:03:45,880 --> 01:03:51,480
the activation function this is the um a

1474
01:03:49,279 --> 01:03:53,760
mathematical function that again is is

1475
01:03:51,480 --> 01:03:55,119
imposed uh on the system and then

1476
01:03:53,760 --> 01:03:57,760
there's regularization which is not

1477
01:03:55,119 --> 01:03:59,400
applied here and regularization rate and

1478
01:03:57,760 --> 01:04:00,960
um and you can change this to regression

1479
01:03:59,400 --> 01:04:04,039
you'll see again you can play with it

1480
01:04:00,960 --> 01:04:05,960
but I just want to show you a few things

1481
01:04:04,039 --> 01:04:08,760
uh but this is really cool to to to play

1482
01:04:05,960 --> 01:04:10,520
with so just Google uh tensor flow

1483
01:04:08,760 --> 01:04:12,680
playground okay so this is going be

1484
01:04:10,520 --> 01:04:14,559
solved this is very simple now if I come

1485
01:04:12,680 --> 01:04:16,680
to this problem which is slightly harder

1486
01:04:14,559 --> 01:04:18,440
right now this these cannot be divided

1487
01:04:16,680 --> 01:04:21,079
by a single line I would need at least

1488
01:04:18,440 --> 01:04:24,079
two different lines uh to divide this

1489
01:04:21,079 --> 01:04:26,599
and so if I run this with a single

1490
01:04:24,079 --> 01:04:28,440
logistic regression it'll never

1491
01:04:26,599 --> 01:04:30,359
um it'll never do well because it

1492
01:04:28,440 --> 01:04:33,119
doesn't have enough complexity in the

1493
01:04:30,359 --> 01:04:35,039
model so this is what we call model bias

1494
01:04:33,119 --> 01:04:36,760
uh this model even if it runs for a

1495
01:04:35,039 --> 01:04:38,599
million years it'll never solve this

1496
01:04:36,760 --> 01:04:40,520
problem and so what I would what I could

1497
01:04:38,599 --> 01:04:45,119
do is add a hidden

1498
01:04:40,520 --> 01:04:48,279
layer right and if I add um again the

1499
01:04:45,119 --> 01:04:50,119
model um architecture really depends on

1500
01:04:48,279 --> 01:04:53,880
base knowledge the bigger the model than

1501
01:04:50,119 --> 01:04:56,760
the more problems it can solve and um

1502
01:04:53,880 --> 01:04:59,079
now that I've done this it seems to be

1503
01:04:56,760 --> 01:05:00,559
able to solve this problem right so now

1504
01:04:59,079 --> 01:05:04,000
the Orange is under the orange and the

1505
01:05:00,559 --> 01:05:05,559
blue is under the blue um and so this

1506
01:05:04,000 --> 01:05:08,200
particular

1507
01:05:05,559 --> 01:05:09,880
architecture um can solve this model and

1508
01:05:08,200 --> 01:05:12,200
again this is a neural network right it

1509
01:05:09,880 --> 01:05:16,200
has the input layer the output layer and

1510
01:05:12,200 --> 01:05:18,760
two hidden layers okay so now this one

1511
01:05:16,200 --> 01:05:21,000
is a little bit more complex um let's

1512
01:05:18,760 --> 01:05:23,839
see what it's going to

1513
01:05:21,000 --> 01:05:25,720
do oh and that that one solves quite

1514
01:05:23,839 --> 01:05:27,160
well so the the blue is under the blue

1515
01:05:25,720 --> 01:05:30,039
and the Orange is under the orange and

1516
01:05:27,160 --> 01:05:31,599
then you can see the model weight so X1

1517
01:05:30,039 --> 01:05:32,279
if I was to write this down this would

1518
01:05:31,599 --> 01:05:38,839
be

1519
01:05:32,279 --> 01:05:40,799
X1 um time -7 into this minus time -.3

1520
01:05:38,839 --> 01:05:42,400
into this and then all of these you'd

1521
01:05:40,799 --> 01:05:44,920
have to account for all of these going

1522
01:05:42,400 --> 01:05:48,119
through a sigmoid function um so it gets

1523
01:05:44,920 --> 01:05:49,760
quite complex mathematically okay and

1524
01:05:48,119 --> 01:05:52,760
then we've got this

1525
01:05:49,760 --> 01:05:54,920
one this is the hardest one and again

1526
01:05:52,760 --> 01:05:57,839
what ends up happening is if it can't

1527
01:05:54,920 --> 01:06:00,480
solve it if you add layers and you add

1528
01:05:57,839 --> 01:06:02,559
neurons the bigger the model is then it

1529
01:06:00,480 --> 01:06:04,720
it becomes really powerful and this is

1530
01:06:02,559 --> 01:06:09,160
where these gen models come in and that

1531
01:06:04,720 --> 01:06:09,160
they can they can encode a lot of

1532
01:06:09,279 --> 01:06:14,480
information and so it's learning and you

1533
01:06:12,680 --> 01:06:15,680
can see what's doing every iteration

1534
01:06:14,480 --> 01:06:17,480
what is it doing it's making a

1535
01:06:15,680 --> 01:06:18,680
prediction calculating an error updating

1536
01:06:17,480 --> 01:06:19,960
the weights making a prediction

1537
01:06:18,680 --> 01:06:24,599
calculating an error updating the

1538
01:06:19,960 --> 01:06:27,240
weights until it finds itself um not

1539
01:06:24,599 --> 01:06:28,720
making mistakes anymore

1540
01:06:27,240 --> 01:06:30,640
okay and so that that kind of solves the

1541
01:06:28,720 --> 01:06:33,039
problem right it's doing a loop of

1542
01:06:30,640 --> 01:06:35,279
orange and these are orange and these

1543
01:06:33,039 --> 01:06:36,559
are blue maybe this if I put an orange

1544
01:06:35,279 --> 01:06:38,000
here it would make an error and then it

1545
01:06:36,559 --> 01:06:41,000
would clean that up but at the moment

1546
01:06:38,000 --> 01:06:44,319
there is no data there okay and so

1547
01:06:41,000 --> 01:06:48,480
that's it um that's all I wanted to show

1548
01:06:44,319 --> 01:06:52,760
you um I hope it makes it clearer hello

1549
01:06:48,480 --> 01:06:55,839
again so this is ml13 this is

1550
01:06:52,760 --> 01:06:58,200
Introduction to generative AI this is I

1551
01:06:55,839 --> 01:07:01,400
think the longest lecture here but it

1552
01:06:58,200 --> 01:07:05,240
goes into a lot of details on

1553
01:07:01,400 --> 01:07:06,799
gen okay so uh what is generative AI uh

1554
01:07:05,240 --> 01:07:08,960
so generative AI like we said before is

1555
01:07:06,799 --> 01:07:13,079
a subset of machine learning uh

1556
01:07:08,960 --> 01:07:17,480
algorithms that generates new uh content

1557
01:07:13,079 --> 01:07:21,240
in a lot of um predictive ml the

1558
01:07:17,480 --> 01:07:24,240
objective uh the the output of the model

1559
01:07:21,240 --> 01:07:26,240
is pretty constrained it it um in

1560
01:07:24,240 --> 01:07:28,559
supervised learning it if you're

1561
01:07:26,240 --> 01:07:31,640
classifying that it it chooses one of

1562
01:07:28,559 --> 01:07:35,200
those uh classes it doesn't go outside

1563
01:07:31,640 --> 01:07:37,799
of that um in regression again there's a

1564
01:07:35,200 --> 01:07:41,680
a range it's a number uh but so

1565
01:07:37,799 --> 01:07:44,799
generative AI um is able to create in

1566
01:07:41,680 --> 01:07:47,680
content that it hasn't seen

1567
01:07:44,799 --> 01:07:50,319
um but from information that it has seen

1568
01:07:47,680 --> 01:07:52,839
before and it emerged in the public eye

1569
01:07:50,319 --> 01:07:56,039
in November I think it was 30 November

1570
01:07:52,839 --> 01:08:00,520
2022 when open AI launched ch GPT for

1571
01:07:56,039 --> 01:08:04,200
free and um before that geni was really

1572
01:08:00,520 --> 01:08:10,039
it is a field that has uh been around uh

1573
01:08:04,200 --> 01:08:13,520
for a while but um in 2022 it it was

1574
01:08:10,039 --> 01:08:18,480
um put in the public eye and the world

1575
01:08:13,520 --> 01:08:23,120
has never been the same since um and so

1576
01:08:18,480 --> 01:08:26,199
um a lot of what we see G VI um can

1577
01:08:23,120 --> 01:08:28,679
create content in different modal so it

1578
01:08:26,199 --> 01:08:30,279
could be uh in language it could be text

1579
01:08:28,679 --> 01:08:32,000
gener it could be text generation in

1580
01:08:30,279 --> 01:08:33,679
language it could be image generation it

1581
01:08:32,000 --> 01:08:36,400
could be in videos and audios and so the

1582
01:08:33,679 --> 01:08:39,239
inputs and outputs can vary widely but

1583
01:08:36,400 --> 01:08:42,799
the most success we've had has been in

1584
01:08:39,239 --> 01:08:44,400
in language um a lot of uh the really

1585
01:08:42,799 --> 01:08:45,640
cool things are happening in language

1586
01:08:44,400 --> 01:08:47,759
and and those are fueled by large

1587
01:08:45,640 --> 01:08:49,640
language models llm so tell let me tell

1588
01:08:47,759 --> 01:08:51,960
you a little bit more about those so

1589
01:08:49,640 --> 01:08:54,839
llms as the name suggest are large

1590
01:08:51,960 --> 01:08:56,239
language models um and we'll see what

1591
01:08:54,839 --> 01:08:59,480
large means

1592
01:08:56,239 --> 01:09:01,040
me and um they are sophisticated tubs

1593
01:08:59,480 --> 01:09:02,799
are neural networks right we were just

1594
01:09:01,040 --> 01:09:04,480
playing with neural Nets you should know

1595
01:09:02,799 --> 01:09:05,440
by now that it's just another formula

1596
01:09:04,480 --> 01:09:08,640
it's a

1597
01:09:05,440 --> 01:09:12,159
mathematical uh equation that's quite

1598
01:09:08,640 --> 01:09:15,319
complex um and we played with the

1599
01:09:12,159 --> 01:09:17,600
tensorflow uh playground which uh you

1600
01:09:15,319 --> 01:09:19,920
can build your own neural net you can

1601
01:09:17,600 --> 01:09:21,759
decide how many uh hidden layers it has

1602
01:09:19,920 --> 01:09:23,159
and how many neurons per layer and how

1603
01:09:21,759 --> 01:09:24,400
they're connected I don't think you can

1604
01:09:23,159 --> 01:09:27,560
change how they're connected I think

1605
01:09:24,400 --> 01:09:29,480
it's a feed forward neural net um but

1606
01:09:27,560 --> 01:09:31,960
anyway it's just another type of neural

1607
01:09:29,480 --> 01:09:35,600
Nets with a particular

1608
01:09:31,960 --> 01:09:37,000
uh uh architecture large language models

1609
01:09:35,600 --> 01:09:38,679
are characterized by their large number

1610
01:09:37,000 --> 01:09:42,640
of parameters they're often in the

1611
01:09:38,679 --> 01:09:44,080
billions or trillions um and lmms

1612
01:09:42,640 --> 01:09:46,000
understand the probability distribution

1613
01:09:44,080 --> 01:09:49,400
of words and sequences if I have time at

1614
01:09:46,000 --> 01:09:52,359
the end I'll show you a visualizer of

1615
01:09:49,400 --> 01:09:54,560
the Transformer model which is um the

1616
01:09:52,359 --> 01:09:56,600
heart of these things and and um

1617
01:09:54,560 --> 01:09:58,360
hopefully you'll be able to see what

1618
01:09:56,600 --> 01:10:01,239
this means the probability distribution

1619
01:09:58,360 --> 01:10:02,880
of words in a sequence um the primary

1620
01:10:01,239 --> 01:10:06,600
goal of an nlm is to predict the next

1621
01:10:02,880 --> 01:10:10,560
word it's kind of greedy in its um way

1622
01:10:06,600 --> 01:10:14,199
of working it it really is a next word

1623
01:10:10,560 --> 01:10:15,960
predictor based on uh previous words and

1624
01:10:14,199 --> 01:10:17,199
it can capture both the syntax which is

1625
01:10:15,960 --> 01:10:19,280
the arrangement of words and the

1626
01:10:17,199 --> 01:10:21,719
semantics which is the meaning of words

1627
01:10:19,280 --> 01:10:23,120
and LMS have proven useful for a lot of

1628
01:10:21,719 --> 01:10:25,719
things including translations and

1629
01:10:23,120 --> 01:10:28,640
natural language generation uh speech

1630
01:10:25,719 --> 01:10:30,880
tagging information retrieval um there's

1631
01:10:28,640 --> 01:10:33,719
a lot of different use cases which we're

1632
01:10:30,880 --> 01:10:36,840
going to look into and uh they the way

1633
01:10:33,719 --> 01:10:38,760
they work is uh they use self-supervised

1634
01:10:36,840 --> 01:10:40,440
learning for pre trainining which

1635
01:10:38,760 --> 01:10:41,800
removes the need for explicit labeling

1636
01:10:40,440 --> 01:10:43,159
and it's a really cool technique if you

1637
01:10:41,800 --> 01:10:45,920
want to look under the hood but this is

1638
01:10:43,159 --> 01:10:50,159
out of scope for

1639
01:10:45,920 --> 01:10:52,199
me um example tasks uh that llms can

1640
01:10:50,159 --> 01:10:54,719
accomplish well we know they can read

1641
01:10:52,199 --> 01:10:56,800
okay so they have been super useful in

1642
01:10:54,719 --> 01:10:59,840
things like proof reading summarizing

1643
01:10:56,800 --> 01:11:01,719
analyzing contact classification we know

1644
01:10:59,840 --> 01:11:04,760
they can write so they've been also used

1645
01:11:01,719 --> 01:11:06,719
as stylistic polishing agents answering

1646
01:11:04,760 --> 01:11:10,400
questions first draft

1647
01:11:06,719 --> 01:11:12,679
generation translation code writing and

1648
01:11:10,400 --> 01:11:15,640
because they can read and write uh then

1649
01:11:12,679 --> 01:11:17,080
they can converse um that's actually not

1650
01:11:15,640 --> 01:11:18,080
necessarily true it's not because they

1651
01:11:17,080 --> 01:11:23,000
can do these things they've been

1652
01:11:18,080 --> 01:11:24,880
fine-tuned to do that uh but they we see

1653
01:11:23,000 --> 01:11:29,920
a lot of uh chat Bots a lot of not

1654
01:11:24,880 --> 01:11:32,640
natural language um layers on top of uh

1655
01:11:29,920 --> 01:11:34,960
knowledge bases and so a lot of common

1656
01:11:32,640 --> 01:11:36,800
uses some of the common uses we see is

1657
01:11:34,960 --> 01:11:38,560
you know essay writing summarization

1658
01:11:36,800 --> 01:11:41,600
translation information retrieval

1659
01:11:38,560 --> 01:11:44,480
conversation assistance um image

1660
01:11:41,600 --> 01:11:46,960
generators coding tools there's a lot of

1661
01:11:44,480 --> 01:11:51,199
there's have been a proliferation of use

1662
01:11:46,960 --> 01:11:54,880
cases for um uh

1663
01:11:51,199 --> 01:11:56,560
llms okay oops where am I okay so

1664
01:11:54,880 --> 01:11:58,760
possible issues with L LMS well

1665
01:11:56,560 --> 01:12:03,280
Hallucination is one issue Hallucination

1666
01:11:58,760 --> 01:12:06,360
is the uh is when a

1667
01:12:03,280 --> 01:12:09,600
model proper information and so it comes

1668
01:12:06,360 --> 01:12:12,760
up with a very reasonably sounding

1669
01:12:09,600 --> 01:12:17,560
explanation and because the objective

1670
01:12:12,760 --> 01:12:20,280
function of an llm is to optimize for

1671
01:12:17,560 --> 01:12:22,760
next sequence prediction based on

1672
01:12:20,280 --> 01:12:27,000
probabilities it's not optimizing for

1673
01:12:22,760 --> 01:12:30,239
accuracy right it it's optimizing for

1674
01:12:27,000 --> 01:12:32,560
um sentences that sound reasonable not

1675
01:12:30,239 --> 01:12:34,280
sentences that are necessarily accurate

1676
01:12:32,560 --> 01:12:37,239
okay so that's the very important thing

1677
01:12:34,280 --> 01:12:41,960
to know and so it

1678
01:12:37,239 --> 01:12:45,639
sounds like human sentences the actual

1679
01:12:41,960 --> 01:12:47,920
content um and accuracy is beyond the

1680
01:12:45,639 --> 01:12:51,440
scope of the llm right it it has seen

1681
01:12:47,920 --> 01:12:53,199
information and if it sees it enough

1682
01:12:51,440 --> 01:12:55,760
then the probabilities would reflect

1683
01:12:53,199 --> 01:12:58,840
that but it's not optimization for

1684
01:12:55,760 --> 01:13:00,719
accuracy in general okay so that's

1685
01:12:58,840 --> 01:13:03,320
called Hallucination is when it comes up

1686
01:13:00,719 --> 01:13:06,560
with a response that is that sounds

1687
01:13:03,320 --> 01:13:11,040
reasonable but it's not it made it up um

1688
01:13:06,560 --> 01:13:12,679
knowledge cut offs um models only see uh

1689
01:13:11,040 --> 01:13:14,920
only know about data they've seen up to

1690
01:13:12,679 --> 01:13:16,480
a point so if a model was trained in

1691
01:13:14,920 --> 01:13:18,480
2024 and you say well who's the

1692
01:13:16,480 --> 01:13:21,239
president that was voted in 2025 it does

1693
01:13:18,480 --> 01:13:23,040
not know because it did not see that

1694
01:13:21,239 --> 01:13:24,840
information uh there's issues with

1695
01:13:23,040 --> 01:13:27,840
context windows or or that's at least a

1696
01:13:24,840 --> 01:13:31,480
property is how much information can it

1697
01:13:27,840 --> 01:13:33,719
take in or spit out um and that varies

1698
01:13:31,480 --> 01:13:37,600
widely by models there's issues with

1699
01:13:33,719 --> 01:13:40,480
biason toxicity the model sees data from

1700
01:13:37,600 --> 01:13:45,120
the internet which of course um there's

1701
01:13:40,480 --> 01:13:48,639
a lot of biases um baked into data and

1702
01:13:45,120 --> 01:13:49,960
so the model sometimes reflects that um

1703
01:13:48,639 --> 01:13:51,360
there's still not really great at

1704
01:13:49,960 --> 01:13:53,080
structured or tabular data and they're

1705
01:13:51,360 --> 01:13:54,639
not really good at number processing and

1706
01:13:53,080 --> 01:13:56,639
we'll see why there's a few issues where

1707
01:13:54,639 --> 01:13:58,360
they're not necessarily great at but

1708
01:13:56,639 --> 01:14:01,080
they are very powerful and they do a lot

1709
01:13:58,360 --> 01:14:04,120
of really cool things and we'll see some

1710
01:14:01,080 --> 01:14:06,800
of those things okay so again I'll go

1711
01:14:04,120 --> 01:14:08,480
through terminology or or glossery some

1712
01:14:06,800 --> 01:14:10,560
of it might seem abstract we're going to

1713
01:14:08,480 --> 01:14:12,040
talk a lot about these things in details

1714
01:14:10,560 --> 01:14:13,440
but these are things we hear about so

1715
01:14:12,040 --> 01:14:15,480
again we talked about artificial

1716
01:14:13,440 --> 01:14:16,880
intelligence in one of the lectures it's

1717
01:14:15,480 --> 01:14:19,920
techniques that enable computers to

1718
01:14:16,880 --> 01:14:23,080
mimic human behavior ml or machine

1719
01:14:19,920 --> 01:14:25,199
learning is a subset of that so it is

1720
01:14:23,080 --> 01:14:26,719
techniques that allow computers to learn

1721
01:14:25,199 --> 01:14:30,600
without explicit programming so they're

1722
01:14:26,719 --> 01:14:32,440
making the learning um side of humans

1723
01:14:30,600 --> 01:14:34,080
generative AI is a type of AI that

1724
01:14:32,440 --> 01:14:35,920
allows computers to generate new content

1725
01:14:34,080 --> 01:14:37,840
we've seen all of this now what is an

1726
01:14:35,920 --> 01:14:39,520
llm it's a large language model so it's

1727
01:14:37,840 --> 01:14:40,440
an umbrella term for model specialized

1728
01:14:39,520 --> 01:14:42,679
in

1729
01:14:40,440 --> 01:14:44,560
language what is a Transformer so the

1730
01:14:42,679 --> 01:14:47,320
Transformer is an algorithm or a neural

1731
01:14:44,560 --> 01:14:49,480
network that revolutionaries gen and

1732
01:14:47,320 --> 01:14:51,920
underlies LM so it's the heart of the

1733
01:14:49,480 --> 01:14:55,719
llm is the actual the

1734
01:14:51,920 --> 01:14:58,639
actual um architecture that underly ize

1735
01:14:55,719 --> 01:15:01,040
this LNM a prompt is the input to the

1736
01:14:58,639 --> 01:15:02,800
model it's the actual text that you're

1737
01:15:01,040 --> 01:15:05,679
giving the model that's the input it's

1738
01:15:02,800 --> 01:15:07,719
called The Prompt um a token is a word

1739
01:15:05,679 --> 01:15:10,120
or part of the world it's the currency

1740
01:15:07,719 --> 01:15:12,480
of an llm so the context windows that we

1741
01:15:10,120 --> 01:15:15,960
talked about how much it in takes in or

1742
01:15:12,480 --> 01:15:18,880
spits out is um it's the unit of

1743
01:15:15,960 --> 01:15:21,400
measuring input and output size is a

1744
01:15:18,880 --> 01:15:23,480
token an embedding is a numerical

1745
01:15:21,400 --> 01:15:25,120
representation of a non-numerical entity

1746
01:15:23,480 --> 01:15:26,840
so it's it's a projection into math

1747
01:15:25,120 --> 01:15:28,360
medical space and we'll see why this is

1748
01:15:26,840 --> 01:15:31,440
important

1749
01:15:28,360 --> 01:15:33,280
um rag we hear a lot this is a retrieval

1750
01:15:31,440 --> 01:15:35,760
augmented generation this is the use of

1751
01:15:33,280 --> 01:15:37,040
an external knowledge base to augment uh

1752
01:15:35,760 --> 01:15:39,120
the system again I wanted to put them

1753
01:15:37,040 --> 01:15:41,400
all here but we're going to go into more

1754
01:15:39,120 --> 01:15:43,639
detail a foundational model is an ml

1755
01:15:41,400 --> 01:15:46,400
model trained on vast data sets so that

1756
01:15:43,639 --> 01:15:48,400
it could be applied across a wide range

1757
01:15:46,400 --> 01:15:51,520
of use cases so this is a very powerful

1758
01:15:48,400 --> 01:15:56,159
model that somebody trained uh that you

1759
01:15:51,520 --> 01:15:58,840
can use for a wide variety of tasks

1760
01:15:56,159 --> 01:16:01,120
so one of the things that people I think

1761
01:15:58,840 --> 01:16:05,199
don't really realize is the

1762
01:16:01,120 --> 01:16:07,639
size difference between gen models and

1763
01:16:05,199 --> 01:16:09,360
predictive ml models and as I said in

1764
01:16:07,639 --> 01:16:12,000
some of the previous lectures the bigger

1765
01:16:09,360 --> 01:16:14,600
the model the more capable of learning

1766
01:16:12,000 --> 01:16:16,840
it is needs more data but there's more

1767
01:16:14,600 --> 01:16:20,120
tunable knobs and more information at

1768
01:16:16,840 --> 01:16:23,480
Canon code okay and so um I want to just

1769
01:16:20,120 --> 01:16:27,719
give you an idea of the generative AI

1770
01:16:23,480 --> 01:16:29,400
size uh size so MLS like I said are

1771
01:16:27,719 --> 01:16:31,880
sized by the number of parameters this

1772
01:16:29,400 --> 01:16:35,000
tells you this is aoxy for how big the

1773
01:16:31,880 --> 01:16:36,800
model is and it ranges from one

1774
01:16:35,000 --> 01:16:39,120
parameter so we've been playing with

1775
01:16:36,800 --> 01:16:42,080
logistic regression uh linear regression

1776
01:16:39,120 --> 01:16:44,000
sorry with two parameters ax plus b um

1777
01:16:42,080 --> 01:16:46,280
it could be as small as y equals ax

1778
01:16:44,000 --> 01:16:48,679
right this is a line that passes through

1779
01:16:46,280 --> 01:16:51,000
the the

1780
01:16:48,679 --> 01:16:53,000
axis there's no I don't think there's

1781
01:16:51,000 --> 01:16:54,880
any real use case for that but you can

1782
01:16:53,000 --> 01:16:56,719
imagine that that is the smallest Poss

1783
01:16:54,880 --> 01:17:00,159
ible equation and they can go all the

1784
01:16:56,719 --> 01:17:03,239
way to two uh terabytes of parameters I

1785
01:17:00,159 --> 01:17:06,159
think um if the leaks are correct I

1786
01:17:03,239 --> 01:17:09,280
think uh gpts are about 1.8 so I'm I'm

1787
01:17:06,159 --> 01:17:12,080
averaging about two trillion

1788
01:17:09,280 --> 01:17:14,159
so the predictive ml space is about

1789
01:17:12,080 --> 01:17:18,159
millions of parameters right the biggest

1790
01:17:14,159 --> 01:17:19,120
ml model that I had ever trained is like

1791
01:17:18,159 --> 01:17:22,280
I think a

1792
01:17:19,120 --> 01:17:24,400
64,000 uh convolutional neural network

1793
01:17:22,280 --> 01:17:27,000
right and so thousands and millions of

1794
01:17:24,400 --> 01:17:30,280
parameters in the predictive ml space is

1795
01:17:27,000 --> 01:17:32,120
quite powerful um the generative AI

1796
01:17:30,280 --> 01:17:33,920
models are in the billions of trillions

1797
01:17:32,120 --> 01:17:38,280
of parameters so there's they're roughly

1798
01:17:33,920 --> 01:17:42,679
two orders of magnitude uh greater right

1799
01:17:38,280 --> 01:17:45,239
and this is the NLP mors law and so

1800
01:17:42,679 --> 01:17:49,320
every year model sizes um increased by

1801
01:17:45,239 --> 01:17:52,199
roughly 10x so we can see that um uh

1802
01:17:49,320 --> 01:17:55,080
Bert and GPT for example Bert is about

1803
01:17:52,199 --> 01:17:57,360
340 million parameters here and and this

1804
01:17:55,080 --> 01:18:03,639
is this is um you know

1805
01:17:57,360 --> 01:18:06,199
2018 um the the gpt3 was at 170 and now

1806
01:18:03,639 --> 01:18:08,639
this is 2021 so it's quite out of date

1807
01:18:06,199 --> 01:18:11,679
but now we've we've reached the 1.82

1808
01:18:08,639 --> 01:18:14,560
trillion parameter

1809
01:18:11,679 --> 01:18:16,679
Mark and I want to give you an estimate

1810
01:18:14,560 --> 01:18:21,040
of what that means in terms of resources

1811
01:18:16,679 --> 01:18:25,040
so a single parameter um in a model or

1812
01:18:21,040 --> 01:18:26,800
or a a single number um it when it's in

1813
01:18:25,040 --> 01:18:30,639
the computer on the computer it's stored

1814
01:18:26,800 --> 01:18:33,639
usually as a 32 FL bit float right and

1815
01:18:30,639 --> 01:18:35,639
what that takes is about four four bytes

1816
01:18:33,639 --> 01:18:38,120
and so if you've got a billion

1817
01:18:35,639 --> 01:18:39,480
parameters just as a paark we we've got

1818
01:18:38,120 --> 01:18:41,440
two trillion but let's say you've got a

1819
01:18:39,480 --> 01:18:43,639
billion parameters that's roughly about

1820
01:18:41,440 --> 01:18:45,320
four gigabytes of RAM just for the

1821
01:18:43,639 --> 01:18:49,320
parameters to

1822
01:18:45,320 --> 01:18:52,040
load right but when you actually train

1823
01:18:49,320 --> 01:18:54,960
the model you need roughly about two 20

1824
01:18:52,040 --> 01:18:56,400
times more space because of that whole

1825
01:18:54,960 --> 01:18:59,239
go we talked about so you've got your

1826
01:18:56,400 --> 01:19:00,840
parameters you're making predictions

1827
01:18:59,239 --> 01:19:03,000
you're calculating errors you're

1828
01:19:00,840 --> 01:19:05,360
updating parameters and you saving some

1829
01:19:03,000 --> 01:19:07,000
metadata and you've got activations

1830
01:19:05,360 --> 01:19:09,000
you've got gradients you've got the

1831
01:19:07,000 --> 01:19:10,920
optimizer and so there's a lot of U

1832
01:19:09,000 --> 01:19:13,000
metadata that is saved across that

1833
01:19:10,920 --> 01:19:15,560
process and it takes about 20 times more

1834
01:19:13,000 --> 01:19:16,920
space than the parameter size to train

1835
01:19:15,560 --> 01:19:21,000
and so if you've got a 1 billion

1836
01:19:16,920 --> 01:19:24,480
parameter model uh you need about 80 gb

1837
01:19:21,000 --> 01:19:28,719
uh of ram to to actually train this

1838
01:19:24,480 --> 01:19:30,679
thing and as you see um we've been we we

1839
01:19:28,719 --> 01:19:34,120
were over the 1 billion parameter models

1840
01:19:30,679 --> 01:19:36,000
a long time ago these are um reference

1841
01:19:34,120 --> 01:19:38,960
this this of course comes from the uh

1842
01:19:36,000 --> 01:19:41,159
corser course Andrew Ang's corser course

1843
01:19:38,960 --> 01:19:43,480
um if you want to look at that reference

1844
01:19:41,159 --> 01:19:48,679
so imagine the requirements of about 1.8

1845
01:19:43,480 --> 01:19:50,840
trillion model right so these systems um

1846
01:19:48,679 --> 01:19:53,639
are very large and they've put

1847
01:19:50,840 --> 01:19:55,280
constraints on compute and data and

1848
01:19:53,639 --> 01:19:57,239
they've made parall Iz ation and

1849
01:19:55,280 --> 01:19:59,719
optimization both at the hardware level

1850
01:19:57,239 --> 01:20:02,440
and a software level a must so there's a

1851
01:19:59,719 --> 01:20:06,360
lot of work in the Gen space to optimize

1852
01:20:02,440 --> 01:20:11,760
everything from compute to memory to

1853
01:20:06,360 --> 01:20:15,639
processing to um loading everything it's

1854
01:20:11,760 --> 01:20:18,360
really forced us to really push

1855
01:20:15,639 --> 01:20:20,239
optimizations to be able to a better

1856
01:20:18,360 --> 01:20:23,360
support these

1857
01:20:20,239 --> 01:20:26,159
things so this is um this is a really

1858
01:20:23,360 --> 01:20:29,440
cool slide that um I've taken from a

1859
01:20:26,159 --> 01:20:33,120
lecture that Yan Dua a

1860
01:20:29,440 --> 01:20:34,639
doctoral uh candidate in at Stanford uh

1861
01:20:33,120 --> 01:20:36,880
gave this is on YouTube you could see it

1862
01:20:34,639 --> 01:20:40,040
in the reference uh section I have a

1863
01:20:36,880 --> 01:20:42,360
reference section and um it's uh if you

1864
01:20:40,040 --> 01:20:43,840
Google Stanford CS 229 lecture you

1865
01:20:42,360 --> 01:20:45,159
should be able to find it but anyway

1866
01:20:43,840 --> 01:20:46,880
these are not my estimates these are

1867
01:20:45,159 --> 01:20:48,880
yand duas but they're really cool to

1868
01:20:46,880 --> 01:20:51,280
give you an estimate of again the

1869
01:20:48,880 --> 01:20:54,920
resources required for training and so

1870
01:20:51,280 --> 01:20:58,679
he uses the example of uh Lama 3 which

1871
01:20:54,920 --> 01:21:01,000
is about 400 billion parameters large

1872
01:20:58,679 --> 01:21:03,120
and so it's exactly 405 billion it's

1873
01:21:01,000 --> 01:21:05,480
trained on data that's about 15.6

1874
01:21:03,120 --> 01:21:07,960
trillion tokens

1875
01:21:05,480 --> 01:21:10,120
um the token per parameter ratio is

1876
01:21:07,960 --> 01:21:12,080
about 40 tokens per parameter which

1877
01:21:10,120 --> 01:21:14,440
means that it is train compute optimal

1878
01:21:12,080 --> 01:21:16,560
we didn't talk about this but there is a

1879
01:21:14,440 --> 01:21:18,760
paper uh that came

1880
01:21:16,560 --> 01:21:20,639
out called the chinella paper which

1881
01:21:18,760 --> 01:21:21,520
looked at these are called scaling laws

1882
01:21:20,639 --> 01:21:25,719
this

1883
01:21:21,520 --> 01:21:28,440
is information about how the performance

1884
01:21:25,719 --> 01:21:30,440
relates um performance and model relates

1885
01:21:28,440 --> 01:21:33,000
to a model size and and resources it

1886
01:21:30,440 --> 01:21:36,239
used in terms of uh various things we

1887
01:21:33,000 --> 01:21:38,520
can look at and in the paper I think

1888
01:21:36,239 --> 01:21:41,480
their estimate was

1889
01:21:38,520 --> 01:21:43,280
that they need you need 20 times the

1890
01:21:41,480 --> 01:21:47,440
number of

1891
01:21:43,280 --> 01:21:49,360
tokens so if it there should be 20 times

1892
01:21:47,440 --> 01:21:51,719
more tokens than parameter size for an

1893
01:21:49,360 --> 01:21:53,960
optimally trained model I think and so

1894
01:21:51,719 --> 01:21:56,000
This Is 40 tokens so they're they're

1895
01:21:53,960 --> 01:21:59,400
higher than that which means that they

1896
01:21:56,000 --> 01:22:02,960
um it's train compute optimal and these

1897
01:21:59,400 --> 01:22:06,120
are the flops so this is how much um in

1898
01:22:02,960 --> 01:22:08,320
a compute it would need uh and so this

1899
01:22:06,120 --> 01:22:10,000
is the 6 NP so we would need six times

1900
01:22:08,320 --> 01:22:12,400
the size of the data sets times the size

1901
01:22:10,000 --> 01:22:15,880
of the model which comes out to this

1902
01:22:12,400 --> 01:22:17,679
number here they in the paper they say

1903
01:22:15,880 --> 01:22:21,280
that they trained it on

1904
01:22:17,679 --> 01:22:23,960
16,000 16,000 gpus that's how many uh

1905
01:22:21,280 --> 01:22:27,159
h100 Nvidia gpus uh which have an

1906
01:22:23,960 --> 01:22:29,639
average throughput I I fixed the error I

1907
01:22:27,159 --> 01:22:32,320
fixed the typo but I left the O uh of

1908
01:22:29,639 --> 01:22:34,360
400 Tera flops and so that comes to

1909
01:22:32,320 --> 01:22:36,480
about 70 days so if you go in and say

1910
01:22:34,360 --> 01:22:38,679
okay well this this is how much compute

1911
01:22:36,480 --> 01:22:40,000
I I need and this is how much I have you

1912
01:22:38,679 --> 01:22:42,320
divide these two numbers you get about

1913
01:22:40,000 --> 01:22:45,920
70 days in the paper they say that you

1914
01:22:42,320 --> 01:22:48,840
used about uh 30 million GPU hours which

1915
01:22:45,920 --> 01:22:51,719
again comes to pretty close to about 70

1916
01:22:48,840 --> 01:22:55,440
days to train this model and so in terms

1917
01:22:51,719 --> 01:22:57,040
of cost um he has Young has a lot more

1918
01:22:55,440 --> 01:22:59,360
information about estimates he's

1919
01:22:57,040 --> 01:23:01,239
estimating that the saty of these people

1920
01:22:59,360 --> 01:23:03,679
is about half a million and so on and

1921
01:23:01,239 --> 01:23:07,000
and more information but he he comes up

1922
01:23:03,679 --> 01:23:09,840
with an estimate that this the the price

1923
01:23:07,000 --> 01:23:13,239
tag of this model training is going to

1924
01:23:09,840 --> 01:23:16,400
be about is is about 65 to 85

1925
01:23:13,239 --> 01:23:17,679
million um and the carbon emitted is

1926
01:23:16,400 --> 01:23:22,120
about

1927
01:23:17,679 --> 01:23:24,880
440 I guess that's ter Terra

1928
01:23:22,120 --> 01:23:28,639
CO2 um which is equivalent to about ,000

1929
01:23:24,880 --> 01:23:31,120
return tickets from JFK to London okay

1930
01:23:28,639 --> 01:23:34,080
and so

1931
01:23:31,120 --> 01:23:37,560
um this shows you that training a model

1932
01:23:34,080 --> 01:23:40,560
from scratch which is uh is really

1933
01:23:37,560 --> 01:23:43,560
really intense and it's not for the

1934
01:23:40,560 --> 01:23:48,040
average uh individual anymore so so it's

1935
01:23:43,560 --> 01:23:51,920
now been constrained to companies that

1936
01:23:48,040 --> 01:23:54,960
have a lot of resources um you know uh

1937
01:23:51,920 --> 01:23:58,159
and they release these models for

1938
01:23:54,960 --> 01:24:00,159
General use either as they can allow you

1939
01:23:58,159 --> 01:24:02,679
to use it as a as close source as a SAS

1940
01:24:00,159 --> 01:24:05,480
solution so they put an API and they

1941
01:24:02,679 --> 01:24:09,199
allow you to call that API for cost some

1942
01:24:05,480 --> 01:24:10,880
people like meta um they release uh the

1943
01:24:09,199 --> 01:24:12,199
open weight model so that means that

1944
01:24:10,880 --> 01:24:14,880
they release the weights of the models

1945
01:24:12,199 --> 01:24:18,120
and so you can play with it uh and and

1946
01:24:14,880 --> 01:24:20,840
deploy it locally but they don't release

1947
01:24:18,120 --> 01:24:22,560
um code or information about how it was

1948
01:24:20,840 --> 01:24:24,480
trained nor the data set and then

1949
01:24:22,560 --> 01:24:25,880
there's open source models which relas

1950
01:24:24,480 --> 01:24:28,280
everything so they release the the

1951
01:24:25,880 --> 01:24:30,360
weights they release the data was

1952
01:24:28,280 --> 01:24:31,719
trained on and the process of which it

1953
01:24:30,360 --> 01:24:33,120
was trained so you can reproduce that

1954
01:24:31,719 --> 01:24:37,000
process

1955
01:24:33,120 --> 01:24:39,320
and usually um academics go for open

1956
01:24:37,000 --> 01:24:41,199
source and so they uh release everything

1957
01:24:39,320 --> 01:24:42,679
they don't have these budgets I I I was

1958
01:24:41,199 --> 01:24:44,760
an academic for a really long time we

1959
01:24:42,679 --> 01:24:47,000
don't see these budgets and so work in

1960
01:24:44,760 --> 01:24:48,360
Academia interestingly enough um

1961
01:24:47,000 --> 01:24:51,080
artificial intelligence or machine

1962
01:24:48,360 --> 01:24:53,560
learning is one of those very few cases

1963
01:24:51,080 --> 01:24:56,560
where industry has taken over um

1964
01:24:53,560 --> 01:25:00,080
academic like it it has superseded

1965
01:24:56,560 --> 01:25:03,360
academic research uh because of small

1966
01:25:00,080 --> 01:25:06,600
budgets for labs a lot of what academics

1967
01:25:03,360 --> 01:25:08,880
do is really focus on algorithms how do

1968
01:25:06,600 --> 01:25:12,440
you perfect the algorithm how do you do

1969
01:25:08,880 --> 01:25:14,840
smart tricks to uh be able to do some of

1970
01:25:12,440 --> 01:25:16,400
these things at at a better cost right

1971
01:25:14,840 --> 01:25:20,440
whereas industry there's a lot of money

1972
01:25:16,400 --> 01:25:22,760
and so they they crank up the compute um

1973
01:25:20,440 --> 01:25:25,639
and so some of the notes is what is the

1974
01:25:22,760 --> 01:25:27,520
next model well there's usually a 10x uh

1975
01:25:25,639 --> 01:25:29,760
more flop so the the the factor of

1976
01:25:27,520 --> 01:25:34,199
increase from cycle to cycle is roughly

1977
01:25:29,760 --> 01:25:36,040
10x and um the complexity of this

1978
01:25:34,199 --> 01:25:38,000
process of the training process grows

1979
01:25:36,040 --> 01:25:40,960
quadratically with the length of the

1980
01:25:38,000 --> 01:25:44,159
input sequence so the more data it sees

1981
01:25:40,960 --> 01:25:49,040
then the more uh it needs a

1982
01:25:44,159 --> 01:25:50,440
quadratic amount of uh resources from

1983
01:25:49,040 --> 01:25:53,679
there

1984
01:25:50,440 --> 01:25:58,159
okay so again just to compare predictive

1985
01:25:53,679 --> 01:25:59,960
ml versus gen um the model sizes are

1986
01:25:58,159 --> 01:26:02,480
very different again in the Millions for

1987
01:25:59,960 --> 01:26:04,119
predictive ml for genis the millions of

1988
01:26:02,480 --> 01:26:06,800
trillions that means that the data

1989
01:26:04,119 --> 01:26:09,040
demands are also very different so you

1990
01:26:06,800 --> 01:26:10,960
need a lot more data for Gen than you do

1991
01:26:09,040 --> 01:26:14,119
for predictive ML and of course that

1992
01:26:10,960 --> 01:26:18,560
means that the training compute is a lot

1993
01:26:14,119 --> 01:26:21,639
uh bigger and so I was able to train uh

1994
01:26:18,560 --> 01:26:25,679
predictive ML on my computer um I don't

1995
01:26:21,639 --> 01:26:29,360
think most of us can train uh a gen

1996
01:26:25,679 --> 01:26:32,840
model at least not not a serious one um

1997
01:26:29,360 --> 01:26:36,000
actually no I should say um uh Andre

1998
01:26:32,840 --> 01:26:38,320
karpati who is a part of who is a really

1999
01:26:36,000 --> 01:26:42,000
big name in machine learning has written

2000
01:26:38,320 --> 01:26:45,560
a nano GPT again you can see this in the

2001
01:26:42,000 --> 01:26:47,239
um reference section uh a nanog GPT

2002
01:26:45,560 --> 01:26:48,920
which is a smaller model it's about it's

2003
01:26:47,239 --> 01:26:50,560
less than 300 lines of so you'll be

2004
01:26:48,920 --> 01:26:52,880
able to see what it looks like and you'd

2005
01:26:50,560 --> 01:26:55,520
be able to run it and train it um I

2006
01:26:52,880 --> 01:26:59,239
think so if you're interested to look at

2007
01:26:55,520 --> 01:27:01,199
that and so um in terms of training uh

2008
01:26:59,239 --> 01:27:02,760
the way that predictive MLS uses usually

2009
01:27:01,199 --> 01:27:06,760
you customize the model with your own

2010
01:27:02,760 --> 01:27:09,320
data uh but with geni you it the

2011
01:27:06,760 --> 01:27:11,880
training is usually done uh by big

2012
01:27:09,320 --> 01:27:13,960
providers and releas to the public uh

2013
01:27:11,880 --> 01:27:16,960
for use cases predictive Amal is better

2014
01:27:13,960 --> 01:27:20,119
at very specific tasks uh whereas gen is

2015
01:27:16,960 --> 01:27:24,239
capable of General tasks in terms of

2016
01:27:20,119 --> 01:27:27,400
cost um predictive ml

2017
01:27:24,239 --> 01:27:28,600
can be cheap is cheaper so cost divides

2018
01:27:27,400 --> 01:27:29,920
into a lot of things right there's the

2019
01:27:28,600 --> 01:27:31,000
training cost there's the inference cost

2020
01:27:29,920 --> 01:27:33,639
and then there's the total cost of

2021
01:27:31,000 --> 01:27:35,639
ownership in terms of training cost gen

2022
01:27:33,639 --> 01:27:38,199
definitely costs more in terms of

2023
01:27:35,639 --> 01:27:40,840
inference um it should definitely cost

2024
01:27:38,199 --> 01:27:43,239
more because it's a bigger model um but

2025
01:27:40,840 --> 01:27:44,520
it depends on whether uh you're using a

2026
01:27:43,239 --> 01:27:46,239
s solution or you're deploying it

2027
01:27:44,520 --> 01:27:47,920
yourself but in general predictive

2028
01:27:46,239 --> 01:27:51,679
amount is

2029
01:27:47,920 --> 01:27:54,920
cheaper where it becomes cheaper to use

2030
01:27:51,679 --> 01:27:56,760
gen is If instead of of training if

2031
01:27:54,920 --> 01:27:59,159
there's not a predictive ml model that's

2032
01:27:56,760 --> 01:28:01,400
pre-trained and you have to hire people

2033
01:27:59,159 --> 01:28:04,080
to train that model and find data and do

2034
01:28:01,400 --> 01:28:07,520
all of that and a gen model can already

2035
01:28:04,080 --> 01:28:12,639
do that you really save that piece and

2036
01:28:07,520 --> 01:28:16,400
so when um a pre-trained predictive ml

2037
01:28:12,639 --> 01:28:18,679
model doesn't exist than a gen model can

2038
01:28:16,400 --> 01:28:21,719
be cheaper because you're saving on

2039
01:28:18,679 --> 01:28:24,199
setting up that model if you

2040
01:28:21,719 --> 01:28:25,760
will so the difficulty in predictive ml

2041
01:28:24,199 --> 01:28:28,320
like I said is really understanding data

2042
01:28:25,760 --> 01:28:30,000
and data processing ml algorithm ml Ops

2043
01:28:28,320 --> 01:28:32,600
it's a pretty complex process the

2044
01:28:30,000 --> 01:28:34,760
difficulty in gen is really about model

2045
01:28:32,600 --> 01:28:36,520
selection um prompt engineering

2046
01:28:34,760 --> 01:28:40,639
evaluation because they produce

2047
01:28:36,520 --> 01:28:44,199
open-ended results in terms of AWS tools

2048
01:28:40,639 --> 01:28:46,920
um predictive ml um the the main service

2049
01:28:44,199 --> 01:28:48,880
for that is uh Amazon Sage maker and for

2050
01:28:46,920 --> 01:28:52,600
Gen is

2051
01:28:48,880 --> 01:28:54,760
bedrock okay so now choosing gen versus

2052
01:28:52,600 --> 01:28:56,880
uh predictive ml the main difference

2053
01:28:54,760 --> 01:28:58,080
between gen and predictive ml just

2054
01:28:56,880 --> 01:28:59,960
there's a lot of differences but the

2055
01:28:58,080 --> 01:29:03,600
main three big ones is really the model

2056
01:28:59,960 --> 01:29:05,199
training usually for Gen you can't train

2057
01:29:03,600 --> 01:29:07,320
the model from scratch just because of

2058
01:29:05,199 --> 01:29:11,239
the the estimates that we just saw in

2059
01:29:07,320 --> 01:29:13,440
predictive ml it's a lot more um uh it's

2060
01:29:11,239 --> 01:29:16,800
easier and so a lot of people do it in

2061
01:29:13,440 --> 01:29:19,000
terms of and often you don't there is a

2062
01:29:16,800 --> 01:29:21,199
lot of pre-trained models out there but

2063
01:29:19,000 --> 01:29:22,679
sometimes for your particular use case

2064
01:29:21,199 --> 01:29:25,080
uh you might have to train your own

2065
01:29:22,679 --> 01:29:27,080
model the model sizes and the required

2066
01:29:25,080 --> 01:29:29,960
resources are just vastly different like

2067
01:29:27,080 --> 01:29:32,440
we just saw and gen uh produces

2068
01:29:29,960 --> 01:29:34,760
open-ended outputs which makes them a

2069
01:29:32,440 --> 01:29:37,639
lot harder to

2070
01:29:34,760 --> 01:29:39,880
evaluate we I what I recommend to people

2071
01:29:37,639 --> 01:29:43,040
is use gen foundational models for

2072
01:29:39,880 --> 01:29:44,960
General tasks uh for quick turnaround so

2073
01:29:43,040 --> 01:29:47,480
if you want uh you don't have the time

2074
01:29:44,960 --> 01:29:50,080
to get your data to to train the model

2075
01:29:47,480 --> 01:29:52,480
to to evaluate it to deploy it to do to

2076
01:29:50,080 --> 01:29:54,199
run that whole cycle then um a

2077
01:29:52,480 --> 01:29:56,760
foundational model that is ready ready

2078
01:29:54,199 --> 01:29:58,639
to go is is a good good option if you

2079
01:29:56,760 --> 01:30:00,360
don't have the expertise uh then

2080
01:29:58,639 --> 01:30:01,840
something that is pre-done is better but

2081
01:30:00,360 --> 01:30:04,040
if you can find a

2082
01:30:01,840 --> 01:30:05,159
predictive uh model that's pre-trained

2083
01:30:04,040 --> 01:30:06,199
it's going to be cheaper and I'll show

2084
01:30:05,159 --> 01:30:09,159
you an

2085
01:30:06,199 --> 01:30:12,040
example and uh if you don't have data

2086
01:30:09,159 --> 01:30:14,480
then uh Foundation models are a good

2087
01:30:12,040 --> 01:30:16,600
idea you use predictive ml for very

2088
01:30:14,480 --> 01:30:19,400
specific tasks um tasks that require

2089
01:30:16,600 --> 01:30:22,199
great accuracy because um you can

2090
01:30:19,400 --> 01:30:24,880
control accuracy and uh compliance a lot

2091
01:30:22,199 --> 01:30:27,679
more with predictive ml than than just I

2092
01:30:24,880 --> 01:30:30,639
if something is a long-term project the

2093
01:30:27,679 --> 01:30:33,080
the the price of a gen model will catch

2094
01:30:30,639 --> 01:30:35,800
up to you if it's a really long-term

2095
01:30:33,080 --> 01:30:39,040
project training your own model in the

2096
01:30:35,800 --> 01:30:41,119
long run uh will become worth it and if

2097
01:30:39,040 --> 01:30:44,280
the large the project load is really

2098
01:30:41,119 --> 01:30:47,159
large so if if you're pinging that model

2099
01:30:44,280 --> 01:30:48,760
millions of times a day then again the

2100
01:30:47,159 --> 01:30:50,520
costs will catch up to you and so owning

2101
01:30:48,760 --> 01:30:53,000
your own model and having a smaller

2102
01:30:50,520 --> 01:30:54,600
model that's customized for you um is

2103
01:30:53,000 --> 01:30:56,760
definitely a better idea and if you have

2104
01:30:54,600 --> 01:30:59,000
high compliance projects because you

2105
01:30:56,760 --> 01:31:02,000
have a lot more control potentially over

2106
01:30:59,000 --> 01:31:04,000
a predictive model than a gen

2107
01:31:02,000 --> 01:31:06,080
model okay so I'm going to give you an

2108
01:31:04,000 --> 01:31:08,800
idea about the trading data um again I'm

2109
01:31:06,080 --> 01:31:11,320
going to go through it fairly fast but

2110
01:31:08,800 --> 01:31:13,800
it's it's good to see um collecting data

2111
01:31:11,320 --> 01:31:16,560
is really hard work um and often it's a

2112
01:31:13,800 --> 01:31:18,040
heavily guarded Secret by companies they

2113
01:31:16,560 --> 01:31:19,560
don't always tell you what they're doing

2114
01:31:18,040 --> 01:31:22,040
and how they're doing it for a variety

2115
01:31:19,560 --> 01:31:23,600
of reasons I mean some of it is because

2116
01:31:22,040 --> 01:31:24,800
they think of it as the secret sauce for

2117
01:31:23,600 --> 01:31:27,360
What from from what the model is

2118
01:31:24,800 --> 01:31:29,320
learning um a lot of it also is because

2119
01:31:27,360 --> 01:31:31,280
there's compliance and legal issues and

2120
01:31:29,320 --> 01:31:32,760
patent laws and it's not really clear

2121
01:31:31,280 --> 01:31:34,760
what is being collected and how it's

2122
01:31:32,760 --> 01:31:36,880
being used which is very unfortunate but

2123
01:31:34,760 --> 01:31:39,679
anyway um we don't always have that

2124
01:31:36,880 --> 01:31:41,639
information but here's an example of how

2125
01:31:39,679 --> 01:31:43,679
this process would go about you would

2126
01:31:41,639 --> 01:31:45,679
download all of the internet uh and so

2127
01:31:43,679 --> 01:31:47,280
people use web crawlers uh you can look

2128
01:31:45,679 --> 01:31:49,679
at common crawl which indexes the

2129
01:31:47,280 --> 01:31:51,199
internet uh there's currently about 250

2130
01:31:49,679 --> 01:31:54,800
billion pages online which is roughly

2131
01:31:51,199 --> 01:31:57,239
about one p data um

2132
01:31:54,800 --> 01:31:58,600
and you extract you extract the text

2133
01:31:57,239 --> 01:32:00,280
from the HTML so when you scrape the

2134
01:31:58,600 --> 01:32:02,520
Internet it's all HTML docs of course

2135
01:32:00,280 --> 01:32:05,880
you extract the actual text from it you

2136
01:32:02,520 --> 01:32:07,679
filter undesired content uh you do D

2137
01:32:05,880 --> 01:32:09,440
duplicate because of course a lot of uh

2138
01:32:07,679 --> 01:32:11,840
pages are found in different places and

2139
01:32:09,440 --> 01:32:14,520
several times you add hortic to remove

2140
01:32:11,840 --> 01:32:17,440
lowquality documents um there's some

2141
01:32:14,520 --> 01:32:20,440
modelbased filtering as well again to to

2142
01:32:17,440 --> 01:32:23,119
filter out some stuff

2143
01:32:20,440 --> 01:32:24,360
um and then you classify your documents

2144
01:32:23,119 --> 01:32:26,719
to be able to

2145
01:32:24,360 --> 01:32:28,320
to decide on what how much to use of

2146
01:32:26,719 --> 01:32:30,560
what right you don't you definitely want

2147
01:32:28,320 --> 01:32:33,159
don't want a model that that's trained

2148
01:32:30,560 --> 01:32:34,800
on social media predominantly right so

2149
01:32:33,159 --> 01:32:37,679
so understanding what the documents are

2150
01:32:34,800 --> 01:32:40,520
and what they relate to and so on um is

2151
01:32:37,679 --> 01:32:42,080
important and then you use that uh to

2152
01:32:40,520 --> 01:32:43,639
train your model again this is the

2153
01:32:42,080 --> 01:32:47,400
devil's in the details and this is a

2154
01:32:43,639 --> 01:32:50,760
really high overview I think probably

2155
01:32:47,400 --> 01:32:53,840
the the data part the data part of ml is

2156
01:32:50,760 --> 01:32:55,280
usually the longest part of ml um and so

2157
01:32:53,840 --> 01:32:58,040
so this just gives you an idea of the

2158
01:32:55,280 --> 01:33:00,199
steps but this is a long and painful

2159
01:32:58,040 --> 01:33:01,560
process there's some open source

2160
01:33:00,199 --> 01:33:04,719
academic data sets if you're interested

2161
01:33:01,560 --> 01:33:06,119
there's a C4 the pile dolma and fine web

2162
01:33:04,719 --> 01:33:08,840
and if you Google those you should be

2163
01:33:06,119 --> 01:33:11,639
able to find them uh

2164
01:33:08,840 --> 01:33:13,719
online and so again like the the the

2165
01:33:11,639 --> 01:33:15,560
bigger the parameter the model is the

2166
01:33:13,719 --> 01:33:19,400
more parameters it has and the more data

2167
01:33:15,560 --> 01:33:21,960
it needs to see and today's models um

2168
01:33:19,400 --> 01:33:24,119
are trained on about 15 trillion tokens

2169
01:33:21,960 --> 01:33:28,199
so we saw in the Lama 3 model model it

2170
01:33:24,119 --> 01:33:30,480
was about I 15.6 trillion around um so

2171
01:33:28,199 --> 01:33:33,520
that's that's where models are today in

2172
01:33:30,480 --> 01:33:35,239
the words of yan Lun uh it's trained on

2173
01:33:33,520 --> 01:33:37,719
enough data that it would take you and

2174
01:33:35,239 --> 01:33:40,040
me 20,000 years to read so these things

2175
01:33:37,719 --> 01:33:42,719
chug a lot of data and they have a lot

2176
01:33:40,040 --> 01:33:45,639
to learn from and honestly the way they

2177
01:33:42,719 --> 01:33:47,360
work um they can do some wonderful some

2178
01:33:45,639 --> 01:33:49,600
some really amazing things but again

2179
01:33:47,360 --> 01:33:51,520
they they're really big models and they

2180
01:33:49,600 --> 01:33:55,280
see a lot of data that you and I can

2181
01:33:51,520 --> 01:33:59,440
never process in our lifetime

2182
01:33:55,280 --> 01:34:01,360
okay how to choose an llm so um one easy

2183
01:33:59,440 --> 01:34:02,800
way to choose of course the to to to

2184
01:34:01,360 --> 01:34:05,920
constraint your options is looking at

2185
01:34:02,800 --> 01:34:07,280
the input and output uh modalities so uh

2186
01:34:05,920 --> 01:34:10,480
different models there's some models

2187
01:34:07,280 --> 01:34:12,480
that take input text and and and output

2188
01:34:10,480 --> 01:34:14,960
text there's some models that take uh

2189
01:34:12,480 --> 01:34:17,639
text to image image to text videos and

2190
01:34:14,960 --> 01:34:19,280
so on and so you need to understand what

2191
01:34:17,639 --> 01:34:21,400
is going in the model and what is coming

2192
01:34:19,280 --> 01:34:24,000
out and that already uh reduces your

2193
01:34:21,400 --> 01:34:26,320
pool of models you want to look at the

2194
01:34:24,000 --> 01:34:27,920
performance on required tasks so LMS

2195
01:34:26,320 --> 01:34:30,360
have a lot of different capabilities

2196
01:34:27,920 --> 01:34:33,679
there's um and so there's a lot of

2197
01:34:30,360 --> 01:34:36,040
evaluation metrics out there uh that

2198
01:34:33,679 --> 01:34:38,280
they're run on and so there's data sets

2199
01:34:36,040 --> 01:34:39,800
evaluation data sets that uh look at

2200
01:34:38,280 --> 01:34:41,679
reasoning some that look at coding

2201
01:34:39,800 --> 01:34:43,840
someone look at summarization and so on

2202
01:34:41,679 --> 01:34:45,960
and so if you are interested in a coding

2203
01:34:43,840 --> 01:34:48,560
model for example you would want to go

2204
01:34:45,960 --> 01:34:50,480
and pick a model that does really well

2205
01:34:48,560 --> 01:34:53,800
on coding evaluation

2206
01:34:50,480 --> 01:34:56,199
tasks and the way you do that is you um

2207
01:34:53,800 --> 01:34:58,119
um look at the model card the model card

2208
01:34:56,199 --> 01:35:00,159
is you can think of it as the ID of that

2209
01:34:58,119 --> 01:35:02,280
model it's the ID card of that model it

2210
01:35:00,159 --> 01:35:04,000
tell you what that model does what's the

2211
01:35:02,280 --> 01:35:06,800
input what's the output how it was

2212
01:35:04,000 --> 01:35:08,920
trained um how big is it what is it good

2213
01:35:06,800 --> 01:35:11,040
at and so on so by looking at the model

2214
01:35:08,920 --> 01:35:14,000
cards you would be able to uh

2215
01:35:11,040 --> 01:35:16,880
potentially choose one just as a

2216
01:35:14,000 --> 01:35:19,119
ballpark for model sizes a model that is

2217
01:35:16,880 --> 01:35:20,760
a roughly a billion parameters is good

2218
01:35:19,119 --> 01:35:22,960
with pattern matching and basic

2219
01:35:20,760 --> 01:35:25,520
knowledge of the world one it gets to

2220
01:35:22,960 --> 01:35:28,119
the 10 billion it it has greater World

2221
01:35:25,520 --> 01:35:30,440
Knowledge and it can follow

2222
01:35:28,119 --> 01:35:32,960
instructions basic instructions but when

2223
01:35:30,440 --> 01:35:36,000
the model gets over 100 billion then it

2224
01:35:32,960 --> 01:35:37,480
has Rich World Knowledge and complex

2225
01:35:36,000 --> 01:35:40,560
reasoning so depending on the task you

2226
01:35:37,480 --> 01:35:43,440
want to do um but again I I think very

2227
01:35:40,560 --> 01:35:46,320
few no we have 70 billion llama models

2228
01:35:43,440 --> 01:35:48,600
so you can depending on what you do the

2229
01:35:46,320 --> 01:35:50,280
bigger the model it's true that the

2230
01:35:48,600 --> 01:35:52,040
bigger the model the more tasks it can

2231
01:35:50,280 --> 01:35:57,159
do but it also means that the more

2232
01:35:52,040 --> 01:35:59,719
expensive it is to to to have and and

2233
01:35:57,159 --> 01:36:02,960
maintain then there's the close Source

2234
01:35:59,719 --> 01:36:05,119
SAS option versus the open source models

2235
01:36:02,960 --> 01:36:06,600
model options so SAS models again are

2236
01:36:05,119 --> 01:36:08,719
easy to use in application because we're

2237
01:36:06,600 --> 01:36:10,080
calling an API they're more powerful

2238
01:36:08,719 --> 01:36:12,880
models because these companies have a

2239
01:36:10,080 --> 01:36:17,080
lot more money money uh than we do not

2240
01:36:12,880 --> 01:36:20,280
true actually with deep seek now um uh

2241
01:36:17,080 --> 01:36:24,119
but again close sources is more likely

2242
01:36:20,280 --> 01:36:27,600
to um because of the money involved

2243
01:36:24,119 --> 01:36:32,080
I am a great proponent of Open Source

2244
01:36:27,600 --> 01:36:33,920
because with Collective knowledge um you

2245
01:36:32,080 --> 01:36:37,320
know we can get further but again the

2246
01:36:33,920 --> 01:36:40,719
the cost of training is not

2247
01:36:37,320 --> 01:36:42,239
trivial um in terms of Open Source again

2248
01:36:40,719 --> 01:36:44,080
you've got full control of the model you

2249
01:36:42,239 --> 01:36:46,320
can run it on your own devices you can

2250
01:36:44,080 --> 01:36:48,440
have full control of the data privacy so

2251
01:36:46,320 --> 01:36:50,560
you're not sending your data outside of

2252
01:36:48,440 --> 01:36:51,800
your domain there's a lot of other

2253
01:36:50,560 --> 01:36:54,960
things you can consider but these are

2254
01:36:51,800 --> 01:36:55,960
some of the things that I look at

2255
01:36:54,960 --> 01:36:58,960
there is a difference between the

2256
01:36:55,960 --> 01:37:01,400
predictive ML and the Gen life cycle so

2257
01:36:58,960 --> 01:37:03,199
in terms of the predictive ml life cycle

2258
01:37:01,400 --> 01:37:05,119
what we do again we looked at this uh we

2259
01:37:03,199 --> 01:37:06,600
frame the problem Source the data we

2260
01:37:05,119 --> 01:37:08,119
choose the model we train it we test it

2261
01:37:06,600 --> 01:37:11,080
we deploy it and we maintain it and we

2262
01:37:08,119 --> 01:37:13,000
looked at this a couple of times now in

2263
01:37:11,080 --> 01:37:15,360
terms of the Gen life cycle what you do

2264
01:37:13,000 --> 01:37:16,800
is um you Scope your project you look at

2265
01:37:15,360 --> 01:37:18,440
your business requirements then you

2266
01:37:16,800 --> 01:37:21,840
build the system so you choose the model

2267
01:37:18,440 --> 01:37:24,000
you prompt engineer um you adapt that

2268
01:37:21,840 --> 01:37:25,280
model to your needs that you evaluate

2269
01:37:24,000 --> 01:37:28,560
your performance when when you're happy

2270
01:37:25,280 --> 01:37:29,719
with it you deploy it and you U monitor

2271
01:37:28,560 --> 01:37:32,199
the difference the main difference

2272
01:37:29,719 --> 01:37:33,560
really is about this whole sourcing your

2273
01:37:32,199 --> 01:37:36,840
own data and

2274
01:37:33,560 --> 01:37:39,840
training uh which which is not present

2275
01:37:36,840 --> 01:37:42,280
in gen again because of the price tag

2276
01:37:39,840 --> 01:37:44,239
maybe one day uh so whereas predictive

2277
01:37:42,280 --> 01:37:45,800
ml uh much of the work is about

2278
01:37:44,239 --> 01:37:48,159
customizing the model to excel it a

2279
01:37:45,800 --> 01:37:50,360
specific task gen is more about

2280
01:37:48,159 --> 01:37:52,199
extracting what you need from a general

2281
01:37:50,360 --> 01:37:54,320
purpose model so this model knows a lot

2282
01:37:52,199 --> 01:37:58,800
of things it knows 20,00

2283
01:37:54,320 --> 01:38:01,280
years worth of data 13 15 terabytes uh

2284
01:37:58,800 --> 01:38:03,360
trillion tokens 15 trillion tokens and

2285
01:38:01,280 --> 01:38:05,800
you're asking it for maybe what a 100

2286
01:38:03,360 --> 01:38:08,400
tokens or or a thousand tokens so it's

2287
01:38:05,800 --> 01:38:11,320
really like asking for a needle in a Hy

2288
01:38:08,400 --> 01:38:15,280
stack and so how you frame that question

2289
01:38:11,320 --> 01:38:17,080
or how you talk to the model uh would

2290
01:38:15,280 --> 01:38:18,360
kind of helps your success in in getting

2291
01:38:17,080 --> 01:38:20,840
what you want and so this is where

2292
01:38:18,360 --> 01:38:24,760
prompt engineering comes

2293
01:38:20,840 --> 01:38:26,639
in um prompts are again like we said the

2294
01:38:24,760 --> 01:38:29,320
input to that model is your question is

2295
01:38:26,639 --> 01:38:32,119
what you are telling the model so prompt

2296
01:38:29,320 --> 01:38:34,119
engineering is editing that input or or

2297
01:38:32,119 --> 01:38:36,239
playing with it to drive the desired

2298
01:38:34,119 --> 01:38:38,520
output from the model and if we want to

2299
01:38:36,239 --> 01:38:40,400
think of the prompt uh again this is the

2300
01:38:38,520 --> 01:38:42,280
input to the model there's a question

2301
01:38:40,400 --> 01:38:44,599
there the the most important thing the

2302
01:38:42,280 --> 01:38:46,040
most the required thing is the query is

2303
01:38:44,599 --> 01:38:48,159
what is it that you want this model to

2304
01:38:46,040 --> 01:38:50,480
do is the question but then there's a

2305
01:38:48,159 --> 01:38:52,480
lot of other things that you can add to

2306
01:38:50,480 --> 01:38:54,159
the context of that prompt and so you

2307
01:38:52,480 --> 01:38:56,320
can give it instructions of how to

2308
01:38:54,159 --> 01:38:58,320
perform the task you can give it an

2309
01:38:56,320 --> 01:39:00,520
objective or a mission to achieve so you

2310
01:38:58,320 --> 01:39:03,040
can tell it we are trying to accomplish

2311
01:39:00,520 --> 01:39:05,199
X you can give it a Persona you say okay

2312
01:39:03,040 --> 01:39:07,320
well you are a doctor or you were a

2313
01:39:05,199 --> 01:39:09,000
lawyer this changes the length the

2314
01:39:07,320 --> 01:39:11,199
length with which the model gives you

2315
01:39:09,000 --> 01:39:13,560
the response you can give it constraints

2316
01:39:11,199 --> 01:39:16,000
so you'd say oh avoid this or don't do

2317
01:39:13,560 --> 01:39:17,639
that you can give it examples of the

2318
01:39:16,000 --> 01:39:19,480
output so you demo the output this is

2319
01:39:17,639 --> 01:39:20,840
where zero shot one shot or few shot

2320
01:39:19,480 --> 01:39:24,080
learning comes in so you give it an

2321
01:39:20,840 --> 01:39:27,480
example and it allows to um uh it it

2322
01:39:24,080 --> 01:39:30,080
tries to mimic it context so more

2323
01:39:27,480 --> 01:39:32,639
information now you give it tone you can

2324
01:39:30,080 --> 01:39:36,560
give it there's a lot more that you can

2325
01:39:32,639 --> 01:39:37,760
do but what I want you to know is that

2326
01:39:36,560 --> 01:39:40,719
again

2327
01:39:37,760 --> 01:39:42,760
this model is huge it's seen a lot of

2328
01:39:40,719 --> 01:39:44,639
information you're trying to get a very

2329
01:39:42,760 --> 01:39:48,360
specific response out of it and so the

2330
01:39:44,639 --> 01:39:49,920
more comp the more well formed your

2331
01:39:48,360 --> 01:39:51,760
prompt is that the higher your chances

2332
01:39:49,920 --> 01:39:54,679
of success and so prompt engineering

2333
01:39:51,760 --> 01:39:56,639
best practices give clear instructions

2334
01:39:54,679 --> 01:39:59,239
um structure your prompts include

2335
01:39:56,639 --> 01:40:02,080
examples so use all of this that is

2336
01:39:59,239 --> 01:40:04,719
available for you right use instructions

2337
01:40:02,080 --> 01:40:06,440
um Chain of Thought really helps uh

2338
01:40:04,719 --> 01:40:08,719
that's when you tell the model to

2339
01:40:06,440 --> 01:40:11,960
explain how it's done something break

2340
01:40:08,719 --> 01:40:16,239
down complex Tas prompt um iteration so

2341
01:40:11,960 --> 01:40:21,639
you keep uh trying until uh it

2342
01:40:16,239 --> 01:40:24,560
works okay um where are we at 34 minutes

2343
01:40:21,639 --> 01:40:26,320
okay um enhancing ing llm

2344
01:40:24,560 --> 01:40:28,719
performance there's several ways to

2345
01:40:26,320 --> 01:40:30,920
enhance llm performance I divided them

2346
01:40:28,719 --> 01:40:32,520
in two main categories uh there's weight

2347
01:40:30,920 --> 01:40:34,960
preserving techniques this means that

2348
01:40:32,520 --> 01:40:36,960
the model itself is unchanged the model

2349
01:40:34,960 --> 01:40:38,679
weights are the same but what you do is

2350
01:40:36,960 --> 01:40:40,119
you focus on how you interact with that

2351
01:40:38,679 --> 01:40:42,800
model so an example is prompt

2352
01:40:40,119 --> 01:40:44,440
engineering you are changing how what

2353
01:40:42,800 --> 01:40:45,960
input you're giving it but the model

2354
01:40:44,440 --> 01:40:48,360
itself is not changed but that does

2355
01:40:45,960 --> 01:40:50,000
increase performance rag for example

2356
01:40:48,360 --> 01:40:51,880
when you add an external knowledge base

2357
01:40:50,000 --> 01:40:54,560
as well that helps the performance of

2358
01:40:51,880 --> 01:40:56,719
the LM without changing the itself there

2359
01:40:54,560 --> 01:40:58,920
are weight altering techniques so the

2360
01:40:56,719 --> 01:41:01,480
model itself changes and so you're

2361
01:40:58,920 --> 01:41:03,520
you're fine-tuning you're pre-tuning uh

2362
01:41:01,480 --> 01:41:05,000
no you're not pre-training this is from

2363
01:41:03,520 --> 01:41:06,800
scratch this is too expensive but you're

2364
01:41:05,000 --> 01:41:09,320
fine tuning so you add a layer and

2365
01:41:06,800 --> 01:41:12,440
there's there is some there are a lot of

2366
01:41:09,320 --> 01:41:13,840
different techniques like PFT um

2367
01:41:12,440 --> 01:41:15,880
parameter efficient fine-tuning and

2368
01:41:13,840 --> 01:41:18,719
other ways that have been and

2369
01:41:15,880 --> 01:41:23,920
quantization and so on that has that

2370
01:41:18,719 --> 01:41:28,400
have been optim been made to um

2371
01:41:23,920 --> 01:41:29,800
uh make handling models a lot uh better

2372
01:41:28,400 --> 01:41:31,080
okay so there's the weight altering

2373
01:41:29,800 --> 01:41:33,199
techniques and the weight preserving

2374
01:41:31,080 --> 01:41:35,560
techniques the way you should go about

2375
01:41:33,199 --> 01:41:36,880
it is uh try the weight preserving

2376
01:41:35,560 --> 01:41:38,760
techniques first so do your prompt

2377
01:41:36,880 --> 01:41:41,080
engineering then your rag if that

2378
01:41:38,760 --> 01:41:43,280
doesn't work then you move on uh don't

2379
01:41:41,080 --> 01:41:45,360
start too complex uh because it's going

2380
01:41:43,280 --> 01:41:47,880
to get expensive very

2381
01:41:45,360 --> 01:41:50,560
fast okay so what is retrieval augmented

2382
01:41:47,880 --> 01:41:53,280
generation or rag

2383
01:41:50,560 --> 01:41:55,239
um this is a method created by the fair

2384
01:41:53,280 --> 01:41:58,159
team at meta to enhance the accuracy of

2385
01:41:55,239 --> 01:42:00,320
an llm it improves llms by adding the

2386
01:41:58,159 --> 01:42:02,280
information uh by an information

2387
01:42:00,320 --> 01:42:06,239
retrieval step before generating an

2388
01:42:02,280 --> 01:42:07,800
answer and so what um what we see here

2389
01:42:06,239 --> 01:42:10,280
is you've got your user they've got a

2390
01:42:07,800 --> 01:42:13,119
prompt this is the question and you've

2391
01:42:10,280 --> 01:42:14,719
got a you've got a an external uh

2392
01:42:13,119 --> 01:42:15,960
knowledge space here and it could be

2393
01:42:14,719 --> 01:42:18,400
anything it could be the documents from

2394
01:42:15,960 --> 01:42:21,719
your company it could be um field

2395
01:42:18,400 --> 01:42:23,360
specific information and um information

2396
01:42:21,719 --> 01:42:25,719
is retrieved from this database it's

2397
01:42:23,360 --> 01:42:27,480
used to augment The Prompt um and then

2398
01:42:25,719 --> 01:42:29,920
send to the model and that kind of helps

2399
01:42:27,480 --> 01:42:31,719
the model in in in different ways and

2400
01:42:29,920 --> 01:42:34,480
then you get a response okay so this is

2401
01:42:31,719 --> 01:42:36,639
the simplest this is a basic vanilla rag

2402
01:42:34,480 --> 01:42:40,000
architecture it's pretty it's pretty

2403
01:42:36,639 --> 01:42:42,239
simple uh and so the benefits of rag is

2404
01:42:40,000 --> 01:42:43,880
it allows you to potentially site

2405
01:42:42,239 --> 01:42:47,000
resources because you've got all of this

2406
01:42:43,880 --> 01:42:48,760
metadata here uh data and metadata um

2407
01:42:47,000 --> 01:42:50,960
you can add up-to-date information

2408
01:42:48,760 --> 01:42:52,840
beyond the cut off date of the model

2409
01:42:50,960 --> 01:42:54,080
itself you can add domain specific

2410
01:42:52,840 --> 01:42:57,360
knowledge

2411
01:42:54,080 --> 01:42:58,920
um of your field you can add specific

2412
01:42:57,360 --> 01:43:00,840
knowledge to your company perhaps it

2413
01:42:58,920 --> 01:43:03,880
reduces hallucination because it gives

2414
01:43:00,840 --> 01:43:07,000
the model more uh resources and it

2415
01:43:03,880 --> 01:43:09,159
improves uh performance without actually

2416
01:43:07,000 --> 01:43:10,840
training the tradeoffs of course is that

2417
01:43:09,159 --> 01:43:12,400
it does increase latency you've added an

2418
01:43:10,840 --> 01:43:14,360
extra piece of the system and it it

2419
01:43:12,400 --> 01:43:17,239
increases cost so you've added this

2420
01:43:14,360 --> 01:43:18,920
extra system right it's cheaper than

2421
01:43:17,239 --> 01:43:21,280
actually changing the model but it's not

2422
01:43:18,920 --> 01:43:25,119
cheaper than just uh using the The

2423
01:43:21,280 --> 01:43:25,119
Prompt engineering for example

2424
01:43:25,280 --> 01:43:29,280
this is a more complex view of this so

2425
01:43:27,760 --> 01:43:31,199
when you want to set up a rag system

2426
01:43:29,280 --> 01:43:32,400
there's a few um steps you can go

2427
01:43:31,199 --> 01:43:34,920
through so these are documents you can

2428
01:43:32,400 --> 01:43:37,480
chunk them um you chunk them which means

2429
01:43:34,920 --> 01:43:39,599
you you you cut them into smaller pieces

2430
01:43:37,480 --> 01:43:41,000
or you divide them into smaller pieces

2431
01:43:39,599 --> 01:43:42,320
and then you embed them which means you

2432
01:43:41,000 --> 01:43:44,880
vectorize them we'll talk a little bit

2433
01:43:42,320 --> 01:43:46,800
about what embedding and vectorization

2434
01:43:44,880 --> 01:43:50,239
is

2435
01:43:46,800 --> 01:43:51,679
um in a little bit uh but you go through

2436
01:43:50,239 --> 01:43:54,960
these steps you chunk you embed and then

2437
01:43:51,679 --> 01:43:59,320
you store it in the database and then uh

2438
01:43:54,960 --> 01:44:02,560
when you want to use the rag uh it's it

2439
01:43:59,320 --> 01:44:06,639
you could you query the database uh you

2440
01:44:02,560 --> 01:44:08,280
retrieve uh the information you want you

2441
01:44:06,639 --> 01:44:11,360
add it to the prompt and then you

2442
01:44:08,280 --> 01:44:13,440
generate the answers okay now there's

2443
01:44:11,360 --> 01:44:15,000
again this is an abstract representation

2444
01:44:13,440 --> 01:44:16,679
of this the devil is in the details

2445
01:44:15,000 --> 01:44:18,599
there are so many decisions to be taken

2446
01:44:16,679 --> 01:44:20,199
at every step of these how do you chunk

2447
01:44:18,599 --> 01:44:23,480
uh what metadata do you save how do you

2448
01:44:20,199 --> 01:44:24,520
embed which embedding model um uh uh how

2449
01:44:23,480 --> 01:44:27,920
are you going to retrieve are you going

2450
01:44:24,520 --> 01:44:32,280
to retrieve based on semantic search or

2451
01:44:27,920 --> 01:44:34,360
um what function are you uh looking at

2452
01:44:32,280 --> 01:44:37,920
similarity you know there's so many

2453
01:44:34,360 --> 01:44:39,560
details across of this but uh my point

2454
01:44:37,920 --> 01:44:41,080
in putting the series is to really give

2455
01:44:39,560 --> 01:44:46,440
you an abstract view so that it does

2456
01:44:41,080 --> 01:44:49,679
it's not as intimidating as um it it

2457
01:44:46,440 --> 01:44:51,400
seems okay gen under the hood um

2458
01:44:49,679 --> 01:44:53,599
Concepts that are important in llm so

2459
01:44:51,400 --> 01:44:55,639
the tokenization token anization is the

2460
01:44:53,599 --> 01:44:57,800
initial phase of interacting with LMS

2461
01:44:55,639 --> 01:44:59,880
what it involves is the breakdown of

2462
01:44:57,800 --> 01:45:02,040
input text into smaller pieces known as

2463
01:44:59,880 --> 01:45:03,920
tokens and we'll talk a little bit more

2464
01:45:02,040 --> 01:45:06,400
in detail about this so do tokenization

2465
01:45:03,920 --> 01:45:08,639
is model dependent each model ships with

2466
01:45:06,400 --> 01:45:10,800
its own pre-trained

2467
01:45:08,639 --> 01:45:15,599
tokenizer and model

2468
01:45:10,800 --> 01:45:17,920
weights and um embeddings are uh in

2469
01:45:15,599 --> 01:45:19,599
involve uh transposing the words into

2470
01:45:17,920 --> 01:45:20,719
mathematical space and we'll talk a

2471
01:45:19,599 --> 01:45:23,119
little bit more about this and the

2472
01:45:20,719 --> 01:45:25,040
Transformer is the model at the heart of

2473
01:45:23,119 --> 01:45:27,480
LM again we're going to uh have slides

2474
01:45:25,040 --> 01:45:28,880
to talk more deeply about these so what

2475
01:45:27,480 --> 01:45:30,639
is tokenization again it's the process

2476
01:45:28,880 --> 01:45:33,480
of breaking down the text into smaller

2477
01:45:30,639 --> 01:45:35,440
units called tokens the benefits of this

2478
01:45:33,480 --> 01:45:36,639
is is cost efficiency so the Transformer

2479
01:45:35,440 --> 01:45:40,040
performance like we said in the last

2480
01:45:36,639 --> 01:45:41,960
structure grows quadratically with um

2481
01:45:40,040 --> 01:45:44,080
the terms of the input token so if we

2482
01:45:41,960 --> 01:45:47,880
were to tokenize if we use if we could

2483
01:45:44,080 --> 01:45:49,679
break words down into letters um that

2484
01:45:47,880 --> 01:45:51,520
would make the input a lot longer and so

2485
01:45:49,679 --> 01:45:54,040
the informance the performance would be

2486
01:45:51,520 --> 01:45:56,199
terrible be really expensive

2487
01:45:54,040 --> 01:45:58,040
uh it does reduce tokenization reduces

2488
01:45:56,199 --> 01:46:00,639
the space complexity of words so when

2489
01:45:58,040 --> 01:46:05,239
you tokenize um then the space is a lot

2490
01:46:00,639 --> 01:46:07,440
less so uh instead of having the all of

2491
01:46:05,239 --> 01:46:09,280
the conjugation of the words for example

2492
01:46:07,440 --> 01:46:12,080
you would have the base word and then

2493
01:46:09,280 --> 01:46:14,679
the possible conjugation so instead of

2494
01:46:12,080 --> 01:46:17,199
um which reduces the space complexity

2495
01:46:14,679 --> 01:46:19,159
you would have less uh information there

2496
01:46:17,199 --> 01:46:21,040
it's really good with things uh it's

2497
01:46:19,159 --> 01:46:23,639
useful because

2498
01:46:21,040 --> 01:46:26,840
then mistakes spelling errors and things

2499
01:46:23,639 --> 01:46:29,840
like that are not as uh dramatic to the

2500
01:46:26,840 --> 01:46:32,280
model the side effects of course is that

2501
01:46:29,840 --> 01:46:36,040
it it creates a lot of weird

2502
01:46:32,280 --> 01:46:37,920
behavior um in the model so LMS cannot

2503
01:46:36,040 --> 01:46:40,080
spell words because they don't see

2504
01:46:37,920 --> 01:46:42,639
letters like we do they see tokens and

2505
01:46:40,080 --> 01:46:44,840
so it doesn't understand uh the letter

2506
01:46:42,639 --> 01:46:47,080
layer uh they cannot do simple

2507
01:46:44,840 --> 01:46:48,520
processing uh string processing again

2508
01:46:47,080 --> 01:46:51,800
because they don't see letters they see

2509
01:46:48,520 --> 01:46:53,320
tokens uh they are worse at non-english

2510
01:46:51,800 --> 01:46:55,920
uh languages because it's it's not the

2511
01:46:53,320 --> 01:46:57,239
same the the tokenization is optimized

2512
01:46:55,920 --> 01:46:59,440
on the English language and so other

2513
01:46:57,239 --> 01:47:02,320
languages might not work as well it's

2514
01:46:59,440 --> 01:47:06,000
very bad at simple arithmetic because

2515
01:47:02,320 --> 01:47:08,960
instead of the tokenizer cuts

2516
01:47:06,000 --> 01:47:10,760
um numbers at different rates it's not

2517
01:47:08,960 --> 01:47:12,960
it doesn't see it as the base 10 system

2518
01:47:10,760 --> 01:47:14,800
that we do um and then it has trouble

2519
01:47:12,960 --> 01:47:17,239
coding in Python again because of the

2520
01:47:14,800 --> 01:47:18,880
tokenization of all of the spacing uh

2521
01:47:17,239 --> 01:47:22,040
which some of these have been fixed in

2522
01:47:18,880 --> 01:47:23,560
in various models but some of the the

2523
01:47:22,040 --> 01:47:25,360
reasons for the these is really

2524
01:47:23,560 --> 01:47:27,000
tokenization and different again like I

2525
01:47:25,360 --> 01:47:28,400
said different tokenizers different

2526
01:47:27,000 --> 01:47:31,080
models come with different tokenizers

2527
01:47:28,400 --> 01:47:33,920
and this this website can show you what

2528
01:47:31,080 --> 01:47:35,480
the tokens look like for different uh

2529
01:47:33,920 --> 01:47:37,639
for different models and so you can play

2530
01:47:35,480 --> 01:47:39,440
with that this is an example of hello

2531
01:47:37,639 --> 01:47:42,560
there it's a it's it's nice to meet you

2532
01:47:39,440 --> 01:47:46,119
for the tokenizer for Google uh Gemma

2533
01:47:42,560 --> 01:47:48,760
and GPT 4 oh and you can see here that

2534
01:47:46,119 --> 01:47:50,840
uh the apostrophe s is is treated

2535
01:47:48,760 --> 01:47:52,639
differently this is this is such a small

2536
01:47:50,840 --> 01:47:53,679
sentence but uh you could see that there

2537
01:47:52,639 --> 01:47:56,320
is a

2538
01:47:53,679 --> 01:47:58,400
difference okay word in vetting or

2539
01:47:56,320 --> 01:48:01,239
vectorization um so machine learning

2540
01:47:58,400 --> 01:48:04,000
models are just large statistical

2541
01:48:01,239 --> 01:48:06,320
calculators uh they work with numbers

2542
01:48:04,000 --> 01:48:08,920
not with words right we as humans um

2543
01:48:06,320 --> 01:48:10,679
communicate with words but models and

2544
01:48:08,920 --> 01:48:13,520
math works with numbers and so we have

2545
01:48:10,679 --> 01:48:15,639
to convert the words into numbers and

2546
01:48:13,520 --> 01:48:17,679
this is what's called embedding or

2547
01:48:15,639 --> 01:48:19,880
vectorization so Vector embedding

2548
01:48:17,679 --> 01:48:21,440
vectorization embedding is are all the

2549
01:48:19,880 --> 01:48:24,280
same things it's really a projection of

2550
01:48:21,440 --> 01:48:26,080
text or image is or whatever your input

2551
01:48:24,280 --> 01:48:27,119
data is into mathematical space which

2552
01:48:26,080 --> 01:48:30,199
means

2553
01:48:27,119 --> 01:48:32,000
numbers and so again this is a numerical

2554
01:48:30,199 --> 01:48:34,199
representation of non-numeric entities

2555
01:48:32,000 --> 01:48:36,480
and there's different examples of how we

2556
01:48:34,199 --> 01:48:37,880
did this across ages and so one hot

2557
01:48:36,480 --> 01:48:40,239
encoding for example if you have an

2558
01:48:37,880 --> 01:48:44,320
example that that that's one way to

2559
01:48:40,239 --> 01:48:46,960
vectorize uh a discrete class uh tfidf

2560
01:48:44,320 --> 01:48:48,840
which is term frequency inverse document

2561
01:48:46,960 --> 01:48:51,320
frequency was one way we did it before

2562
01:48:48,840 --> 01:48:54,400
word toac is really cool um here's the

2563
01:48:51,320 --> 01:48:56,560
paper so his historically some examples

2564
01:48:54,400 --> 01:48:58,199
are in the 1954 there was what they

2565
01:48:56,560 --> 01:48:59,560
called bag of Words which is a simple

2566
01:48:58,199 --> 01:49:03,639
approach what it means is they just

2567
01:48:59,560 --> 01:49:06,719
counted words in a document so um the

2568
01:49:03,639 --> 01:49:08,440
more a if the were if there was more

2569
01:49:06,719 --> 01:49:10,360
Sports words than anything else then

2570
01:49:08,440 --> 01:49:12,000
they would categorize this was made use

2571
01:49:10,360 --> 01:49:13,040
for classification they would classify

2572
01:49:12,000 --> 01:49:15,599
it as a

2573
01:49:13,040 --> 01:49:17,199
sports um document for example but that

2574
01:49:15,599 --> 01:49:19,159
was the simplest way is how do you take

2575
01:49:17,199 --> 01:49:21,880
words and get numbers out of them and

2576
01:49:19,159 --> 01:49:24,239
counting in the 1954 was the easiest way

2577
01:49:21,880 --> 01:49:26,840
and so this was where bag of words come

2578
01:49:24,239 --> 01:49:29,320
in in 1972 it became a little bit more

2579
01:49:26,840 --> 01:49:31,119
sophisticated where tfidf means the term

2580
01:49:29,320 --> 01:49:33,719
frequency inverse document frequency so

2581
01:49:31,119 --> 01:49:37,080
you counted but then you divided by how

2582
01:49:33,719 --> 01:49:39,080
often that um term appears in the

2583
01:49:37,080 --> 01:49:41,280
document so it's it's a frequency count

2584
01:49:39,080 --> 01:49:42,960
now it's not a a base count or an

2585
01:49:41,280 --> 01:49:46,320
absolute count it's it's a

2586
01:49:42,960 --> 01:49:49,080
frequency and then um in

2587
01:49:46,320 --> 01:49:51,280
2013 Google released the word Toc which

2588
01:49:49,080 --> 01:49:53,920
was really really cool and I think is

2589
01:49:51,280 --> 01:49:57,560
underlying a lot of the advancement in

2590
01:49:53,920 --> 01:49:59,840
LP that we see today um what this is is

2591
01:49:57,560 --> 01:50:02,679
is um High dimensional vectors

2592
01:49:59,840 --> 01:50:05,719
encapsulating semantic

2593
01:50:02,679 --> 01:50:09,159
associations and again this was this I

2594
01:50:05,719 --> 01:50:13,280
think is is one of the flag moments this

2595
01:50:09,159 --> 01:50:16,040
is a pivotal moment um advancement in in

2596
01:50:13,280 --> 01:50:18,119
NLP and what it really showed is so what

2597
01:50:16,040 --> 01:50:21,320
they did is they took this model

2598
01:50:18,119 --> 01:50:23,199
embedding model they gave it um a lot of

2599
01:50:21,320 --> 01:50:25,679
Text data and they trained it

2600
01:50:23,199 --> 01:50:28,520
and it came up with these Vector

2601
01:50:25,679 --> 01:50:30,679
embeddings uh Vector representations in

2602
01:50:28,520 --> 01:50:32,440
in high-dimensional space but then what

2603
01:50:30,679 --> 01:50:34,800
they showed is that you can do math with

2604
01:50:32,440 --> 01:50:37,440
words and so if you said something like

2605
01:50:34,800 --> 01:50:39,360
King minus man plus woman the model

2606
01:50:37,440 --> 01:50:40,520
would give you Queen and so this

2607
01:50:39,360 --> 01:50:44,360
transformed

2608
01:50:40,520 --> 01:50:46,520
NLP uh and modeling on text because now

2609
01:50:44,360 --> 01:50:48,440
uh we understand that we can do that

2610
01:50:46,520 --> 01:50:50,119
projection really well and and that's

2611
01:50:48,440 --> 01:50:51,520
the paper and you can read a little bit

2612
01:50:50,119 --> 01:50:54,040
more about

2613
01:50:51,520 --> 01:50:56,920
it um um the Transformer this is the

2614
01:50:54,040 --> 01:50:59,400
last uh big component I wanted to talk

2615
01:50:56,920 --> 01:51:01,599
about the Transformer is really the

2616
01:50:59,400 --> 01:51:03,760
architecture that the the model

2617
01:51:01,599 --> 01:51:07,360
architecture that is at the heart of the

2618
01:51:03,760 --> 01:51:09,320
llm um it's the heart of many llms it's

2619
01:51:07,360 --> 01:51:10,599
a neural network again we played with

2620
01:51:09,320 --> 01:51:12,159
neural network so if you're not a

2621
01:51:10,599 --> 01:51:14,560
familiar go back to the previous

2622
01:51:12,159 --> 01:51:16,960
lectures um and it was introduced in a

2623
01:51:14,560 --> 01:51:20,400
paper uh which was called attention of

2624
01:51:16,960 --> 01:51:22,000
all you need in 2017 this was work from

2625
01:51:20,400 --> 01:51:24,520
uh researchers from Google and the

2626
01:51:22,000 --> 01:51:27,199
University of Toronto it was initially

2627
01:51:24,520 --> 01:51:29,920
designed for sequence to sequence um

2628
01:51:27,199 --> 01:51:32,920
tasks like translation it was I don't

2629
01:51:29,920 --> 01:51:35,400
know that they knew that it would um

2630
01:51:32,920 --> 01:51:38,040
take the World by storm this is what it

2631
01:51:35,400 --> 01:51:40,239
looks like so again because um these

2632
01:51:38,040 --> 01:51:43,480
things the the mathematical model tends

2633
01:51:40,239 --> 01:51:45,800
to be too complex we we visualize them

2634
01:51:43,480 --> 01:51:48,199
um abstractly like this so this is you

2635
01:51:45,800 --> 01:51:50,159
got your inputs uh

2636
01:51:48,199 --> 01:51:51,880
we I don't want to go into too much

2637
01:51:50,159 --> 01:51:53,320
detail but you've got an encoder and

2638
01:51:51,880 --> 01:51:56,760
then you've got a decoder and then

2639
01:51:53,320 --> 01:52:01,119
there's a cross attention in between uh

2640
01:51:56,760 --> 01:52:03,480
there's a really good um lecture on

2641
01:52:01,119 --> 01:52:05,480
YouTube again in the reference about how

2642
01:52:03,480 --> 01:52:07,880
this all works and and you can build it

2643
01:52:05,480 --> 01:52:11,000
from scratch if you want so look at the

2644
01:52:07,880 --> 01:52:13,840
the references but

2645
01:52:11,000 --> 01:52:15,639
um what a lot of people in the field did

2646
01:52:13,840 --> 01:52:18,159
this this started as a translation paper

2647
01:52:15,639 --> 01:52:19,560
and then what in 2017 and then what

2648
01:52:18,159 --> 01:52:20,800
people did after that is they copy

2649
01:52:19,560 --> 01:52:24,320
pasted the

2650
01:52:20,800 --> 01:52:26,679
architecture um and change the input so

2651
01:52:24,320 --> 01:52:29,599
they changed the the ve the

2652
01:52:26,679 --> 01:52:32,480
embedding uh the vectorization yeah the

2653
01:52:29,599 --> 01:52:34,199
embedding and it does wonders I mean

2654
01:52:32,480 --> 01:52:35,560
it's it's still at the heart of a lot of

2655
01:52:34,199 --> 01:52:37,239
things we do there has been some changes

2656
01:52:35,560 --> 01:52:41,000
to the architecture very minor from the

2657
01:52:37,239 --> 01:52:43,719
paper uh but again you can take a look

2658
01:52:41,000 --> 01:52:46,079
the main before that uh the way we did

2659
01:52:43,719 --> 01:52:47,520
sequences is was through uh rnn's

2660
01:52:46,079 --> 01:52:51,520
recurrent neural networks and their

2661
01:52:47,520 --> 01:52:54,239
different variations uh but those uh

2662
01:52:51,520 --> 01:52:58,000
dealt with data qually which meant you

2663
01:52:54,239 --> 01:53:01,320
couldn't paralyze them and um so rnn's

2664
01:52:58,000 --> 01:53:03,119
um you know you can look into them but

2665
01:53:01,320 --> 01:53:05,400
the the differences that made the

2666
01:53:03,119 --> 01:53:06,400
Transformer the next leap is because it

2667
01:53:05,400 --> 01:53:08,639
was

2668
01:53:06,400 --> 01:53:11,000
parallelizable and so we can train this

2669
01:53:08,639 --> 01:53:13,239
on distributed compute and it can get a

2670
01:53:11,000 --> 01:53:14,520
lot larger um there's they introduced

2671
01:53:13,239 --> 01:53:15,679
something called positional encodings

2672
01:53:14,520 --> 01:53:17,639
where it doesn't need to retain the

2673
01:53:15,679 --> 01:53:19,320
sequence anymore it it retains a vector

2674
01:53:17,639 --> 01:53:21,560
of where every word is and and that

2675
01:53:19,320 --> 01:53:23,440
helps it not retain sequence and it

2676
01:53:21,560 --> 01:53:24,679
helps again in paral ation and they

2677
01:53:23,440 --> 01:53:26,920
introduce something called attention

2678
01:53:24,679 --> 01:53:28,400
heads which allows the model to assign

2679
01:53:26,920 --> 01:53:31,679
different weights to different words

2680
01:53:28,400 --> 01:53:33,760
depending on their context um there is

2681
01:53:31,679 --> 01:53:35,800
this I wanted to show you I think this

2682
01:53:33,760 --> 01:53:38,679
is my last slide yeah okay so there's I

2683
01:53:35,800 --> 01:53:41,079
wanted to show you this this is a really

2684
01:53:38,679 --> 01:53:43,960
cool website again you can see it um

2685
01:53:41,079 --> 01:53:45,560
this is based on the nanog

2686
01:53:43,960 --> 01:53:47,960
GPT

2687
01:53:45,560 --> 01:53:49,679
um and what this shows you is this is

2688
01:53:47,960 --> 01:53:51,800
the embedding this is the input okay so

2689
01:53:49,679 --> 01:53:53,360
you've got your data this is the words

2690
01:53:51,800 --> 01:53:55,840
and this is the embedding Vector right

2691
01:53:53,360 --> 01:53:58,119
so you've got your your

2692
01:53:55,840 --> 01:53:59,639
tokens uh there's

2693
01:53:58,119 --> 01:54:02,880
tokenization

2694
01:53:59,639 --> 01:54:05,239
and data visualization empowers users so

2695
01:54:02,880 --> 01:54:07,000
you can see here that empowers has been

2696
01:54:05,239 --> 01:54:09,320
split into two different tokens so

2697
01:54:07,000 --> 01:54:11,840
already this is tokenized you can see

2698
01:54:09,320 --> 01:54:14,040
and this is the positional uh encoding

2699
01:54:11,840 --> 01:54:15,920
so this is the position of each word and

2700
01:54:14,040 --> 01:54:18,000
then it's been vectorized so this is the

2701
01:54:15,920 --> 01:54:21,199
edting the vectorized so this word has

2702
01:54:18,000 --> 01:54:23,199
been um changed into this vector and

2703
01:54:21,199 --> 01:54:24,480
this is using a vector representation

2704
01:54:23,199 --> 01:54:28,159
that is

2705
01:54:24,480 --> 01:54:30,560
768 numbers long the vectorization

2706
01:54:28,159 --> 01:54:33,159
changes from company to company and from

2707
01:54:30,560 --> 01:54:35,000
provider to provider Google uses a

2708
01:54:33,159 --> 01:54:36,960
vector that's

2709
01:54:35,000 --> 01:54:40,639
67,68

2710
01:54:36,960 --> 01:54:43,960
768 um in length I think gpts are closer

2711
01:54:40,639 --> 01:54:45,280
to the 3,000 Mark the more numbers uh

2712
01:54:43,960 --> 01:54:48,760
you have in that Vector then the more

2713
01:54:45,280 --> 01:54:51,280
dimensionality you are um Gathering and

2714
01:54:48,760 --> 01:54:54,079
so there's there's more information that

2715
01:54:51,280 --> 01:54:56,800
you can potentially so just keep that in

2716
01:54:54,079 --> 01:55:00,239
mind so this is 6

2717
01:54:56,800 --> 01:55:03,079
768 it's late here

2718
01:55:00,239 --> 01:55:05,159
um and so now what you see here is this

2719
01:55:03,079 --> 01:55:08,199
is the information and it goes through

2720
01:55:05,159 --> 01:55:10,280
the the layers the this is distributed

2721
01:55:08,199 --> 01:55:13,000
so these are different processes

2722
01:55:10,280 --> 01:55:14,440
happening um and then you can see here

2723
01:55:13,000 --> 01:55:17,920
there's a tension so it's giving

2724
01:55:14,440 --> 01:55:21,719
different words different

2725
01:55:17,920 --> 01:55:24,800
um uh evaluations or importance and it

2726
01:55:21,719 --> 01:55:26,440
goes through the layers and uh what ends

2727
01:55:24,800 --> 01:55:30,320
up happening with what I want to show

2728
01:55:26,440 --> 01:55:33,159
you is right here it takes the the

2729
01:55:30,320 --> 01:55:35,000
tokens and then it uh creates a

2730
01:55:33,159 --> 01:55:37,520
probability distribution so this is the

2731
01:55:35,000 --> 01:55:39,639
probability distribution and so it says

2732
01:55:37,520 --> 01:55:42,719
data visualization empowers the users to

2733
01:55:39,639 --> 01:55:44,679
make and it's a next remember it's a

2734
01:55:42,719 --> 01:55:47,000
next word predictor in the sequence and

2735
01:55:44,679 --> 01:55:51,400
so this is the possible words that could

2736
01:55:47,000 --> 01:55:53,800
be next and it thinks that um the next

2737
01:55:51,400 --> 01:55:57,480
word based on the prob ability

2738
01:55:53,800 --> 01:56:01,079
28.3 is visualized so data visualization

2739
01:55:57,480 --> 01:56:02,800
empowers users to make uh visualize now

2740
01:56:01,079 --> 01:56:04,639
again this is not a great model and that

2741
01:56:02,800 --> 01:56:05,960
it's the nanog GPT it's a small model

2742
01:56:04,639 --> 01:56:07,480
it's not been trained on a lot of data

2743
01:56:05,960 --> 01:56:09,719
but it gives you an example of this how

2744
01:56:07,480 --> 01:56:11,079
this whole thing works now temperature I

2745
01:56:09,719 --> 01:56:14,679
didn't talk about temperature and top

2746
01:56:11,079 --> 01:56:17,159
key and top K these are um these are

2747
01:56:14,679 --> 01:56:19,360
hyper parameters that you can or um just

2748
01:56:17,159 --> 01:56:21,119
variables that you can change that um

2749
01:56:19,360 --> 01:56:24,440
change the Model Behavior and what these

2750
01:56:21,119 --> 01:56:26,960
do is they change the randomness in the

2751
01:56:24,440 --> 01:56:28,480
model and so if the temperature is zero

2752
01:56:26,960 --> 01:56:30,159
what you can see here it's doing is it's

2753
01:56:28,480 --> 01:56:33,400
changing the probability distribution at

2754
01:56:30,159 --> 01:56:35,159
the output layer and so if this is zero

2755
01:56:33,400 --> 01:56:37,480
this model becomes deterministic it

2756
01:56:35,159 --> 01:56:38,880
gives the highest the word the top word

2757
01:56:37,480 --> 01:56:41,079
the highest amount and so it'll

2758
01:56:38,880 --> 01:56:44,520
repeatedly do that if you ask it over

2759
01:56:41,079 --> 01:56:45,760
and over if you make this um highest

2760
01:56:44,520 --> 01:56:47,079
then you can see it changes the

2761
01:56:45,760 --> 01:56:49,000
distribution there's a lot more

2762
01:56:47,079 --> 01:56:50,719
Randomness now the probabilities are

2763
01:56:49,000 --> 01:56:53,719
very close to each other and so it will

2764
01:56:50,719 --> 01:56:56,199
choose one at random different times so

2765
01:56:53,719 --> 01:56:58,199
these are what the top P top K

2766
01:56:56,199 --> 01:57:01,199
temperature though they they really play

2767
01:56:58,199 --> 01:57:05,560
at the level of the

2768
01:57:01,199 --> 01:57:08,199
probabilities okay so that is it for me

2769
01:57:05,560 --> 01:57:09,920
these are my references um yanda's

2770
01:57:08,199 --> 01:57:12,320
lecture is really good it goes into what

2771
01:57:09,920 --> 01:57:14,960
llms are and it is more technical it is

2772
01:57:12,320 --> 01:57:16,719
a Stanford lecture in CS so it goes a

2773
01:57:14,960 --> 01:57:18,560
little bit more into the weeds if that's

2774
01:57:16,719 --> 01:57:22,560
what you want but I I personally enjoyed

2775
01:57:18,560 --> 01:57:25,440
it um there's some lectures here from

2776
01:57:22,560 --> 01:57:27,280
Andre on he does a lot about how do you

2777
01:57:25,440 --> 01:57:29,040
build a GPT how do you build a tokenizer

2778
01:57:27,280 --> 01:57:31,199
how do you do all of these things really

2779
01:57:29,040 --> 01:57:34,199
cool if you're interested in the depth

2780
01:57:31,199 --> 01:57:37,000
uh I personally really like Andre and I

2781
01:57:34,199 --> 01:57:40,079
follow him uh and I take a lot of his

2782
01:57:37,000 --> 01:57:44,960
cero courses in DB so these are there

2783
01:57:40,079 --> 01:57:48,639
for you and that is it hello again um so

2784
01:57:44,960 --> 01:57:51,199
this is the four the final uh lecture in

2785
01:57:48,639 --> 01:57:53,079
this miniseries so this is ml104

2786
01:57:51,199 --> 01:57:58,760
architecting Gen

2787
01:57:53,079 --> 01:58:04,079
systems and um so this is a a reminder

2788
01:57:58,760 --> 01:58:07,000
that um the tech and ml um serve the

2789
01:58:04,079 --> 01:58:08,920
business right so um it has to be linked

2790
01:58:07,000 --> 01:58:10,599
to the use case it has to be the proper

2791
01:58:08,920 --> 01:58:13,719
tool for the use case so the first

2792
01:58:10,599 --> 01:58:17,599
question is to ask is is AIML the right

2793
01:58:13,719 --> 01:58:17,599
tool for the job

2794
01:58:17,719 --> 01:58:23,239
and whether it's ml AI analytics Tech

2795
01:58:20,880 --> 01:58:25,000
they're all tools to solve

2796
01:58:23,239 --> 01:58:28,079
problems but you have to choose the

2797
01:58:25,000 --> 01:58:31,520
right tool um ML and AI are pretty

2798
01:58:28,079 --> 01:58:32,679
powerful uh but not nothing not well if

2799
01:58:31,520 --> 01:58:34,920
you have a hammer I guess everything

2800
01:58:32,679 --> 01:58:38,960
looks like a nail but ideally you would

2801
01:58:34,920 --> 01:58:40,760
choose the finest Tool uh for your job

2802
01:58:38,960 --> 01:58:44,079
so any repeating task in a system is

2803
01:58:40,760 --> 01:58:46,760
worth automating um if that task is

2804
01:58:44,079 --> 01:58:51,639
deterministic you know the rule you know

2805
01:58:46,760 --> 01:58:54,000
the the the the system uh formula like

2806
01:58:51,639 --> 01:58:57,719
we just saw in the previous lecture then

2807
01:58:54,000 --> 01:58:59,880
you can automate that with um with a

2808
01:58:57,719 --> 01:59:03,159
software system with devops with a rule

2809
01:58:59,880 --> 01:59:06,719
based systems um if however the task

2810
01:59:03,159 --> 01:59:09,280
involves miss or reasoning or a pattern

2811
01:59:06,719 --> 01:59:12,079
you don't understand then that's where

2812
01:59:09,280 --> 01:59:13,760
ml uh comes in and again anytime you

2813
01:59:12,079 --> 01:59:15,960
have data then ml is an option like I

2814
01:59:13,760 --> 01:59:20,000
said in the previous lecture but it

2815
01:59:15,960 --> 01:59:21,520
really shines when there is um change

2816
01:59:20,000 --> 01:59:23,480
when there's scale and when there's

2817
01:59:21,520 --> 01:59:26,280
complexity

2818
01:59:23,480 --> 01:59:27,880
okay but um again you just have to look

2819
01:59:26,280 --> 01:59:30,360
at what your use case is what are your

2820
01:59:27,880 --> 01:59:33,880
possible options and if ml is your best

2821
01:59:30,360 --> 01:59:36,400
option now now that you've chosen AI or

2822
01:59:33,880 --> 01:59:39,480
ml you have to choose whether is

2823
01:59:36,400 --> 01:59:42,040
predictive ml or gen and we went a

2824
01:59:39,480 --> 01:59:44,119
little bit over last lecture about when

2825
01:59:42,040 --> 01:59:46,159
to choose either um this is a

2826
01:59:44,119 --> 01:59:47,520
reiteration but um here what I want to

2827
01:59:46,159 --> 01:59:51,880
show is

2828
01:59:47,520 --> 01:59:54,840
that um both in predictive ML and geni

2829
01:59:51,880 --> 01:59:59,440
uh you can have custom models that are

2830
01:59:54,840 --> 02:00:02,520
trained to on your own data um or SAS

2831
01:59:59,440 --> 02:00:04,880
solution so this is a pre-trained model

2832
02:00:02,520 --> 02:00:06,239
um and it could be a pre-train model

2833
02:00:04,880 --> 02:00:08,880
that you deploy yourself or it could be

2834
02:00:06,239 --> 02:00:10,920
a a pre-trained model that is um hosted

2835
02:00:08,880 --> 02:00:13,320
by a provider for you either case I

2836
02:00:10,920 --> 02:00:15,520
didn't put an extra line here for that

2837
02:00:13,320 --> 02:00:17,960
but um like we saw in the last lecture

2838
02:00:15,520 --> 02:00:20,639
custom models in the Gen space are very

2839
02:00:17,960 --> 02:00:25,040
very costly so that's unlikely to happen

2840
02:00:20,639 --> 02:00:27,960
um and predicted ml um Solutions in

2841
02:00:25,040 --> 02:00:29,679
general um there are pre-trained models

2842
02:00:27,960 --> 02:00:32,760
out there but the majority of cases are

2843
02:00:29,679 --> 02:00:34,560
usually Uh custom built and so uh we

2844
02:00:32,760 --> 02:00:36,960
said this before but the main differen

2845
02:00:34,560 --> 02:00:40,199
is to keep in mind is that uh the model

2846
02:00:36,960 --> 02:00:42,920
size is very very different um uh the

2847
02:00:40,199 --> 02:00:44,719
training there is a lot more work in

2848
02:00:42,920 --> 02:00:47,679
training and data Gathering so on

2849
02:00:44,719 --> 02:00:49,960
predictive ml than in gen and that gen

2850
02:00:47,679 --> 02:00:53,880
gives open-ended results

2851
02:00:49,960 --> 02:00:56,639
right and so the predictive the the

2852
02:00:53,880 --> 02:00:58,199
cases that we see normally so again this

2853
02:00:56,639 --> 02:01:00,239
this Matrix you can have predictive ml

2854
02:00:58,199 --> 02:01:02,199
that is custom or that ones that are

2855
02:01:00,239 --> 02:01:06,000
pre-trained or the ones that provide are

2856
02:01:02,199 --> 02:01:08,520
provided uh by a third entity and in gen

2857
02:01:06,000 --> 02:01:11,199
you can have all three as well but the

2858
02:01:08,520 --> 02:01:14,760
pattern that we see Mo most in the wild

2859
02:01:11,199 --> 02:01:18,800
is that um gen people use a third party

2860
02:01:14,760 --> 02:01:20,520
option um an API call um and in the

2861
02:01:18,800 --> 02:01:23,679
predictive ml space it's usually custom

2862
02:01:20,520 --> 02:01:26,040
model so when I'm talking of going to um

2863
02:01:23,679 --> 02:01:27,159
compare these two again it's I

2864
02:01:26,040 --> 02:01:30,400
understand it's not Apples to Apples

2865
02:01:27,159 --> 02:01:33,880
it's it's but these are the patterns

2866
02:01:30,400 --> 02:01:37,599
that we see more often and again when I

2867
02:01:33,880 --> 02:01:39,960
say cost there's um it's a proxy there

2868
02:01:37,599 --> 02:01:41,679
is uh training cost there's inference

2869
02:01:39,960 --> 02:01:44,040
cost and there's total cost of ownership

2870
02:01:41,679 --> 02:01:45,560
and of course there's the cost of having

2871
02:01:44,040 --> 02:01:49,079
personnel and training personnel and

2872
02:01:45,560 --> 02:01:53,119
collecting data and so on um but on

2873
02:01:49,079 --> 02:01:55,960
average um gen 10 to be more

2874
02:01:53,119 --> 02:01:58,440
expensive and so this is a again we've

2875
02:01:55,960 --> 02:02:00,880
seen some elements of this uh the model

2876
02:01:58,440 --> 02:02:02,639
size is a lot bigger uh the initial

2877
02:02:00,880 --> 02:02:03,960
training investment is a lot bigger in

2878
02:02:02,639 --> 02:02:06,679
predictive ml I think this should be

2879
02:02:03,960 --> 02:02:08,239
clear by by now uh you have to collect

2880
02:02:06,679 --> 02:02:09,880
your data you have to train you have to

2881
02:02:08,239 --> 02:02:11,520
have the skill set so the data

2882
02:02:09,880 --> 02:02:13,960
availability is required here whereas

2883
02:02:11,520 --> 02:02:16,480
it's not in in gen the expertise is

2884
02:02:13,960 --> 02:02:19,920
required whereas it's not in gen not as

2885
02:02:16,480 --> 02:02:21,360
much anyway um so the initial investment

2886
02:02:19,920 --> 02:02:23,800
uh required for predictive Mount is a

2887
02:02:21,360 --> 02:02:25,800
lot higher than it is for J so if you

2888
02:02:23,800 --> 02:02:28,840
have a use case where you really want to

2889
02:02:25,800 --> 02:02:30,880
hit the ground running uh and and prove

2890
02:02:28,840 --> 02:02:34,360
value really fast then gen might be a

2891
02:02:30,880 --> 02:02:38,239
better option for you um in terms of

2892
02:02:34,360 --> 02:02:41,040
inference cost um again it's not Apples

2893
02:02:38,239 --> 02:02:42,920
to Apples but on average gen tends to be

2894
02:02:41,040 --> 02:02:44,840
more expensive because these models are

2895
02:02:42,920 --> 02:02:47,599
bigger because they're more expensive to

2896
02:02:44,840 --> 02:02:52,560
host because that model provider needs

2897
02:02:47,599 --> 02:02:54,840
to get um their their service paid for

2898
02:02:52,560 --> 02:02:57,079
um in terms of model control oops in

2899
02:02:54,840 --> 02:03:00,520
terms of model control uh you have a lot

2900
02:02:57,079 --> 02:03:02,360
more model over a custom a model that is

2901
02:03:00,520 --> 02:03:04,719
in that that is customed to you that is

2902
02:03:02,360 --> 02:03:06,719
yours as opposed to a model that is

2903
02:03:04,719 --> 02:03:08,960
hosted by somebody else in terms of

2904
02:03:06,719 --> 02:03:11,000
deterministic or not um predictive

2905
02:03:08,960 --> 02:03:14,560
models are a lot more deterministic

2906
02:03:11,000 --> 02:03:16,880
foundational models um or llms uh tend

2907
02:03:14,560 --> 02:03:19,599
to be a lot more uh

2908
02:03:16,880 --> 02:03:21,639
probabilistic and less deterministic and

2909
02:03:19,599 --> 02:03:23,239
so depending on if you have a and I said

2910
02:03:21,639 --> 02:03:25,440
this before in the lecture so this is a

2911
02:03:23,239 --> 02:03:27,480
repeat if we you have a project that is

2912
02:03:25,440 --> 02:03:30,520
really long term it's it's it's a long

2913
02:03:27,480 --> 02:03:33,280
project um that it makes sense to use

2914
02:03:30,520 --> 02:03:36,159
predictive ml because the cost of gen is

2915
02:03:33,280 --> 02:03:38,560
going to catch up with you uh again if

2916
02:03:36,159 --> 02:03:40,079
your work size uh workload size is

2917
02:03:38,560 --> 02:03:41,520
really large again the cost will catch

2918
02:03:40,079 --> 02:03:43,320
up with you so a predictive model might

2919
02:03:41,520 --> 02:03:45,760
be a better option and if you have high

2920
02:03:43,320 --> 02:03:47,280
compliance than a a predictive ml custom

2921
02:03:45,760 --> 02:03:50,280
predictive ml model is a probably a

2922
02:03:47,280 --> 02:03:53,719
better choice uh you control a lot more

2923
02:03:50,280 --> 02:03:53,719
uh than you do with a foundational model

2924
02:03:54,239 --> 02:03:58,400
um so now this this is here we we're

2925
02:03:57,079 --> 02:04:00,079
we're comparing Apples to Apples and

2926
02:03:58,400 --> 02:04:03,719
that here we're looking at a predictive

2927
02:04:00,079 --> 02:04:06,000
ml SAS solution uh versus a gen SAS

2928
02:04:03,719 --> 02:04:09,440
solution so this is document processing

2929
02:04:06,000 --> 02:04:11,119
uh textt trct is an AWS Service uh that

2930
02:04:09,440 --> 02:04:15,239
is a model as a surface it's a

2931
02:04:11,119 --> 02:04:17,280
pre-trained model um and um I'm looking

2932
02:04:15,239 --> 02:04:21,559
at what it would cost to process about a

2933
02:04:17,280 --> 02:04:23,960
million Pages a month uh with the um

2934
02:04:21,559 --> 02:04:26,119
with the assumption that there's about

2935
02:04:23,960 --> 02:04:29,920
676 words per

2936
02:04:26,119 --> 02:04:33,920
page and um if I do that on text track

2937
02:04:29,920 --> 02:04:36,880
that gives me about 1,500 USD a month uh

2938
02:04:33,920 --> 02:04:39,079
if I do that on Nova bedro through Nova

2939
02:04:36,880 --> 02:04:41,480
um it'll cost me about 2,600 which is a

2940
02:04:39,079 --> 02:04:44,719
2X roughly if I do it on clots on it

2941
02:04:41,480 --> 02:04:48,440
it'll cost me 11,000 right and

2942
02:04:44,719 --> 02:04:52,040
so novas are I'm they're surprisingly

2943
02:04:48,440 --> 02:04:54,639
cheap I think that's one of their um

2944
02:04:52,040 --> 02:04:57,880
uh good features is that they're fairly

2945
02:04:54,639 --> 02:05:01,360
cheap uh but the idea is that if you

2946
02:04:57,880 --> 02:05:03,320
have a predictive ml model that is

2947
02:05:01,360 --> 02:05:07,480
pre-trained and does a specific task

2948
02:05:03,320 --> 02:05:09,360
that you want it to do that model I'm

2949
02:05:07,480 --> 02:05:10,840
again different environments and

2950
02:05:09,360 --> 02:05:13,079
different things might vary but I am

2951
02:05:10,840 --> 02:05:15,239
willing to make the bed that uh it'll be

2952
02:05:13,079 --> 02:05:17,679
cheaper than a gen model simply because

2953
02:05:15,239 --> 02:05:19,920
of the size and the resources required

2954
02:05:17,679 --> 02:05:21,880
to host a

2955
02:05:19,920 --> 02:05:24,000
model okay so we're going to talk talk a

2956
02:05:21,880 --> 02:05:27,760
little bit about um so let's say you've

2957
02:05:24,000 --> 02:05:31,520
decided that um ml is a great fit for

2958
02:05:27,760 --> 02:05:35,199
their use case and uh within uh AIML

2959
02:05:31,520 --> 02:05:37,360
you've decided that gen is um a better

2960
02:05:35,199 --> 02:05:43,000
fit for your use case so let's say you

2961
02:05:37,360 --> 02:05:43,000
need to show your stakeholders um really

2962
02:05:43,239 --> 02:05:48,840
fast value and so you don't have really

2963
02:05:46,920 --> 02:05:51,760
a lot of time to to think about custom

2964
02:05:48,840 --> 02:05:53,639
models there isn't a SAS there isn't a

2965
02:05:51,760 --> 02:05:55,559
pre-t trade model that does exactly what

2966
02:05:53,639 --> 02:05:58,440
you want it to do but an llm does it for

2967
02:05:55,559 --> 02:06:01,079
you so that's that's um you've decided

2968
02:05:58,440 --> 02:06:04,000
that uh hypothetically that J is the

2969
02:06:01,079 --> 02:06:07,440
thing for you let's architect a

2970
02:06:04,000 --> 02:06:09,360
system and so um what I'm going to show

2971
02:06:07,440 --> 02:06:11,840
you here is a series of conceptual

2972
02:06:09,360 --> 02:06:14,679
diagrams um so they they

2973
02:06:11,840 --> 02:06:17,480
abstract uh the main building blocks in

2974
02:06:14,679 --> 02:06:19,400
a system and how they are

2975
02:06:17,480 --> 02:06:20,920
connected there are many different tools

2976
02:06:19,400 --> 02:06:22,960
that can fit into these blocks so when I

2977
02:06:20,920 --> 02:06:24,360
say a rag system there's many different

2978
02:06:22,960 --> 02:06:25,760
ways there's a million ways to ro

2979
02:06:24,360 --> 02:06:29,079
there's a million ways to build that

2980
02:06:25,760 --> 02:06:31,639
system in technical terms but um it

2981
02:06:29,079 --> 02:06:34,079
serves the same function and so uh I'm

2982
02:06:31,639 --> 02:06:36,920
trying to help you abstract all of the

2983
02:06:34,079 --> 02:06:38,440
important uh building blocks and so the

2984
02:06:36,920 --> 02:06:41,880
main point of this exercise is really to

2985
02:06:38,440 --> 02:06:43,199
get a high level view of the system um

2986
02:06:41,880 --> 02:06:45,360
and it's very important to understand

2987
02:06:43,199 --> 02:06:47,440
what the function of that uh service is

2988
02:06:45,360 --> 02:06:50,599
or that piece that component what the

2989
02:06:47,440 --> 02:06:52,480
pros and cons of having it are and um

2990
02:06:50,599 --> 02:06:53,800
and then once you get that and you

2991
02:06:52,480 --> 02:06:55,480
decide that that component is important

2992
02:06:53,800 --> 02:06:57,719
to the system you can go in and dig into

2993
02:06:55,480 --> 02:07:00,400
the technical implementations what tools

2994
02:06:57,719 --> 02:07:02,040
fit into that uh or serve that function

2995
02:07:00,400 --> 02:07:03,280
and how you would Implement that that

2996
02:07:02,040 --> 02:07:05,000
that is beyond the scope of this

2997
02:07:03,280 --> 02:07:08,320
particular call I'm just looking at

2998
02:07:05,000 --> 02:07:10,679
conceptual uh big component diagrams but

2999
02:07:08,320 --> 02:07:14,840
uh I think within uh if you're taking

3000
02:07:10,679 --> 02:07:17,079
the um gen free boot camp then you're

3001
02:07:14,840 --> 02:07:20,000
going to have some opportunities to do

3002
02:07:17,079 --> 02:07:23,840
that work okay

3003
02:07:20,000 --> 02:07:25,719
so um J architecture Ground Zero is a

3004
02:07:23,840 --> 02:07:28,880
model call by the way uh these series

3005
02:07:25,719 --> 02:07:32,040
are uh not exactly but they are based on

3006
02:07:28,880 --> 02:07:34,760
uh the book AI engineering by uh chip

3007
02:07:32,040 --> 02:07:36,880
hen uh I really enjoyed that book I I I

3008
02:07:34,760 --> 02:07:40,000
like both her books actually so um it's

3009
02:07:36,880 --> 02:07:43,119
a really good resource the first book uh

3010
02:07:40,000 --> 02:07:45,559
which is designing machine learning

3011
02:07:43,119 --> 02:07:49,159
systems that talks more about predictive

3012
02:07:45,559 --> 02:07:51,639
ML and this one um gen AI engineering

3013
02:07:49,159 --> 02:07:55,280
talks about generative AI

3014
02:07:51,639 --> 02:07:58,760
um okay so at the heart of a gen system

3015
02:07:55,280 --> 02:08:02,800
is a um geni model we're going to call

3016
02:07:58,760 --> 02:08:04,559
it a generation model or and um so let's

3017
02:08:02,800 --> 02:08:05,440
say we're using text here so it's going

3018
02:08:04,559 --> 02:08:08,360
to

3019
02:08:05,440 --> 02:08:11,760
llm and the way this system works is

3020
02:08:08,360 --> 02:08:14,079
you've got a model here um the user

3021
02:08:11,760 --> 02:08:16,639
sends in a query again we call this a

3022
02:08:14,079 --> 02:08:19,440
prompt and then uh gets a response which

3023
02:08:16,639 --> 02:08:21,920
in the field is called a completion okay

3024
02:08:19,440 --> 02:08:25,480
uh gets a response which is a completion

3025
02:08:21,920 --> 02:08:27,719
and already um this is a very very

3026
02:08:25,480 --> 02:08:31,199
powerful system in that these models can

3027
02:08:27,719 --> 02:08:34,040
do a lot of things so they can they can

3028
02:08:31,199 --> 02:08:36,559
summarize text they can classify text

3029
02:08:34,040 --> 02:08:38,760
they can an they can answer questions

3030
02:08:36,559 --> 02:08:40,280
they can write drafts for you they can

3031
02:08:38,760 --> 02:08:42,480
write code for you there's a lot of

3032
02:08:40,280 --> 02:08:45,000
things that these things uh can do

3033
02:08:42,480 --> 02:08:48,320
they're pretty um impressive

3034
02:08:45,000 --> 02:08:52,079
actually um it is important to note that

3035
02:08:48,320 --> 02:08:54,040
if you are using a um

3036
02:08:52,079 --> 02:08:55,559
a foundational model by a third party

3037
02:08:54,040 --> 02:08:57,960
provider you're not hosting it yourself

3038
02:08:55,559 --> 02:09:01,360
that this um here I should have put a

3039
02:08:57,960 --> 02:09:04,760
line here this is within the uh domain

3040
02:09:01,360 --> 02:09:08,559
of the model provider so the data is

3041
02:09:04,760 --> 02:09:11,239
going outside of your own uh

3042
02:09:08,559 --> 02:09:14,559
jurisdiction okay so this is at the

3043
02:09:11,239 --> 02:09:18,719
heart of the system this is the biggest

3044
02:09:14,559 --> 02:09:20,440
piece is the model call now um like I

3045
02:09:18,719 --> 02:09:22,679
said in previous lectures these models

3046
02:09:20,440 --> 02:09:24,360
are very big they have a lot of encoded

3047
02:09:22,679 --> 02:09:27,559
information and what you're looking for

3048
02:09:24,360 --> 02:09:30,040
is a particular answer or some sort of

3049
02:09:27,559 --> 02:09:32,119
uh query that you're looking at or

3050
02:09:30,040 --> 02:09:34,239
information um and really it's like

3051
02:09:32,119 --> 02:09:35,719
looking at for a needle in a Hast stack

3052
02:09:34,239 --> 02:09:40,000
and so what you want to do is you want

3053
02:09:35,719 --> 02:09:41,040
to um give that model more information

3054
02:09:40,000 --> 02:09:43,920
and more

3055
02:09:41,040 --> 02:09:46,480
context uh for it to be able to help you

3056
02:09:43,920 --> 02:09:49,599
the best way and so that's where the

3057
02:09:46,480 --> 02:09:50,760
anatomy of a prompt comes in so uh I'm

3058
02:09:49,599 --> 02:09:52,239
not going to go through this in detail

3059
02:09:50,760 --> 02:09:54,159
because we already in previous lecture

3060
02:09:52,239 --> 02:09:55,559
if you've missed it please go back uh

3061
02:09:54,159 --> 02:09:57,000
but the idea is that a prompt of course

3062
02:09:55,559 --> 02:10:00,760
is the input like I said prompt

3063
02:09:57,000 --> 02:10:02,679
engineering is the the process of uh

3064
02:10:00,760 --> 02:10:04,840
editing the input or formulating the

3065
02:10:02,679 --> 02:10:09,239
input or formatting it to drive the

3066
02:10:04,840 --> 02:10:11,159
desired output and um The Prompt itself

3067
02:10:09,239 --> 02:10:13,800
uh as at the heart of it is a question a

3068
02:10:11,159 --> 02:10:16,199
query what it is that you want the task

3069
02:10:13,800 --> 02:10:18,320
what task do you want the model to do

3070
02:10:16,199 --> 02:10:20,040
but that's not all of it you can add so

3071
02:10:18,320 --> 02:10:22,760
many things to a prompt and so you can

3072
02:10:20,040 --> 02:10:24,520
add instructions um um this is steps to

3073
02:10:22,760 --> 02:10:26,320
perform you can add objectives so you

3074
02:10:24,520 --> 02:10:28,119
can tell it um something you want to

3075
02:10:26,320 --> 02:10:30,400
achieve the goal you want to achieve you

3076
02:10:28,119 --> 02:10:32,280
can give it a Persona so you you tell it

3077
02:10:30,400 --> 02:10:34,360
oh this in terms of context you are a

3078
02:10:32,280 --> 02:10:35,360
doctor you are a lawyer and that gives

3079
02:10:34,360 --> 02:10:37,280
you different

3080
02:10:35,360 --> 02:10:39,400
viewpoints um you can give it

3081
02:10:37,280 --> 02:10:41,000
constraints you can say avoid this or or

3082
02:10:39,400 --> 02:10:43,159
or don't do that you can give it

3083
02:10:41,000 --> 02:10:45,480
examples so you can give it an a Dem a

3084
02:10:43,159 --> 02:10:47,639
demo of the output so this is where a

3085
02:10:45,480 --> 02:10:49,719
zero shot one shot and few shot learning

3086
02:10:47,639 --> 02:10:51,760
come in or you can give it more context

3087
02:10:49,719 --> 02:10:53,599
for relevant information or you can

3088
02:10:51,760 --> 02:10:55,679
change the tone and there's more this is

3089
02:10:53,599 --> 02:10:58,119
just an example but the idea is that you

3090
02:10:55,679 --> 02:11:01,840
can change the prompt you can enrich The

3091
02:10:58,119 --> 02:11:03,880
Prompt uh for the model to be able to to

3092
02:11:01,840 --> 02:11:06,040
help you better so you can give it more

3093
02:11:03,880 --> 02:11:08,920
instructions and so this is what we've

3094
02:11:06,040 --> 02:11:10,520
added here we've added this where you

3095
02:11:08,920 --> 02:11:12,119
are adding the context construction so

3096
02:11:10,520 --> 02:11:14,440
this this prompt here that we're

3097
02:11:12,119 --> 02:11:18,760
building you're building it a little

3098
02:11:14,440 --> 02:11:21,599
with with um with a little bit more uh

3099
02:11:18,760 --> 02:11:23,440
awareness right and so that comes here

3100
02:11:21,599 --> 02:11:25,320
so as I move through these diagrams the

3101
02:11:23,440 --> 02:11:27,040
new piece that I'm building in is in

3102
02:11:25,320 --> 02:11:28,880
Orange and the rest is in Black just to

3103
02:11:27,040 --> 02:11:30,880
allow you to to follow through so we

3104
02:11:28,880 --> 02:11:33,840
enhance the context or the prompt or the

3105
02:11:30,880 --> 02:11:35,320
model input and so this becomes um a

3106
02:11:33,840 --> 02:11:36,920
little bit more information for the

3107
02:11:35,320 --> 02:11:39,679
model

3108
02:11:36,920 --> 02:11:42,119
right the other thing we can do is to

3109
02:11:39,679 --> 02:11:43,599
add external an external knowledge base

3110
02:11:42,119 --> 02:11:45,719
this is a rag system so you've got a

3111
02:11:43,599 --> 02:11:48,320
database here and then the input

3112
02:11:45,719 --> 02:11:50,559
retrieved from that database goes into

3113
02:11:48,320 --> 02:11:52,159
the prompt uh construction and then it's

3114
02:11:50,559 --> 02:11:54,079
given to the model model there's a lot

3115
02:11:52,159 --> 02:11:55,520
of reasons why you would want to add rag

3116
02:11:54,079 --> 02:11:59,480
again we talked about rag in the last

3117
02:11:55,520 --> 02:12:02,800
lecture so you can go back and see

3118
02:11:59,480 --> 02:12:03,920
that now if you want you can add uh

3119
02:12:02,800 --> 02:12:08,040
guard

3120
02:12:03,920 --> 02:12:09,960
rails uh for your model so as again like

3121
02:12:08,040 --> 02:12:13,199
I said in the beginning if you are using

3122
02:12:09,960 --> 02:12:15,280
a uh SAS solution from a model provider

3123
02:12:13,199 --> 02:12:19,040
then again this piece right here or or

3124
02:12:15,280 --> 02:12:21,639
this here this this generation call um

3125
02:12:19,040 --> 02:12:24,320
that is not in your domain that goes to

3126
02:12:21,639 --> 02:12:27,199
the provider and so there's information

3127
02:12:24,320 --> 02:12:30,639
here crossing your your your your your

3128
02:12:27,199 --> 02:12:33,880
company Network and so what you can do

3129
02:12:30,639 --> 02:12:36,280
here is you can put input guard rails

3130
02:12:33,880 --> 02:12:39,119
what that does is it validates that the

3131
02:12:36,280 --> 02:12:41,280
input going out of your organization is

3132
02:12:39,119 --> 02:12:43,000
um based on your Norms it's compliant

3133
02:12:41,280 --> 02:12:45,559
with your Norms is there any pii in

3134
02:12:43,000 --> 02:12:47,480
there do I mask anything is is any

3135
02:12:45,559 --> 02:12:49,719
information sensitive information that I

3136
02:12:47,480 --> 02:12:52,320
don't want out of my company and so that

3137
02:12:49,719 --> 02:12:55,679
where that's where inut guards in uh

3138
02:12:52,320 --> 02:12:58,000
before they before they leave your um

3139
02:12:55,679 --> 02:13:01,639
Network and then you can add output

3140
02:12:58,000 --> 02:13:04,599
output guard rails because uh open um

3141
02:13:01,639 --> 02:13:06,239
because LMS give open-ended mod uh

3142
02:13:04,599 --> 02:13:09,520
inputs

3143
02:13:06,239 --> 02:13:11,639
outputs you can um put output guard

3144
02:13:09,520 --> 02:13:13,679
rails to check whether there's any

3145
02:13:11,639 --> 02:13:16,960
whether again the response is compliant

3146
02:13:13,679 --> 02:13:19,000
with your um requirements is is there

3147
02:13:16,960 --> 02:13:22,559
any safety contraints is there any bias

3148
02:13:19,000 --> 02:13:24,320
is there any um is there any uh

3149
02:13:22,559 --> 02:13:27,360
profanities all of that stuff that you

3150
02:13:24,320 --> 02:13:31,840
wouldn't want uh your user to get you

3151
02:13:27,360 --> 02:13:34,199
can put a a catch uh right

3152
02:13:31,840 --> 02:13:37,559
here and so now we've augmented the

3153
02:13:34,199 --> 02:13:40,040
system again with these uh guard

3154
02:13:37,559 --> 02:13:42,480
rails what we could also do for example

3155
02:13:40,040 --> 02:13:45,880
is ADD routers and gateways and so what

3156
02:13:42,480 --> 02:13:48,679
this um does is that this model

3157
02:13:45,880 --> 02:13:51,400
generation you can this generation piece

3158
02:13:48,679 --> 02:13:55,840
here is uh a model it goes out to this

3159
02:13:51,400 --> 02:13:58,520
is a model call and what happens is that

3160
02:13:55,840 --> 02:14:00,159
um different models have different

3161
02:13:58,520 --> 02:14:01,599
strengths so some models are better at

3162
02:14:00,159 --> 02:14:03,119
reasoning some models are better at

3163
02:14:01,599 --> 02:14:07,119
coding some models are better at

3164
02:14:03,119 --> 02:14:09,880
summarizing and so on and if you have

3165
02:14:07,119 --> 02:14:13,040
users that um if you're supporting all

3166
02:14:09,880 --> 02:14:15,320
sorts of requests you might want to do

3167
02:14:13,040 --> 02:14:17,520
different model calls based on the user

3168
02:14:15,320 --> 02:14:20,880
input and so what you would do is you

3169
02:14:17,520 --> 02:14:22,880
you write this class uh a wrapper class

3170
02:14:20,880 --> 02:14:26,800
with which is we're calling here a model

3171
02:14:22,880 --> 02:14:28,400
Gateway which uh routes uh different

3172
02:14:26,800 --> 02:14:30,199
calls to different models depending on

3173
02:14:28,400 --> 02:14:32,400
certain criteria right what this does is

3174
02:14:30,199 --> 02:14:35,840
it abstracts the model

3175
02:14:32,400 --> 02:14:37,480
use um from the underlying model it just

3176
02:14:35,840 --> 02:14:41,480
puts an abstraction layer which allows

3177
02:14:37,480 --> 02:14:46,239
you to switch models

3178
02:14:41,480 --> 02:14:48,480
seamlessly okay now again one added uh

3179
02:14:46,239 --> 02:14:50,800
something else we can add as well as uh

3180
02:14:48,480 --> 02:14:52,960
caches caches in different parts of your

3181
02:14:50,800 --> 02:14:54,440
system system can reduce latency but

3182
02:14:52,960 --> 02:14:56,119
they also can reduce cost because you're

3183
02:14:54,440 --> 02:15:00,639
not hitting your databases or you're not

3184
02:14:56,119 --> 02:15:03,559
hitting that model as um as often oops

3185
02:15:00,639 --> 02:15:05,400
that's the and so you can add caches uh

3186
02:15:03,559 --> 02:15:07,440
at the query level you can add them at

3187
02:15:05,400 --> 02:15:09,199
the the knowledge base level you can add

3188
02:15:07,440 --> 02:15:11,000
them in different places and again you

3189
02:15:09,199 --> 02:15:12,719
can there's all sorts of questions about

3190
02:15:11,000 --> 02:15:16,800
what types of caches and how do we cash

3191
02:15:12,719 --> 02:15:19,440
and when do you know that in all of

3192
02:15:16,800 --> 02:15:22,239
these different scenarios uh there's all

3193
02:15:19,440 --> 02:15:24,920
sorts of uh uh detailed questions that

3194
02:15:22,239 --> 02:15:29,599
can follow but I'm just showing you uh

3195
02:15:24,920 --> 02:15:32,679
an abstract uh

3196
02:15:29,599 --> 02:15:35,119
system and uh

3197
02:15:32,679 --> 02:15:36,960
so you can also add functionality with

3198
02:15:35,119 --> 02:15:39,520
agents so you can add agents that that

3199
02:15:36,960 --> 02:15:44,559
that do various things

3200
02:15:39,520 --> 02:15:46,880
um and then you can add all sorts of uh

3201
02:15:44,559 --> 02:15:48,440
interesting it is a software system at

3202
02:15:46,880 --> 02:15:49,960
the end of the day right you you would

3203
02:15:48,440 --> 02:15:51,719
want to follow best practices you add

3204
02:15:49,960 --> 02:15:53,520
Authentication authoriz ation State and

3205
02:15:51,719 --> 02:15:56,440
session management monitoring and

3206
02:15:53,520 --> 02:15:58,119
observability pipeline orchestration

3207
02:15:56,440 --> 02:16:00,760
human feedback there's so many other

3208
02:15:58,119 --> 02:16:02,639
things that you can to make this model

3209
02:16:00,760 --> 02:16:05,520
this system production ready but what I

3210
02:16:02,639 --> 02:16:07,400
wanted to show you is if had I shown you

3211
02:16:05,520 --> 02:16:09,840
this I hope this is now understandable

3212
02:16:07,400 --> 02:16:12,639
or or seemingly digestible but had I

3213
02:16:09,840 --> 02:16:15,520
shown you this uh from the very

3214
02:16:12,639 --> 02:16:16,400
beginning it could have potentially um

3215
02:16:15,520 --> 02:16:18,840
looked

3216
02:16:16,400 --> 02:16:20,559
intimidating um what I want to encourage

3217
02:16:18,840 --> 02:16:22,559
you is to really look at everything you

3218
02:16:20,559 --> 02:16:24,800
look at online all the different

3219
02:16:22,559 --> 02:16:26,599
diagrams from this lens from the

3220
02:16:24,800 --> 02:16:29,199
conceptual lens and try to understand

3221
02:16:26,599 --> 02:16:32,240
what the component is which bucket does

3222
02:16:29,199 --> 02:16:34,080
it fit into what does it do um and then

3223
02:16:32,240 --> 02:16:36,000
not to really get down bogged down with

3224
02:16:34,080 --> 02:16:38,519
the technology the technology changes

3225
02:16:36,000 --> 02:16:40,639
really fast um and it's it's moving

3226
02:16:38,519 --> 02:16:43,599
super fast but what you really need to

3227
02:16:40,639 --> 02:16:44,880
have is an overview of the system and

3228
02:16:43,599 --> 02:16:50,000
the

3229
02:16:44,880 --> 02:16:52,880
components okay and that is it I hope

3230
02:16:50,000 --> 02:16:54,319
this series was useful full um if you

3231
02:16:52,880 --> 02:16:56,399
have any questions let me know I am

3232
02:16:54,319 --> 02:17:00,359
going to release the the

3233
02:16:56,399 --> 02:17:02,639
the the slides with the uh Jupiter

3234
02:17:00,359 --> 02:17:04,840
notebooks I think that's it yeah that's

3235
02:17:02,639 --> 02:17:07,920
si in the Jupiter notebooks hope this

3236
02:17:04,840 --> 02:17:07,920
was useful